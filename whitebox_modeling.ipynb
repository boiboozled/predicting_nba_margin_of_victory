{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9389 entries, 34 to 19036\n",
      "Columns: 180 entries, GAME_ID to PLUS_MINUS\n",
      "dtypes: float64(174), int64(2), object(4)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./data/rolling_averages_with_opponent.pkl\")\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset=[\"GAME_ID\"], keep=\"first\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>FGM_AVG</th>\n",
       "      <th>FGA_AVG</th>\n",
       "      <th>FG_PCT_AVG</th>\n",
       "      <th>FG3M_AVG</th>\n",
       "      <th>FG3A_AVG</th>\n",
       "      <th>FG3_PCT_AVG</th>\n",
       "      <th>FTM_AVG</th>\n",
       "      <th>FTA_AVG</th>\n",
       "      <th>FT_PCT_AVG</th>\n",
       "      <th>OREB_AVG</th>\n",
       "      <th>DREB_AVG</th>\n",
       "      <th>REB_AVG</th>\n",
       "      <th>AST_AVG</th>\n",
       "      <th>STL_AVG</th>\n",
       "      <th>BLK_AVG</th>\n",
       "      <th>TO_AVG</th>\n",
       "      <th>PF_AVG</th>\n",
       "      <th>PTS_AVG</th>\n",
       "      <th>E_OFF_RATING_AVG</th>\n",
       "      <th>OFF_RATING_AVG</th>\n",
       "      <th>E_DEF_RATING_AVG</th>\n",
       "      <th>DEF_RATING_AVG</th>\n",
       "      <th>E_NET_RATING_AVG</th>\n",
       "      <th>NET_RATING_AVG</th>\n",
       "      <th>AST_PCT_AVG</th>\n",
       "      <th>AST_TOV_AVG</th>\n",
       "      <th>AST_RATIO_AVG</th>\n",
       "      <th>OREB_PCT_AVG</th>\n",
       "      <th>DREB_PCT_AVG</th>\n",
       "      <th>REB_PCT_AVG</th>\n",
       "      <th>E_TM_TOV_PCT_AVG</th>\n",
       "      <th>TM_TOV_PCT_AVG</th>\n",
       "      <th>EFG_PCT_AVG</th>\n",
       "      <th>TS_PCT_AVG</th>\n",
       "      <th>E_USG_PCT_AVG</th>\n",
       "      <th>E_PACE_AVG</th>\n",
       "      <th>PACE_AVG</th>\n",
       "      <th>PACE_PER40_AVG</th>\n",
       "      <th>POSS_AVG</th>\n",
       "      <th>PIE_AVG</th>\n",
       "      <th>FTA_RATE_AVG</th>\n",
       "      <th>OPP_EFG_PCT_AVG</th>\n",
       "      <th>OPP_FTA_RATE_AVG</th>\n",
       "      <th>OPP_TOV_PCT_AVG</th>\n",
       "      <th>OPP_OREB_PCT_AVG</th>\n",
       "      <th>PTS_OFF_TOV_AVG</th>\n",
       "      <th>PTS_2ND_CHANCE_AVG</th>\n",
       "      <th>PTS_FB_AVG</th>\n",
       "      <th>PTS_PAINT_AVG</th>\n",
       "      <th>OPP_PTS_OFF_TOV_AVG</th>\n",
       "      <th>OPP_PTS_2ND_CHANCE_AVG</th>\n",
       "      <th>OPP_PTS_FB_AVG</th>\n",
       "      <th>OPP_PTS_PAINT_AVG</th>\n",
       "      <th>BLKA_AVG</th>\n",
       "      <th>PFD_AVG</th>\n",
       "      <th>PCT_FGA_2PT_AVG</th>\n",
       "      <th>PCT_FGA_3PT_AVG</th>\n",
       "      <th>PCT_PTS_2PT_AVG</th>\n",
       "      <th>PCT_PTS_2PT_MR_AVG</th>\n",
       "      <th>PCT_PTS_3PT_AVG</th>\n",
       "      <th>PCT_PTS_FB_AVG</th>\n",
       "      <th>PCT_PTS_FT_AVG</th>\n",
       "      <th>PCT_PTS_OFF_TOV_AVG</th>\n",
       "      <th>PCT_PTS_PAINT_AVG</th>\n",
       "      <th>PCT_AST_2PM_AVG</th>\n",
       "      <th>PCT_UAST_2PM_AVG</th>\n",
       "      <th>PCT_AST_3PM_AVG</th>\n",
       "      <th>PCT_UAST_3PM_AVG</th>\n",
       "      <th>PCT_AST_FGM_AVG</th>\n",
       "      <th>PCT_UAST_FGM_AVG</th>\n",
       "      <th>DIST_AVG</th>\n",
       "      <th>ORBC_AVG</th>\n",
       "      <th>DRBC_AVG</th>\n",
       "      <th>RBC_AVG</th>\n",
       "      <th>TCHS_AVG</th>\n",
       "      <th>SAST_AVG</th>\n",
       "      <th>FTAST_AVG</th>\n",
       "      <th>PASS_AVG</th>\n",
       "      <th>CFGM_AVG</th>\n",
       "      <th>CFGA_AVG</th>\n",
       "      <th>CFG_PCT_AVG</th>\n",
       "      <th>UFGM_AVG</th>\n",
       "      <th>UFGA_AVG</th>\n",
       "      <th>UFG_PCT_AVG</th>\n",
       "      <th>DFGM_AVG</th>\n",
       "      <th>DFGA_AVG</th>\n",
       "      <th>DFG_PCT_AVG</th>\n",
       "      <th>FGM_OPP_AVG</th>\n",
       "      <th>FGA_OPP_AVG</th>\n",
       "      <th>FG_PCT_OPP_AVG</th>\n",
       "      <th>FG3M_OPP_AVG</th>\n",
       "      <th>FG3A_OPP_AVG</th>\n",
       "      <th>FG3_PCT_OPP_AVG</th>\n",
       "      <th>FTM_OPP_AVG</th>\n",
       "      <th>FTA_OPP_AVG</th>\n",
       "      <th>FT_PCT_OPP_AVG</th>\n",
       "      <th>OREB_OPP_AVG</th>\n",
       "      <th>DREB_OPP_AVG</th>\n",
       "      <th>REB_OPP_AVG</th>\n",
       "      <th>AST_OPP_AVG</th>\n",
       "      <th>STL_OPP_AVG</th>\n",
       "      <th>BLK_OPP_AVG</th>\n",
       "      <th>TO_OPP_AVG</th>\n",
       "      <th>PF_OPP_AVG</th>\n",
       "      <th>PTS_OPP_AVG</th>\n",
       "      <th>E_OFF_RATING_OPP_AVG</th>\n",
       "      <th>OFF_RATING_OPP_AVG</th>\n",
       "      <th>E_DEF_RATING_OPP_AVG</th>\n",
       "      <th>DEF_RATING_OPP_AVG</th>\n",
       "      <th>E_NET_RATING_OPP_AVG</th>\n",
       "      <th>NET_RATING_OPP_AVG</th>\n",
       "      <th>AST_PCT_OPP_AVG</th>\n",
       "      <th>AST_TOV_OPP_AVG</th>\n",
       "      <th>AST_RATIO_OPP_AVG</th>\n",
       "      <th>OREB_PCT_OPP_AVG</th>\n",
       "      <th>DREB_PCT_OPP_AVG</th>\n",
       "      <th>REB_PCT_OPP_AVG</th>\n",
       "      <th>E_TM_TOV_PCT_OPP_AVG</th>\n",
       "      <th>TM_TOV_PCT_OPP_AVG</th>\n",
       "      <th>EFG_PCT_OPP_AVG</th>\n",
       "      <th>TS_PCT_OPP_AVG</th>\n",
       "      <th>E_USG_PCT_OPP_AVG</th>\n",
       "      <th>E_PACE_OPP_AVG</th>\n",
       "      <th>PACE_OPP_AVG</th>\n",
       "      <th>PACE_PER40_OPP_AVG</th>\n",
       "      <th>POSS_OPP_AVG</th>\n",
       "      <th>PIE_OPP_AVG</th>\n",
       "      <th>FTA_RATE_OPP_AVG</th>\n",
       "      <th>OPP_EFG_PCT_OPP_AVG</th>\n",
       "      <th>OPP_FTA_RATE_OPP_AVG</th>\n",
       "      <th>OPP_TOV_PCT_OPP_AVG</th>\n",
       "      <th>OPP_OREB_PCT_OPP_AVG</th>\n",
       "      <th>PTS_OFF_TOV_OPP_AVG</th>\n",
       "      <th>PTS_2ND_CHANCE_OPP_AVG</th>\n",
       "      <th>PTS_FB_OPP_AVG</th>\n",
       "      <th>PTS_PAINT_OPP_AVG</th>\n",
       "      <th>OPP_PTS_OFF_TOV_OPP_AVG</th>\n",
       "      <th>OPP_PTS_2ND_CHANCE_OPP_AVG</th>\n",
       "      <th>OPP_PTS_FB_OPP_AVG</th>\n",
       "      <th>OPP_PTS_PAINT_OPP_AVG</th>\n",
       "      <th>BLKA_OPP_AVG</th>\n",
       "      <th>PFD_OPP_AVG</th>\n",
       "      <th>PCT_FGA_2PT_OPP_AVG</th>\n",
       "      <th>PCT_FGA_3PT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_2PT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_2PT_MR_OPP_AVG</th>\n",
       "      <th>PCT_PTS_3PT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_FB_OPP_AVG</th>\n",
       "      <th>PCT_PTS_FT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_OFF_TOV_OPP_AVG</th>\n",
       "      <th>PCT_PTS_PAINT_OPP_AVG</th>\n",
       "      <th>PCT_AST_2PM_OPP_AVG</th>\n",
       "      <th>PCT_UAST_2PM_OPP_AVG</th>\n",
       "      <th>PCT_AST_3PM_OPP_AVG</th>\n",
       "      <th>PCT_UAST_3PM_OPP_AVG</th>\n",
       "      <th>PCT_AST_FGM_OPP_AVG</th>\n",
       "      <th>PCT_UAST_FGM_OPP_AVG</th>\n",
       "      <th>DIST_OPP_AVG</th>\n",
       "      <th>ORBC_OPP_AVG</th>\n",
       "      <th>DRBC_OPP_AVG</th>\n",
       "      <th>RBC_OPP_AVG</th>\n",
       "      <th>TCHS_OPP_AVG</th>\n",
       "      <th>SAST_OPP_AVG</th>\n",
       "      <th>FTAST_OPP_AVG</th>\n",
       "      <th>PASS_OPP_AVG</th>\n",
       "      <th>CFGM_OPP_AVG</th>\n",
       "      <th>CFGA_OPP_AVG</th>\n",
       "      <th>CFG_PCT_OPP_AVG</th>\n",
       "      <th>UFGM_OPP_AVG</th>\n",
       "      <th>UFGA_OPP_AVG</th>\n",
       "      <th>UFG_PCT_OPP_AVG</th>\n",
       "      <th>DFGM_OPP_AVG</th>\n",
       "      <th>DFGA_OPP_AVG</th>\n",
       "      <th>DFG_PCT_OPP_AVG</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9.389000e+03</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "      <td>9389.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>39.950721</td>\n",
       "      <td>87.343146</td>\n",
       "      <td>0.458300</td>\n",
       "      <td>10.895364</td>\n",
       "      <td>30.657866</td>\n",
       "      <td>0.354650</td>\n",
       "      <td>17.528373</td>\n",
       "      <td>22.802531</td>\n",
       "      <td>0.768676</td>\n",
       "      <td>10.260761</td>\n",
       "      <td>34.108642</td>\n",
       "      <td>44.369403</td>\n",
       "      <td>23.413651</td>\n",
       "      <td>7.737255</td>\n",
       "      <td>4.960646</td>\n",
       "      <td>13.898848</td>\n",
       "      <td>20.536168</td>\n",
       "      <td>108.325178</td>\n",
       "      <td>106.644110</td>\n",
       "      <td>108.512322</td>\n",
       "      <td>106.612944</td>\n",
       "      <td>108.467870</td>\n",
       "      <td>0.031195</td>\n",
       "      <td>0.044373</td>\n",
       "      <td>0.585427</td>\n",
       "      <td>1.763443</td>\n",
       "      <td>17.220010</td>\n",
       "      <td>0.270852</td>\n",
       "      <td>0.730040</td>\n",
       "      <td>0.500366</td>\n",
       "      <td>14.257367</td>\n",
       "      <td>14.514347</td>\n",
       "      <td>0.520808</td>\n",
       "      <td>0.557239</td>\n",
       "      <td>0.198321</td>\n",
       "      <td>100.967119</td>\n",
       "      <td>99.200940</td>\n",
       "      <td>82.667415</td>\n",
       "      <td>99.839112</td>\n",
       "      <td>0.500431</td>\n",
       "      <td>0.264465</td>\n",
       "      <td>0.521188</td>\n",
       "      <td>0.265068</td>\n",
       "      <td>0.143086</td>\n",
       "      <td>0.271444</td>\n",
       "      <td>16.816641</td>\n",
       "      <td>13.101210</td>\n",
       "      <td>12.973244</td>\n",
       "      <td>46.128921</td>\n",
       "      <td>16.705125</td>\n",
       "      <td>13.016007</td>\n",
       "      <td>12.913173</td>\n",
       "      <td>45.985692</td>\n",
       "      <td>4.906743</td>\n",
       "      <td>20.461056</td>\n",
       "      <td>0.649118</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.538865</td>\n",
       "      <td>0.112322</td>\n",
       "      <td>0.298986</td>\n",
       "      <td>0.119328</td>\n",
       "      <td>0.162131</td>\n",
       "      <td>0.155672</td>\n",
       "      <td>0.426546</td>\n",
       "      <td>0.494028</td>\n",
       "      <td>0.505989</td>\n",
       "      <td>0.832192</td>\n",
       "      <td>0.167619</td>\n",
       "      <td>0.585417</td>\n",
       "      <td>0.414591</td>\n",
       "      <td>17.654926</td>\n",
       "      <td>27.121276</td>\n",
       "      <td>57.473372</td>\n",
       "      <td>82.085239</td>\n",
       "      <td>413.099637</td>\n",
       "      <td>2.856512</td>\n",
       "      <td>1.799263</td>\n",
       "      <td>291.429850</td>\n",
       "      <td>17.706007</td>\n",
       "      <td>36.533672</td>\n",
       "      <td>0.485882</td>\n",
       "      <td>21.911756</td>\n",
       "      <td>50.277355</td>\n",
       "      <td>0.434635</td>\n",
       "      <td>16.115482</td>\n",
       "      <td>25.435499</td>\n",
       "      <td>0.633996</td>\n",
       "      <td>39.920989</td>\n",
       "      <td>87.282719</td>\n",
       "      <td>0.458284</td>\n",
       "      <td>11.122806</td>\n",
       "      <td>31.272134</td>\n",
       "      <td>0.354426</td>\n",
       "      <td>17.516533</td>\n",
       "      <td>22.793254</td>\n",
       "      <td>0.768955</td>\n",
       "      <td>10.187010</td>\n",
       "      <td>34.150841</td>\n",
       "      <td>44.337851</td>\n",
       "      <td>23.651204</td>\n",
       "      <td>7.697442</td>\n",
       "      <td>4.917986</td>\n",
       "      <td>13.999807</td>\n",
       "      <td>20.444239</td>\n",
       "      <td>108.481318</td>\n",
       "      <td>106.690746</td>\n",
       "      <td>108.530697</td>\n",
       "      <td>106.648117</td>\n",
       "      <td>108.499755</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.030924</td>\n",
       "      <td>0.591828</td>\n",
       "      <td>1.767798</td>\n",
       "      <td>17.362137</td>\n",
       "      <td>0.269481</td>\n",
       "      <td>0.729839</td>\n",
       "      <td>0.499785</td>\n",
       "      <td>14.333184</td>\n",
       "      <td>14.586950</td>\n",
       "      <td>0.522150</td>\n",
       "      <td>0.558436</td>\n",
       "      <td>0.198310</td>\n",
       "      <td>101.041930</td>\n",
       "      <td>99.290656</td>\n",
       "      <td>82.742170</td>\n",
       "      <td>99.969030</td>\n",
       "      <td>0.499991</td>\n",
       "      <td>0.264378</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.263555</td>\n",
       "      <td>0.142966</td>\n",
       "      <td>0.271662</td>\n",
       "      <td>16.799497</td>\n",
       "      <td>12.911099</td>\n",
       "      <td>12.979119</td>\n",
       "      <td>46.025711</td>\n",
       "      <td>16.880227</td>\n",
       "      <td>12.985969</td>\n",
       "      <td>13.018055</td>\n",
       "      <td>46.114991</td>\n",
       "      <td>4.962133</td>\n",
       "      <td>20.530897</td>\n",
       "      <td>0.641664</td>\n",
       "      <td>0.358355</td>\n",
       "      <td>0.533476</td>\n",
       "      <td>0.108304</td>\n",
       "      <td>0.304657</td>\n",
       "      <td>0.119181</td>\n",
       "      <td>0.161848</td>\n",
       "      <td>0.155461</td>\n",
       "      <td>0.425182</td>\n",
       "      <td>0.503704</td>\n",
       "      <td>0.496313</td>\n",
       "      <td>0.823779</td>\n",
       "      <td>0.175874</td>\n",
       "      <td>0.591803</td>\n",
       "      <td>0.408206</td>\n",
       "      <td>17.613526</td>\n",
       "      <td>27.163113</td>\n",
       "      <td>57.837941</td>\n",
       "      <td>82.486533</td>\n",
       "      <td>414.177653</td>\n",
       "      <td>2.951684</td>\n",
       "      <td>1.824418</td>\n",
       "      <td>292.423365</td>\n",
       "      <td>17.660269</td>\n",
       "      <td>36.261218</td>\n",
       "      <td>0.488873</td>\n",
       "      <td>22.173131</td>\n",
       "      <td>50.574464</td>\n",
       "      <td>0.437302</td>\n",
       "      <td>16.089533</td>\n",
       "      <td>25.427158</td>\n",
       "      <td>0.633425</td>\n",
       "      <td>-0.172755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.758431e+00</td>\n",
       "      <td>2.261645</td>\n",
       "      <td>3.360753</td>\n",
       "      <td>0.019109</td>\n",
       "      <td>2.226503</td>\n",
       "      <td>5.778841</td>\n",
       "      <td>0.025109</td>\n",
       "      <td>2.184409</td>\n",
       "      <td>2.711463</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>1.457246</td>\n",
       "      <td>2.100497</td>\n",
       "      <td>2.505444</td>\n",
       "      <td>2.506311</td>\n",
       "      <td>1.069637</td>\n",
       "      <td>0.915397</td>\n",
       "      <td>1.441165</td>\n",
       "      <td>1.837237</td>\n",
       "      <td>6.118891</td>\n",
       "      <td>4.602309</td>\n",
       "      <td>4.598764</td>\n",
       "      <td>4.411436</td>\n",
       "      <td>4.454009</td>\n",
       "      <td>5.585157</td>\n",
       "      <td>5.403196</td>\n",
       "      <td>0.044955</td>\n",
       "      <td>0.264995</td>\n",
       "      <td>1.428845</td>\n",
       "      <td>0.028407</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.017455</td>\n",
       "      <td>1.337508</td>\n",
       "      <td>1.368545</td>\n",
       "      <td>0.025021</td>\n",
       "      <td>0.023619</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>2.957159</td>\n",
       "      <td>2.870400</td>\n",
       "      <td>2.391971</td>\n",
       "      <td>2.970476</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>0.024017</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>2.178695</td>\n",
       "      <td>1.968392</td>\n",
       "      <td>3.139162</td>\n",
       "      <td>4.870947</td>\n",
       "      <td>2.039210</td>\n",
       "      <td>1.648424</td>\n",
       "      <td>2.349627</td>\n",
       "      <td>4.341077</td>\n",
       "      <td>0.827331</td>\n",
       "      <td>1.703266</td>\n",
       "      <td>0.061578</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.046195</td>\n",
       "      <td>0.052331</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.036464</td>\n",
       "      <td>0.050945</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>0.058487</td>\n",
       "      <td>0.058234</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.044952</td>\n",
       "      <td>0.600311</td>\n",
       "      <td>3.926415</td>\n",
       "      <td>3.673363</td>\n",
       "      <td>6.495700</td>\n",
       "      <td>14.878582</td>\n",
       "      <td>0.538552</td>\n",
       "      <td>0.645953</td>\n",
       "      <td>13.962118</td>\n",
       "      <td>1.484364</td>\n",
       "      <td>2.871259</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>1.908595</td>\n",
       "      <td>3.853690</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>1.849484</td>\n",
       "      <td>2.629874</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>2.219392</td>\n",
       "      <td>3.091154</td>\n",
       "      <td>0.020253</td>\n",
       "      <td>2.227526</td>\n",
       "      <td>5.669894</td>\n",
       "      <td>0.025985</td>\n",
       "      <td>2.134604</td>\n",
       "      <td>2.696309</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>1.402878</td>\n",
       "      <td>1.982376</td>\n",
       "      <td>2.434404</td>\n",
       "      <td>2.503055</td>\n",
       "      <td>1.038853</td>\n",
       "      <td>0.970182</td>\n",
       "      <td>1.483069</td>\n",
       "      <td>1.801275</td>\n",
       "      <td>6.055714</td>\n",
       "      <td>4.695365</td>\n",
       "      <td>4.656310</td>\n",
       "      <td>4.300101</td>\n",
       "      <td>4.345303</td>\n",
       "      <td>5.575028</td>\n",
       "      <td>5.398525</td>\n",
       "      <td>0.044802</td>\n",
       "      <td>0.259489</td>\n",
       "      <td>1.462764</td>\n",
       "      <td>0.027856</td>\n",
       "      <td>0.022431</td>\n",
       "      <td>0.017438</td>\n",
       "      <td>1.307329</td>\n",
       "      <td>1.339636</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>0.025198</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>2.896079</td>\n",
       "      <td>2.806421</td>\n",
       "      <td>2.338670</td>\n",
       "      <td>2.906291</td>\n",
       "      <td>0.034425</td>\n",
       "      <td>0.033681</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>0.033457</td>\n",
       "      <td>0.014068</td>\n",
       "      <td>0.022440</td>\n",
       "      <td>2.043339</td>\n",
       "      <td>1.912790</td>\n",
       "      <td>3.058786</td>\n",
       "      <td>4.796126</td>\n",
       "      <td>2.120340</td>\n",
       "      <td>1.712098</td>\n",
       "      <td>2.172588</td>\n",
       "      <td>4.167648</td>\n",
       "      <td>0.856550</td>\n",
       "      <td>1.725136</td>\n",
       "      <td>0.061270</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.047673</td>\n",
       "      <td>0.045070</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.037373</td>\n",
       "      <td>0.052792</td>\n",
       "      <td>0.052789</td>\n",
       "      <td>0.058257</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.044786</td>\n",
       "      <td>0.589525</td>\n",
       "      <td>4.028182</td>\n",
       "      <td>3.837692</td>\n",
       "      <td>6.799244</td>\n",
       "      <td>15.181280</td>\n",
       "      <td>0.554278</td>\n",
       "      <td>0.665246</td>\n",
       "      <td>14.268765</td>\n",
       "      <td>1.447222</td>\n",
       "      <td>2.964485</td>\n",
       "      <td>0.029228</td>\n",
       "      <td>1.922948</td>\n",
       "      <td>3.724062</td>\n",
       "      <td>0.019735</td>\n",
       "      <td>1.882069</td>\n",
       "      <td>2.703731</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>14.357537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>77.800000</td>\n",
       "      <td>77.600000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>-32.400000</td>\n",
       "      <td>-28.900000</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.564000</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>6.031000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>92.370000</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>75.420000</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.458444</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.306000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.176000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>13.588000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.273000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>73.800000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>80.550000</td>\n",
       "      <td>82.100000</td>\n",
       "      <td>-43.900000</td>\n",
       "      <td>-46.800000</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.102000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>6.715000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>92.600000</td>\n",
       "      <td>91.115385</td>\n",
       "      <td>75.929231</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>0.164000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.357000</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.204000</td>\n",
       "      <td>0.238000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.205000</td>\n",
       "      <td>14.338333</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>-73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>38.491525</td>\n",
       "      <td>85.197368</td>\n",
       "      <td>0.446537</td>\n",
       "      <td>9.357143</td>\n",
       "      <td>26.256410</td>\n",
       "      <td>0.342485</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>21.126761</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>9.294118</td>\n",
       "      <td>32.703704</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>21.782609</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.375000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.315789</td>\n",
       "      <td>103.916667</td>\n",
       "      <td>103.481579</td>\n",
       "      <td>105.264000</td>\n",
       "      <td>104.013043</td>\n",
       "      <td>105.788889</td>\n",
       "      <td>-3.220690</td>\n",
       "      <td>-3.115190</td>\n",
       "      <td>0.557878</td>\n",
       "      <td>1.595833</td>\n",
       "      <td>16.329268</td>\n",
       "      <td>0.252333</td>\n",
       "      <td>0.717313</td>\n",
       "      <td>0.488979</td>\n",
       "      <td>13.461600</td>\n",
       "      <td>13.688235</td>\n",
       "      <td>0.504386</td>\n",
       "      <td>0.541622</td>\n",
       "      <td>0.197962</td>\n",
       "      <td>98.985797</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>81.043000</td>\n",
       "      <td>97.916667</td>\n",
       "      <td>0.480460</td>\n",
       "      <td>0.241889</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>0.242333</td>\n",
       "      <td>0.132276</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>15.281250</td>\n",
       "      <td>11.971429</td>\n",
       "      <td>10.822222</td>\n",
       "      <td>42.882353</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>12.027778</td>\n",
       "      <td>11.486486</td>\n",
       "      <td>42.769231</td>\n",
       "      <td>4.392857</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>0.609393</td>\n",
       "      <td>0.307119</td>\n",
       "      <td>0.507986</td>\n",
       "      <td>0.075794</td>\n",
       "      <td>0.265797</td>\n",
       "      <td>0.101174</td>\n",
       "      <td>0.149099</td>\n",
       "      <td>0.142563</td>\n",
       "      <td>0.403019</td>\n",
       "      <td>0.461673</td>\n",
       "      <td>0.472406</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.557857</td>\n",
       "      <td>0.385066</td>\n",
       "      <td>17.177234</td>\n",
       "      <td>24.085714</td>\n",
       "      <td>54.923077</td>\n",
       "      <td>77.045455</td>\n",
       "      <td>402.543860</td>\n",
       "      <td>2.538462</td>\n",
       "      <td>1.269841</td>\n",
       "      <td>281.758621</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>34.585366</td>\n",
       "      <td>0.468328</td>\n",
       "      <td>20.756410</td>\n",
       "      <td>47.683333</td>\n",
       "      <td>0.425394</td>\n",
       "      <td>14.807018</td>\n",
       "      <td>23.575758</td>\n",
       "      <td>0.614957</td>\n",
       "      <td>38.485714</td>\n",
       "      <td>85.250000</td>\n",
       "      <td>0.445270</td>\n",
       "      <td>9.632353</td>\n",
       "      <td>27.424242</td>\n",
       "      <td>0.341476</td>\n",
       "      <td>16.117647</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.746273</td>\n",
       "      <td>9.237288</td>\n",
       "      <td>32.922078</td>\n",
       "      <td>42.823529</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.321429</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>104.076923</td>\n",
       "      <td>103.361538</td>\n",
       "      <td>105.184615</td>\n",
       "      <td>104.075000</td>\n",
       "      <td>105.914286</td>\n",
       "      <td>-3.183673</td>\n",
       "      <td>-2.900000</td>\n",
       "      <td>0.563750</td>\n",
       "      <td>1.595397</td>\n",
       "      <td>16.473333</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.717533</td>\n",
       "      <td>0.488873</td>\n",
       "      <td>13.488681</td>\n",
       "      <td>13.724000</td>\n",
       "      <td>0.504676</td>\n",
       "      <td>0.541769</td>\n",
       "      <td>0.197930</td>\n",
       "      <td>99.058966</td>\n",
       "      <td>97.364643</td>\n",
       "      <td>81.137500</td>\n",
       "      <td>98.020833</td>\n",
       "      <td>0.480250</td>\n",
       "      <td>0.241474</td>\n",
       "      <td>0.507643</td>\n",
       "      <td>0.241000</td>\n",
       "      <td>0.133442</td>\n",
       "      <td>0.258968</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>11.763158</td>\n",
       "      <td>10.907895</td>\n",
       "      <td>43.090909</td>\n",
       "      <td>15.450000</td>\n",
       "      <td>11.981481</td>\n",
       "      <td>11.714286</td>\n",
       "      <td>43.133333</td>\n",
       "      <td>4.433962</td>\n",
       "      <td>19.394366</td>\n",
       "      <td>0.602469</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.501892</td>\n",
       "      <td>0.072163</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.102188</td>\n",
       "      <td>0.148725</td>\n",
       "      <td>0.143222</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470280</td>\n",
       "      <td>0.463200</td>\n",
       "      <td>0.793000</td>\n",
       "      <td>0.139273</td>\n",
       "      <td>0.563732</td>\n",
       "      <td>0.379919</td>\n",
       "      <td>17.151408</td>\n",
       "      <td>24.057692</td>\n",
       "      <td>55.215385</td>\n",
       "      <td>77.285714</td>\n",
       "      <td>403.638889</td>\n",
       "      <td>2.629630</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>282.315789</td>\n",
       "      <td>16.767857</td>\n",
       "      <td>34.129032</td>\n",
       "      <td>0.470620</td>\n",
       "      <td>20.947368</td>\n",
       "      <td>47.931034</td>\n",
       "      <td>0.426906</td>\n",
       "      <td>14.789474</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>0.615800</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>39.906250</td>\n",
       "      <td>87.270833</td>\n",
       "      <td>0.458704</td>\n",
       "      <td>10.894737</td>\n",
       "      <td>30.903846</td>\n",
       "      <td>0.354938</td>\n",
       "      <td>17.439024</td>\n",
       "      <td>22.692308</td>\n",
       "      <td>0.772222</td>\n",
       "      <td>10.190476</td>\n",
       "      <td>33.965517</td>\n",
       "      <td>44.227273</td>\n",
       "      <td>23.294118</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>4.946429</td>\n",
       "      <td>13.772727</td>\n",
       "      <td>20.461538</td>\n",
       "      <td>108.560000</td>\n",
       "      <td>107.054167</td>\n",
       "      <td>108.800000</td>\n",
       "      <td>106.825000</td>\n",
       "      <td>108.656410</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.586375</td>\n",
       "      <td>1.761231</td>\n",
       "      <td>17.242254</td>\n",
       "      <td>0.270023</td>\n",
       "      <td>0.729650</td>\n",
       "      <td>0.499765</td>\n",
       "      <td>14.163259</td>\n",
       "      <td>14.433333</td>\n",
       "      <td>0.522476</td>\n",
       "      <td>0.558023</td>\n",
       "      <td>0.198308</td>\n",
       "      <td>100.872157</td>\n",
       "      <td>99.097222</td>\n",
       "      <td>82.581111</td>\n",
       "      <td>99.666667</td>\n",
       "      <td>0.500842</td>\n",
       "      <td>0.262709</td>\n",
       "      <td>0.521886</td>\n",
       "      <td>0.264431</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>0.271692</td>\n",
       "      <td>16.636364</td>\n",
       "      <td>13.096154</td>\n",
       "      <td>12.545455</td>\n",
       "      <td>45.806452</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>13.029412</td>\n",
       "      <td>12.766667</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>20.283333</td>\n",
       "      <td>0.647324</td>\n",
       "      <td>0.352676</td>\n",
       "      <td>0.540949</td>\n",
       "      <td>0.106923</td>\n",
       "      <td>0.296429</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.160042</td>\n",
       "      <td>0.154677</td>\n",
       "      <td>0.425254</td>\n",
       "      <td>0.493792</td>\n",
       "      <td>0.506238</td>\n",
       "      <td>0.835060</td>\n",
       "      <td>0.164840</td>\n",
       "      <td>0.586375</td>\n",
       "      <td>0.413644</td>\n",
       "      <td>17.731266</td>\n",
       "      <td>26.454545</td>\n",
       "      <td>57.055556</td>\n",
       "      <td>81.222222</td>\n",
       "      <td>412.887324</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>1.733333</td>\n",
       "      <td>291.547619</td>\n",
       "      <td>17.645161</td>\n",
       "      <td>36.458333</td>\n",
       "      <td>0.486182</td>\n",
       "      <td>22.148148</td>\n",
       "      <td>50.936170</td>\n",
       "      <td>0.435455</td>\n",
       "      <td>16.064103</td>\n",
       "      <td>25.179487</td>\n",
       "      <td>0.632880</td>\n",
       "      <td>39.765625</td>\n",
       "      <td>87.200000</td>\n",
       "      <td>0.457788</td>\n",
       "      <td>11.125000</td>\n",
       "      <td>31.465753</td>\n",
       "      <td>0.354014</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>22.640625</td>\n",
       "      <td>0.771846</td>\n",
       "      <td>10.166667</td>\n",
       "      <td>34.014085</td>\n",
       "      <td>44.250000</td>\n",
       "      <td>23.508475</td>\n",
       "      <td>7.607143</td>\n",
       "      <td>4.850000</td>\n",
       "      <td>13.869565</td>\n",
       "      <td>20.325000</td>\n",
       "      <td>108.633333</td>\n",
       "      <td>106.803448</td>\n",
       "      <td>108.638000</td>\n",
       "      <td>106.938889</td>\n",
       "      <td>108.687654</td>\n",
       "      <td>0.160345</td>\n",
       "      <td>0.109211</td>\n",
       "      <td>0.590368</td>\n",
       "      <td>1.767037</td>\n",
       "      <td>17.307692</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>0.729469</td>\n",
       "      <td>0.499470</td>\n",
       "      <td>14.239639</td>\n",
       "      <td>14.504348</td>\n",
       "      <td>0.522071</td>\n",
       "      <td>0.557630</td>\n",
       "      <td>0.198302</td>\n",
       "      <td>100.857222</td>\n",
       "      <td>99.090667</td>\n",
       "      <td>82.575410</td>\n",
       "      <td>99.727273</td>\n",
       "      <td>0.501375</td>\n",
       "      <td>0.261592</td>\n",
       "      <td>0.522958</td>\n",
       "      <td>0.262333</td>\n",
       "      <td>0.142217</td>\n",
       "      <td>0.271761</td>\n",
       "      <td>16.641026</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>45.714286</td>\n",
       "      <td>16.761194</td>\n",
       "      <td>13.019231</td>\n",
       "      <td>12.904762</td>\n",
       "      <td>46.200000</td>\n",
       "      <td>4.972973</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.360500</td>\n",
       "      <td>0.533871</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.306814</td>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.159673</td>\n",
       "      <td>0.154188</td>\n",
       "      <td>0.423762</td>\n",
       "      <td>0.500286</td>\n",
       "      <td>0.499735</td>\n",
       "      <td>0.827895</td>\n",
       "      <td>0.171970</td>\n",
       "      <td>0.590333</td>\n",
       "      <td>0.409687</td>\n",
       "      <td>17.664253</td>\n",
       "      <td>26.422222</td>\n",
       "      <td>57.269231</td>\n",
       "      <td>81.500000</td>\n",
       "      <td>414.413793</td>\n",
       "      <td>2.966667</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>293.393939</td>\n",
       "      <td>17.645161</td>\n",
       "      <td>36.169014</td>\n",
       "      <td>0.488679</td>\n",
       "      <td>22.351351</td>\n",
       "      <td>51.043478</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>16.166667</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>0.633667</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>89.609375</td>\n",
       "      <td>0.471194</td>\n",
       "      <td>12.260870</td>\n",
       "      <td>34.305556</td>\n",
       "      <td>0.367812</td>\n",
       "      <td>18.857143</td>\n",
       "      <td>24.421053</td>\n",
       "      <td>0.791826</td>\n",
       "      <td>11.064516</td>\n",
       "      <td>35.362500</td>\n",
       "      <td>45.805556</td>\n",
       "      <td>25.075000</td>\n",
       "      <td>8.391304</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>14.685714</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>112.944444</td>\n",
       "      <td>109.888525</td>\n",
       "      <td>111.787500</td>\n",
       "      <td>109.519048</td>\n",
       "      <td>111.444000</td>\n",
       "      <td>3.428986</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>1.924915</td>\n",
       "      <td>18.139726</td>\n",
       "      <td>0.288048</td>\n",
       "      <td>0.742437</td>\n",
       "      <td>0.511557</td>\n",
       "      <td>14.982651</td>\n",
       "      <td>15.268182</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.572812</td>\n",
       "      <td>0.198667</td>\n",
       "      <td>102.812346</td>\n",
       "      <td>100.997619</td>\n",
       "      <td>84.165000</td>\n",
       "      <td>101.750000</td>\n",
       "      <td>0.521458</td>\n",
       "      <td>0.286170</td>\n",
       "      <td>0.536640</td>\n",
       "      <td>0.285737</td>\n",
       "      <td>0.152441</td>\n",
       "      <td>0.284823</td>\n",
       "      <td>18.169811</td>\n",
       "      <td>14.243902</td>\n",
       "      <td>14.700000</td>\n",
       "      <td>49.052632</td>\n",
       "      <td>17.838710</td>\n",
       "      <td>13.920000</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>48.866667</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>21.333333</td>\n",
       "      <td>0.692898</td>\n",
       "      <td>0.390643</td>\n",
       "      <td>0.568344</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.134053</td>\n",
       "      <td>0.174390</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>0.449036</td>\n",
       "      <td>0.527641</td>\n",
       "      <td>0.538358</td>\n",
       "      <td>0.869925</td>\n",
       "      <td>0.199889</td>\n",
       "      <td>0.614934</td>\n",
       "      <td>0.442143</td>\n",
       "      <td>18.085778</td>\n",
       "      <td>29.809524</td>\n",
       "      <td>59.620253</td>\n",
       "      <td>86.271429</td>\n",
       "      <td>422.838235</td>\n",
       "      <td>3.160494</td>\n",
       "      <td>2.290323</td>\n",
       "      <td>300.347826</td>\n",
       "      <td>18.562500</td>\n",
       "      <td>38.372093</td>\n",
       "      <td>0.502540</td>\n",
       "      <td>23.172414</td>\n",
       "      <td>52.782609</td>\n",
       "      <td>0.444414</td>\n",
       "      <td>17.338983</td>\n",
       "      <td>27.181818</td>\n",
       "      <td>0.654458</td>\n",
       "      <td>41.440000</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>0.470769</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.368042</td>\n",
       "      <td>18.789474</td>\n",
       "      <td>24.361111</td>\n",
       "      <td>0.793246</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>35.300000</td>\n",
       "      <td>45.714286</td>\n",
       "      <td>25.214286</td>\n",
       "      <td>8.305085</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>14.833333</td>\n",
       "      <td>21.552239</td>\n",
       "      <td>112.857143</td>\n",
       "      <td>110.094030</td>\n",
       "      <td>112.013846</td>\n",
       "      <td>109.662069</td>\n",
       "      <td>111.570000</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>3.432432</td>\n",
       "      <td>0.620092</td>\n",
       "      <td>1.937115</td>\n",
       "      <td>18.230882</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.742323</td>\n",
       "      <td>0.511323</td>\n",
       "      <td>15.112000</td>\n",
       "      <td>15.378947</td>\n",
       "      <td>0.539045</td>\n",
       "      <td>0.574839</td>\n",
       "      <td>0.198667</td>\n",
       "      <td>102.865000</td>\n",
       "      <td>101.051579</td>\n",
       "      <td>84.210000</td>\n",
       "      <td>101.808219</td>\n",
       "      <td>0.521478</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.537925</td>\n",
       "      <td>0.283859</td>\n",
       "      <td>0.151429</td>\n",
       "      <td>0.284407</td>\n",
       "      <td>18.072464</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>48.789474</td>\n",
       "      <td>17.965517</td>\n",
       "      <td>13.909091</td>\n",
       "      <td>14.222222</td>\n",
       "      <td>48.913580</td>\n",
       "      <td>5.459459</td>\n",
       "      <td>21.440000</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.397547</td>\n",
       "      <td>0.563667</td>\n",
       "      <td>0.138940</td>\n",
       "      <td>0.339055</td>\n",
       "      <td>0.134071</td>\n",
       "      <td>0.173775</td>\n",
       "      <td>0.166135</td>\n",
       "      <td>0.448820</td>\n",
       "      <td>0.536813</td>\n",
       "      <td>0.529737</td>\n",
       "      <td>0.860588</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.620092</td>\n",
       "      <td>0.436278</td>\n",
       "      <td>18.048065</td>\n",
       "      <td>29.862069</td>\n",
       "      <td>60.189189</td>\n",
       "      <td>86.939394</td>\n",
       "      <td>424.470588</td>\n",
       "      <td>3.277778</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>302.027397</td>\n",
       "      <td>18.529412</td>\n",
       "      <td>38.102041</td>\n",
       "      <td>0.507646</td>\n",
       "      <td>23.367347</td>\n",
       "      <td>53.087719</td>\n",
       "      <td>0.447935</td>\n",
       "      <td>17.302326</td>\n",
       "      <td>27.083333</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.610613e+09</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>127.650000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>126.600000</td>\n",
       "      <td>128.100000</td>\n",
       "      <td>43.900000</td>\n",
       "      <td>46.800000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>25.401000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0.651333</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>117.060000</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>94.580000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.505667</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.523000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.541556</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>0.308000</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>20.220000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>529.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.580500</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>0.562000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>128.700000</td>\n",
       "      <td>129.900000</td>\n",
       "      <td>128.700000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>32.400000</td>\n",
       "      <td>28.700000</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>3.630000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.634000</td>\n",
       "      <td>21.974000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>0.662000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>0.203000</td>\n",
       "      <td>116.780000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>96.670000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.548000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.333000</td>\n",
       "      <td>0.685000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>21.360000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>116.250000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>0.591000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            TEAM_ID      FGM_AVG      FGA_AVG   FG_PCT_AVG     FG3M_AVG  \\\n",
       "count  9.389000e+03  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean   1.610613e+09    39.950721    87.343146     0.458300    10.895364   \n",
       "std    7.758431e+00     2.261645     3.360753     0.019109     2.226503   \n",
       "min    1.610613e+09    25.000000    73.000000     0.298000     2.500000   \n",
       "25%    1.610613e+09    38.491525    85.197368     0.446537     9.357143   \n",
       "50%    1.610613e+09    39.906250    87.270833     0.458704    10.894737   \n",
       "75%    1.610613e+09    41.500000    89.609375     0.471194    12.260870   \n",
       "max    1.610613e+09    54.000000   109.000000     0.560000    19.000000   \n",
       "\n",
       "          FG3A_AVG  FG3_PCT_AVG      FTM_AVG      FTA_AVG   FT_PCT_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean     30.657866     0.354650    17.528373    22.802531     0.768676   \n",
       "std       5.778841     0.025109     2.184409     2.711463     0.037111   \n",
       "min      12.500000     0.156000     3.000000     8.000000     0.375000   \n",
       "25%      26.256410     0.342485    16.125000    21.126761     0.748000   \n",
       "50%      30.903846     0.354938    17.439024    22.692308     0.772222   \n",
       "75%      34.305556     0.367812    18.857143    24.421053     0.791826   \n",
       "max      50.000000     0.600000    33.000000    42.000000     1.000000   \n",
       "\n",
       "          OREB_AVG     DREB_AVG      REB_AVG      AST_AVG      STL_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean     10.260761    34.108642    44.369403    23.413651     7.737255   \n",
       "std       1.457246     2.100497     2.505444     2.506311     1.069637   \n",
       "min       2.000000    21.000000    28.000000    12.000000     3.000000   \n",
       "25%       9.294118    32.703704    42.750000    21.782609     7.000000   \n",
       "50%      10.190476    33.965517    44.227273    23.294118     7.666667   \n",
       "75%      11.064516    35.362500    45.805556    25.075000     8.391304   \n",
       "max      21.000000    47.000000    64.000000    38.000000    16.000000   \n",
       "\n",
       "           BLK_AVG       TO_AVG       PF_AVG      PTS_AVG  E_OFF_RATING_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000       9389.000000   \n",
       "mean      4.960646    13.898848    20.536168   108.325178        106.644110   \n",
       "std       0.915397     1.441165     1.837237     6.118891          4.602309   \n",
       "min       0.000000     6.000000    11.000000    83.000000         77.800000   \n",
       "25%       4.375000    13.000000    19.315789   103.916667        103.481579   \n",
       "50%       4.946429    13.772727    20.461538   108.560000        107.054167   \n",
       "75%       5.500000    14.685714    21.666667   112.944444        109.888525   \n",
       "max      12.000000    26.000000    32.000000   140.000000        127.650000   \n",
       "\n",
       "       OFF_RATING_AVG  E_DEF_RATING_AVG  DEF_RATING_AVG  E_NET_RATING_AVG  \\\n",
       "count     9389.000000       9389.000000     9389.000000       9389.000000   \n",
       "mean       108.512322        106.612944      108.467870          0.031195   \n",
       "std          4.598764          4.411436        4.454009          5.585157   \n",
       "min         77.600000         73.800000       76.000000        -32.400000   \n",
       "25%        105.264000        104.013043      105.788889         -3.220690   \n",
       "50%        108.800000        106.825000      108.656410         -0.040000   \n",
       "75%        111.787500        109.519048      111.444000          3.428986   \n",
       "max        129.000000        126.600000      128.100000         43.900000   \n",
       "\n",
       "       NET_RATING_AVG  AST_PCT_AVG  AST_TOV_AVG  AST_RATIO_AVG  OREB_PCT_AVG  \\\n",
       "count     9389.000000  9389.000000  9389.000000    9389.000000   9389.000000   \n",
       "mean         0.044373     0.585427     1.763443      17.220010      0.270852   \n",
       "std          5.403196     0.044955     0.264995       1.428845      0.028407   \n",
       "min        -28.900000     0.353000     0.500000       9.300000      0.108000   \n",
       "25%         -3.115190     0.557878     1.595833      16.329268      0.252333   \n",
       "50%         -0.041667     0.586375     1.761231      17.242254      0.270023   \n",
       "75%          3.400000     0.615000     1.924915      18.139726      0.288048   \n",
       "max         46.800000     0.816000     4.000000      25.300000      0.472000   \n",
       "\n",
       "       DREB_PCT_AVG  REB_PCT_AVG  E_TM_TOV_PCT_AVG  TM_TOV_PCT_AVG  \\\n",
       "count   9389.000000  9389.000000       9389.000000     9389.000000   \n",
       "mean       0.730040     0.500366         14.257367       14.514347   \n",
       "std        0.022456     0.017455          1.337508        1.368545   \n",
       "min        0.564000     0.366000          6.031000        6.100000   \n",
       "25%        0.717313     0.488979         13.461600       13.688235   \n",
       "50%        0.729650     0.499765         14.163259       14.433333   \n",
       "75%        0.742437     0.511557         14.982651       15.268182   \n",
       "max        0.898000     0.624000         25.401000       26.300000   \n",
       "\n",
       "       EFG_PCT_AVG   TS_PCT_AVG  E_USG_PCT_AVG   E_PACE_AVG     PACE_AVG  \\\n",
       "count  9389.000000  9389.000000    9389.000000  9389.000000  9389.000000   \n",
       "mean      0.520808     0.557239       0.198321   100.967119    99.200940   \n",
       "std       0.025021     0.023619       0.000629     2.957159     2.870400   \n",
       "min       0.345000     0.389000       0.190000    92.370000    90.500000   \n",
       "25%       0.504386     0.541622       0.197962    98.985797    97.250000   \n",
       "50%       0.522476     0.558023       0.198308   100.872157    99.097222   \n",
       "75%       0.536500     0.572812       0.198667   102.812346   100.997619   \n",
       "max       0.628000     0.651333       0.203000   117.060000   113.500000   \n",
       "\n",
       "       PACE_PER40_AVG     POSS_AVG      PIE_AVG  FTA_RATE_AVG  \\\n",
       "count     9389.000000  9389.000000  9389.000000   9389.000000   \n",
       "mean        82.667415    99.839112     0.500431      0.264465   \n",
       "std          2.391971     2.970476     0.034433      0.034429   \n",
       "min         75.420000    89.500000     0.282000      0.086000   \n",
       "25%         81.043000    97.916667     0.480460      0.241889   \n",
       "50%         82.581111    99.666667     0.500842      0.262709   \n",
       "75%         84.165000   101.750000     0.521458      0.286170   \n",
       "max         94.580000   119.000000     0.836000      0.505667   \n",
       "\n",
       "       OPP_EFG_PCT_AVG  OPP_FTA_RATE_AVG  OPP_TOV_PCT_AVG  OPP_OREB_PCT_AVG  \\\n",
       "count      9389.000000       9389.000000      9389.000000       9389.000000   \n",
       "mean          0.521188          0.265068         0.143086          0.271444   \n",
       "std           0.024017          0.034795         0.015040          0.022598   \n",
       "min           0.345000          0.097000         0.060000          0.102000   \n",
       "25%           0.507000          0.242333         0.132276          0.259000   \n",
       "50%           0.521886          0.264431         0.142900          0.271692   \n",
       "75%           0.536640          0.285737         0.152441          0.284823   \n",
       "max           0.644000          0.523000         0.250000          0.436000   \n",
       "\n",
       "       PTS_OFF_TOV_AVG  PTS_2ND_CHANCE_AVG   PTS_FB_AVG  PTS_PAINT_AVG  \\\n",
       "count      9389.000000         9389.000000  9389.000000    9389.000000   \n",
       "mean         16.816641           13.101210    12.973244      46.128921   \n",
       "std           2.178695            1.968392     3.139162       4.870947   \n",
       "min           5.500000            2.000000     0.000000      16.000000   \n",
       "25%          15.281250           11.971429    10.822222      42.882353   \n",
       "50%          16.636364           13.096154    12.545455      45.806452   \n",
       "75%          18.169811           14.243902    14.700000      49.052632   \n",
       "max          35.000000           36.000000    34.000000      78.000000   \n",
       "\n",
       "       OPP_PTS_OFF_TOV_AVG  OPP_PTS_2ND_CHANCE_AVG  OPP_PTS_FB_AVG  \\\n",
       "count          9389.000000             9389.000000     9389.000000   \n",
       "mean             16.705125               13.016007       12.913173   \n",
       "std               2.039210                1.648424        2.349627   \n",
       "min               5.000000                2.000000        0.000000   \n",
       "25%              15.333333               12.027778       11.486486   \n",
       "50%              16.600000               13.029412       12.766667   \n",
       "75%              17.838710               13.920000       14.285714   \n",
       "max              35.000000               31.000000       35.000000   \n",
       "\n",
       "       OPP_PTS_PAINT_AVG     BLKA_AVG      PFD_AVG  PCT_FGA_2PT_AVG  \\\n",
       "count        9389.000000  9389.000000  9389.000000      9389.000000   \n",
       "mean           45.985692     4.906743    20.461056         0.649118   \n",
       "std             4.341077     0.827331     1.703266         0.061578   \n",
       "min            26.000000     0.000000    11.000000         0.458444   \n",
       "25%            42.769231     4.392857    19.333333         0.609393   \n",
       "50%            46.000000     4.875000    20.283333         0.647324   \n",
       "75%            48.866667     5.363636    21.333333         0.692898   \n",
       "max            74.000000    12.000000    34.000000         0.847500   \n",
       "\n",
       "       PCT_FGA_3PT_AVG  PCT_PTS_2PT_AVG  PCT_PTS_2PT_MR_AVG  PCT_PTS_3PT_AVG  \\\n",
       "count      9389.000000      9389.000000         9389.000000      9389.000000   \n",
       "mean          0.350900         0.538865            0.112322         0.298986   \n",
       "std           0.061575         0.047618            0.046195         0.052331   \n",
       "min           0.152500         0.306000            0.000000         0.083000   \n",
       "25%           0.307119         0.507986            0.075794         0.265797   \n",
       "50%           0.352676         0.540949            0.106923         0.296429   \n",
       "75%           0.390643         0.568344            0.142700         0.333000   \n",
       "max           0.541556         0.755000            0.324000         0.475000   \n",
       "\n",
       "       PCT_PTS_FB_AVG  PCT_PTS_FT_AVG  PCT_PTS_OFF_TOV_AVG  PCT_PTS_PAINT_AVG  \\\n",
       "count     9389.000000     9389.000000          9389.000000        9389.000000   \n",
       "mean         0.119328        0.162131             0.155672           0.426546   \n",
       "std          0.026312        0.019709             0.019621           0.036464   \n",
       "min          0.000000        0.030000             0.048500           0.193000   \n",
       "25%          0.101174        0.149099             0.142563           0.403019   \n",
       "50%          0.116567        0.160042             0.154677           0.425254   \n",
       "75%          0.134053        0.174390             0.167429           0.449036   \n",
       "max          0.286000        0.308000             0.304500           0.653000   \n",
       "\n",
       "       PCT_AST_2PM_AVG  PCT_UAST_2PM_AVG  PCT_AST_3PM_AVG  PCT_UAST_3PM_AVG  \\\n",
       "count      9389.000000       9389.000000      9389.000000       9389.000000   \n",
       "mean          0.494028          0.505989         0.832192          0.167619   \n",
       "std           0.050945          0.050944         0.058487          0.058234   \n",
       "min           0.250000          0.176000         0.400000          0.000000   \n",
       "25%           0.461673          0.472406         0.800000          0.130000   \n",
       "50%           0.493792          0.506238         0.835060          0.164840   \n",
       "75%           0.527641          0.538358         0.869925          0.199889   \n",
       "max           0.824000          0.750000         1.000000          0.500000   \n",
       "\n",
       "       PCT_AST_FGM_AVG  PCT_UAST_FGM_AVG     DIST_AVG     ORBC_AVG  \\\n",
       "count      9389.000000       9389.000000  9389.000000  9389.000000   \n",
       "mean          0.585417          0.414591    17.654926    27.121276   \n",
       "std           0.044952          0.044952     0.600311     3.926415   \n",
       "min           0.353000          0.184000    13.588000    14.000000   \n",
       "25%           0.557857          0.385066    17.177234    24.085714   \n",
       "50%           0.586375          0.413644    17.731266    26.454545   \n",
       "75%           0.614934          0.442143    18.085778    29.809524   \n",
       "max           0.816000          0.647000    20.220000    55.000000   \n",
       "\n",
       "          DRBC_AVG      RBC_AVG     TCHS_AVG     SAST_AVG    FTAST_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean     57.473372    82.085239   413.099637     2.856512     1.799263   \n",
       "std       3.673363     6.495700    14.878582     0.538552     0.645953   \n",
       "min      42.000000    62.000000   314.000000     0.000000     0.000000   \n",
       "25%      54.923077    77.045455   402.543860     2.538462     1.269841   \n",
       "50%      57.055556    81.222222   412.887324     2.857143     1.733333   \n",
       "75%      59.620253    86.271429   422.838235     3.160494     2.290323   \n",
       "max      83.000000   128.000000   529.000000     8.000000     7.000000   \n",
       "\n",
       "          PASS_AVG     CFGM_AVG     CFGA_AVG  CFG_PCT_AVG     UFGM_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean    291.429850    17.706007    36.533672     0.485882    21.911756   \n",
       "std      13.962118     1.484364     2.871259     0.027736     1.908595   \n",
       "min     212.000000     9.000000    23.000000     0.273000    11.000000   \n",
       "25%     281.758621    16.800000    34.585366     0.468328    20.756410   \n",
       "50%     291.547619    17.645161    36.458333     0.486182    22.148148   \n",
       "75%     300.347826    18.562500    38.372093     0.502540    23.172414   \n",
       "max     414.000000    29.000000    58.000000     0.704000    35.000000   \n",
       "\n",
       "          UFGA_AVG  UFG_PCT_AVG     DFGM_AVG     DFGA_AVG  DFG_PCT_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean     50.277355     0.434635    16.115482    25.435499     0.633996   \n",
       "std       3.853690     0.018749     1.849484     2.629874     0.032017   \n",
       "min      29.000000     0.250000     5.000000    10.000000     0.250000   \n",
       "25%      47.683333     0.425394    14.807018    23.575758     0.614957   \n",
       "50%      50.936170     0.435455    16.064103    25.179487     0.632880   \n",
       "75%      52.782609     0.444414    17.338983    27.181818     0.654458   \n",
       "max      69.000000     0.580500    31.000000    42.000000     0.885000   \n",
       "\n",
       "       FGM_OPP_AVG  FGA_OPP_AVG  FG_PCT_OPP_AVG  FG3M_OPP_AVG  FG3A_OPP_AVG  \\\n",
       "count  9389.000000  9389.000000     9389.000000   9389.000000   9389.000000   \n",
       "mean     39.920989    87.282719        0.458284     11.122806     31.272134   \n",
       "std       2.219392     3.091154        0.020253      2.227526      5.669894   \n",
       "min      28.000000    75.000000        0.315000      0.000000      9.000000   \n",
       "25%      38.485714    85.250000        0.445270      9.632353     27.424242   \n",
       "50%      39.765625    87.200000        0.457788     11.125000     31.465753   \n",
       "75%      41.440000    89.250000        0.470769     12.555556     35.000000   \n",
       "max      53.000000   117.000000        0.572000     23.000000     57.000000   \n",
       "\n",
       "       FG3_PCT_OPP_AVG  FTM_OPP_AVG  FTA_OPP_AVG  FT_PCT_OPP_AVG  \\\n",
       "count      9389.000000  9389.000000  9389.000000     9389.000000   \n",
       "mean          0.354426    17.516533    22.793254        0.768955   \n",
       "std           0.025985     2.134604     2.696309        0.037859   \n",
       "min           0.000000     5.000000     9.000000        0.474000   \n",
       "25%           0.341476    16.117647    21.000000        0.746273   \n",
       "50%           0.354014    17.400000    22.640625        0.771846   \n",
       "75%           0.368042    18.789474    24.361111        0.793246   \n",
       "max           0.562000    33.000000    46.000000        0.967000   \n",
       "\n",
       "       OREB_OPP_AVG  DREB_OPP_AVG  REB_OPP_AVG  AST_OPP_AVG  STL_OPP_AVG  \\\n",
       "count   9389.000000   9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean      10.187010     34.150841    44.337851    23.651204     7.697442   \n",
       "std        1.402878      1.982376     2.434404     2.503055     1.038853   \n",
       "min        4.000000     23.000000    32.000000    10.000000     2.000000   \n",
       "25%        9.237288     32.922078    42.823529    22.000000     7.000000   \n",
       "50%       10.166667     34.014085    44.250000    23.508475     7.607143   \n",
       "75%       11.000000     35.300000    45.714286    25.214286     8.305085   \n",
       "max       18.000000     50.000000    62.000000    35.000000    18.000000   \n",
       "\n",
       "       BLK_OPP_AVG   TO_OPP_AVG   PF_OPP_AVG  PTS_OPP_AVG  \\\n",
       "count  9389.000000  9389.000000  9389.000000  9389.000000   \n",
       "mean      4.917986    13.999807    20.444239   108.481318   \n",
       "std       0.970182     1.483069     1.801275     6.055714   \n",
       "min       0.000000     7.000000    15.000000    76.000000   \n",
       "25%       4.321429    13.000000    19.225806   104.076923   \n",
       "50%       4.850000    13.869565    20.325000   108.633333   \n",
       "75%       5.454545    14.833333    21.552239   112.857143   \n",
       "max      15.000000    24.000000    34.000000   140.000000   \n",
       "\n",
       "       E_OFF_RATING_OPP_AVG  OFF_RATING_OPP_AVG  E_DEF_RATING_OPP_AVG  \\\n",
       "count           9389.000000         9389.000000           9389.000000   \n",
       "mean             106.690746          108.530697            106.648117   \n",
       "std                4.695365            4.656310              4.300101   \n",
       "min               73.800000           76.000000             80.550000   \n",
       "25%              103.361538          105.184615            104.075000   \n",
       "50%              106.803448          108.638000            106.938889   \n",
       "75%              110.094030          112.013846            109.662069   \n",
       "max              128.700000          129.900000            128.700000   \n",
       "\n",
       "       DEF_RATING_OPP_AVG  E_NET_RATING_OPP_AVG  NET_RATING_OPP_AVG  \\\n",
       "count         9389.000000           9389.000000         9389.000000   \n",
       "mean           108.499755              0.042616            0.030924   \n",
       "std              4.345303              5.575028            5.398525   \n",
       "min             82.100000            -43.900000          -46.800000   \n",
       "25%            105.914286             -3.183673           -2.900000   \n",
       "50%            108.687654              0.160345            0.109211   \n",
       "75%            111.570000              3.433333            3.432432   \n",
       "max            133.000000             32.400000           28.700000   \n",
       "\n",
       "       AST_PCT_OPP_AVG  AST_TOV_OPP_AVG  AST_RATIO_OPP_AVG  OREB_PCT_OPP_AVG  \\\n",
       "count      9389.000000      9389.000000        9389.000000       9389.000000   \n",
       "mean          0.591828         1.767798          17.362137          0.269481   \n",
       "std           0.044802         0.259489           1.462764          0.027856   \n",
       "min           0.324000         0.630000           8.100000          0.102000   \n",
       "25%           0.563750         1.595397          16.473333          0.252200   \n",
       "50%           0.590368         1.767037          17.307692          0.269750   \n",
       "75%           0.620092         1.937115          18.230882          0.286300   \n",
       "max           0.795000         3.630000          25.900000          0.436000   \n",
       "\n",
       "       DREB_PCT_OPP_AVG  REB_PCT_OPP_AVG  E_TM_TOV_PCT_OPP_AVG  \\\n",
       "count       9389.000000      9389.000000           9389.000000   \n",
       "mean           0.729839         0.499785             14.333184   \n",
       "std            0.022431         0.017438              1.307329   \n",
       "min            0.528000         0.376000              6.715000   \n",
       "25%            0.717533         0.488873             13.488681   \n",
       "50%            0.729469         0.499470             14.239639   \n",
       "75%            0.742323         0.511323             15.112000   \n",
       "max            0.925000         0.634000             21.974000   \n",
       "\n",
       "       TM_TOV_PCT_OPP_AVG  EFG_PCT_OPP_AVG  TS_PCT_OPP_AVG  E_USG_PCT_OPP_AVG  \\\n",
       "count         9389.000000      9389.000000     9389.000000        9389.000000   \n",
       "mean            14.586950         0.522150        0.558436           0.198310   \n",
       "std              1.339636         0.026817        0.025198           0.000660   \n",
       "min              6.700000         0.354000        0.392000           0.192000   \n",
       "25%             13.724000         0.504676        0.541769           0.197930   \n",
       "50%             14.504348         0.522071        0.557630           0.198302   \n",
       "75%             15.378947         0.539045        0.574839           0.198667   \n",
       "max             22.800000         0.662000        0.687000           0.203000   \n",
       "\n",
       "       E_PACE_OPP_AVG  PACE_OPP_AVG  PACE_PER40_OPP_AVG  POSS_OPP_AVG  \\\n",
       "count     9389.000000   9389.000000         9389.000000   9389.000000   \n",
       "mean       101.041930     99.290656           82.742170     99.969030   \n",
       "std          2.896079      2.806421            2.338670      2.906291   \n",
       "min         92.600000     91.115385           75.929231     90.750000   \n",
       "25%         99.058966     97.364643           81.137500     98.020833   \n",
       "50%        100.857222     99.090667           82.575410     99.727273   \n",
       "75%        102.865000    101.051579           84.210000    101.808219   \n",
       "max        116.780000    116.000000           96.670000    125.000000   \n",
       "\n",
       "       PIE_OPP_AVG  FTA_RATE_OPP_AVG  OPP_EFG_PCT_OPP_AVG  \\\n",
       "count  9389.000000       9389.000000          9389.000000   \n",
       "mean      0.499991          0.264378             0.521484   \n",
       "std       0.034425          0.033681             0.024006   \n",
       "min       0.164000          0.096000             0.357000   \n",
       "25%       0.480250          0.241474             0.507643   \n",
       "50%       0.501375          0.261592             0.522958   \n",
       "75%       0.521478          0.285000             0.537925   \n",
       "max       0.714000          0.511500             0.738000   \n",
       "\n",
       "       OPP_FTA_RATE_OPP_AVG  OPP_TOV_PCT_OPP_AVG  OPP_OREB_PCT_OPP_AVG  \\\n",
       "count           9389.000000          9389.000000           9389.000000   \n",
       "mean               0.263555             0.142966              0.271662   \n",
       "std                0.033457             0.014068              0.022440   \n",
       "min                0.086000             0.070000              0.070000   \n",
       "25%                0.241000             0.133442              0.258968   \n",
       "50%                0.262333             0.142217              0.271761   \n",
       "75%                0.283859             0.151429              0.284407   \n",
       "max                0.483000             0.254000              0.472000   \n",
       "\n",
       "       PTS_OFF_TOV_OPP_AVG  PTS_2ND_CHANCE_OPP_AVG  PTS_FB_OPP_AVG  \\\n",
       "count          9389.000000             9389.000000     9389.000000   \n",
       "mean             16.799497               12.911099       12.979119   \n",
       "std               2.043339                1.912790        3.058786   \n",
       "min               2.000000                1.000000        2.000000   \n",
       "25%              15.416667               11.763158       10.907895   \n",
       "50%              16.641026               12.933333       12.555556   \n",
       "75%              18.072464               14.000000       14.714286   \n",
       "max              38.000000               27.000000       36.000000   \n",
       "\n",
       "       PTS_PAINT_OPP_AVG  OPP_PTS_OFF_TOV_OPP_AVG  OPP_PTS_2ND_CHANCE_OPP_AVG  \\\n",
       "count        9389.000000              9389.000000                 9389.000000   \n",
       "mean           46.025711                16.880227                   12.985969   \n",
       "std             4.796126                 2.120340                    1.712098   \n",
       "min            22.000000                 4.000000                    2.000000   \n",
       "25%            43.090909                15.450000                   11.981481   \n",
       "50%            45.714286                16.761194                   13.019231   \n",
       "75%            48.789474                17.965517                   13.909091   \n",
       "max            74.000000                38.000000                   36.000000   \n",
       "\n",
       "       OPP_PTS_FB_OPP_AVG  OPP_PTS_PAINT_OPP_AVG  BLKA_OPP_AVG  PFD_OPP_AVG  \\\n",
       "count         9389.000000            9389.000000   9389.000000  9389.000000   \n",
       "mean            13.018055              46.114991      4.962133    20.530897   \n",
       "std              2.172588               4.167648      0.856550     1.725136   \n",
       "min              2.000000              16.000000      0.000000    15.000000   \n",
       "25%             11.714286              43.133333      4.433962    19.394366   \n",
       "50%             12.904762              46.200000      4.972973    20.333333   \n",
       "75%             14.222222              48.913580      5.459459    21.440000   \n",
       "max             34.000000              78.000000     12.000000    34.000000   \n",
       "\n",
       "       PCT_FGA_2PT_OPP_AVG  PCT_FGA_3PT_OPP_AVG  PCT_PTS_2PT_OPP_AVG  \\\n",
       "count          9389.000000          9389.000000          9389.000000   \n",
       "mean              0.641664             0.358355             0.533476   \n",
       "std               0.061270             0.061269             0.047673   \n",
       "min               0.459800             0.097000             0.296000   \n",
       "25%               0.602469             0.319000             0.501892   \n",
       "50%               0.639500             0.360500             0.533871   \n",
       "75%               0.681000             0.397547             0.563667   \n",
       "max               0.903000             0.540200             0.796000   \n",
       "\n",
       "       PCT_PTS_2PT_MR_OPP_AVG  PCT_PTS_3PT_OPP_AVG  PCT_PTS_FB_OPP_AVG  \\\n",
       "count             9389.000000          9389.000000         9389.000000   \n",
       "mean                 0.108304             0.304657            0.119181   \n",
       "std                  0.045070             0.051813            0.025337   \n",
       "min                  0.000000             0.000000            0.023000   \n",
       "25%                  0.072163             0.270941            0.102188   \n",
       "50%                  0.103500             0.306814            0.116608   \n",
       "75%                  0.138940             0.339055            0.134071   \n",
       "max                  0.320000             0.548000            0.333000   \n",
       "\n",
       "       PCT_PTS_FT_OPP_AVG  PCT_PTS_OFF_TOV_OPP_AVG  PCT_PTS_PAINT_OPP_AVG  \\\n",
       "count         9389.000000              9389.000000            9389.000000   \n",
       "mean             0.161848                 0.155461               0.425182   \n",
       "std              0.019125                 0.018680               0.037373   \n",
       "min              0.045000                 0.019000               0.204000   \n",
       "25%              0.148725                 0.143222               0.400000   \n",
       "50%              0.159673                 0.154188               0.423762   \n",
       "75%              0.173775                 0.166135               0.448820   \n",
       "max              0.312000                 0.333000               0.685000   \n",
       "\n",
       "       PCT_AST_2PM_OPP_AVG  PCT_UAST_2PM_OPP_AVG  PCT_AST_3PM_OPP_AVG  \\\n",
       "count          9389.000000           9389.000000          9389.000000   \n",
       "mean              0.503704              0.496313             0.823779   \n",
       "std               0.052792              0.052789             0.058257   \n",
       "min               0.238000              0.280000             0.000000   \n",
       "25%               0.470280              0.463200             0.793000   \n",
       "50%               0.500286              0.499735             0.827895   \n",
       "75%               0.536813              0.529737             0.860588   \n",
       "max               0.720000              0.762000             1.000000   \n",
       "\n",
       "       PCT_UAST_3PM_OPP_AVG  PCT_AST_FGM_OPP_AVG  PCT_UAST_FGM_OPP_AVG  \\\n",
       "count           9389.000000          9389.000000           9389.000000   \n",
       "mean               0.175874             0.591803              0.408206   \n",
       "std                0.057529             0.044787              0.044786   \n",
       "min                0.000000             0.324000              0.205000   \n",
       "25%                0.139273             0.563732              0.379919   \n",
       "50%                0.171970             0.590333              0.409687   \n",
       "75%                0.206600             0.620092              0.436278   \n",
       "max                0.571000             0.795000              0.676000   \n",
       "\n",
       "       DIST_OPP_AVG  ORBC_OPP_AVG  DRBC_OPP_AVG  RBC_OPP_AVG  TCHS_OPP_AVG  \\\n",
       "count   9389.000000   9389.000000   9389.000000  9389.000000   9389.000000   \n",
       "mean      17.613526     27.163113     57.837941    82.486533    414.177653   \n",
       "std        0.589525      4.028182      3.837692     6.799244     15.181280   \n",
       "min       14.338333     10.000000     38.000000    60.500000    339.000000   \n",
       "25%       17.151408     24.057692     55.215385    77.285714    403.638889   \n",
       "50%       17.664253     26.422222     57.269231    81.500000    414.413793   \n",
       "75%       18.048065     29.862069     60.189189    86.939394    424.470588   \n",
       "max       21.360000     52.000000     91.000000   116.250000    527.000000   \n",
       "\n",
       "       SAST_OPP_AVG  FTAST_OPP_AVG  PASS_OPP_AVG  CFGM_OPP_AVG  CFGA_OPP_AVG  \\\n",
       "count   9389.000000    9389.000000   9389.000000   9389.000000   9389.000000   \n",
       "mean       2.951684       1.824418    292.423365     17.660269     36.261218   \n",
       "std        0.554278       0.665246     14.268765      1.447222      2.964485   \n",
       "min        0.000000       0.000000    210.000000      7.000000     23.500000   \n",
       "25%        2.629630       1.277778    282.315789     16.767857     34.129032   \n",
       "50%        2.966667       1.720000    293.393939     17.645161     36.169014   \n",
       "75%        3.277778       2.360000    302.027397     18.529412     38.102041   \n",
       "max        7.000000       6.000000    375.000000     27.000000     52.500000   \n",
       "\n",
       "       CFG_PCT_OPP_AVG  UFGM_OPP_AVG  UFGA_OPP_AVG  UFG_PCT_OPP_AVG  \\\n",
       "count      9389.000000   9389.000000   9389.000000      9389.000000   \n",
       "mean          0.488873     22.173131     50.574464         0.437302   \n",
       "std           0.029228      1.922948      3.724062         0.019735   \n",
       "min           0.233000     12.000000     33.000000         0.254000   \n",
       "25%           0.470620     20.947368     47.931034         0.426906   \n",
       "50%           0.488679     22.351351     51.043478         0.437600   \n",
       "75%           0.507646     23.367347     53.087719         0.447935   \n",
       "max           0.714000     36.000000     87.000000         0.591000   \n",
       "\n",
       "       DFGM_OPP_AVG  DFGA_OPP_AVG  DFG_PCT_OPP_AVG   PLUS_MINUS  \n",
       "count   9389.000000   9389.000000      9389.000000  9389.000000  \n",
       "mean      16.089533     25.427158         0.633425    -0.172755  \n",
       "std        1.882069      2.703731         0.032145    14.357537  \n",
       "min        8.000000      9.000000         0.360000   -73.000000  \n",
       "25%       14.789474     23.600000         0.615800    -9.000000  \n",
       "50%       16.166667     25.300000         0.633667    -1.000000  \n",
       "75%       17.302326     27.083333         0.653000     9.000000  \n",
       "max       30.000000     47.000000         1.000000    53.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>FGM_AVG</th>\n",
       "      <th>FGA_AVG</th>\n",
       "      <th>FG_PCT_AVG</th>\n",
       "      <th>FG3M_AVG</th>\n",
       "      <th>FG3A_AVG</th>\n",
       "      <th>FG3_PCT_AVG</th>\n",
       "      <th>FTM_AVG</th>\n",
       "      <th>FTA_AVG</th>\n",
       "      <th>FT_PCT_AVG</th>\n",
       "      <th>OREB_AVG</th>\n",
       "      <th>DREB_AVG</th>\n",
       "      <th>REB_AVG</th>\n",
       "      <th>AST_AVG</th>\n",
       "      <th>STL_AVG</th>\n",
       "      <th>BLK_AVG</th>\n",
       "      <th>TO_AVG</th>\n",
       "      <th>PF_AVG</th>\n",
       "      <th>PTS_AVG</th>\n",
       "      <th>E_OFF_RATING_AVG</th>\n",
       "      <th>OFF_RATING_AVG</th>\n",
       "      <th>E_DEF_RATING_AVG</th>\n",
       "      <th>DEF_RATING_AVG</th>\n",
       "      <th>E_NET_RATING_AVG</th>\n",
       "      <th>NET_RATING_AVG</th>\n",
       "      <th>AST_PCT_AVG</th>\n",
       "      <th>AST_TOV_AVG</th>\n",
       "      <th>AST_RATIO_AVG</th>\n",
       "      <th>OREB_PCT_AVG</th>\n",
       "      <th>DREB_PCT_AVG</th>\n",
       "      <th>REB_PCT_AVG</th>\n",
       "      <th>E_TM_TOV_PCT_AVG</th>\n",
       "      <th>TM_TOV_PCT_AVG</th>\n",
       "      <th>EFG_PCT_AVG</th>\n",
       "      <th>TS_PCT_AVG</th>\n",
       "      <th>E_USG_PCT_AVG</th>\n",
       "      <th>E_PACE_AVG</th>\n",
       "      <th>PACE_AVG</th>\n",
       "      <th>PACE_PER40_AVG</th>\n",
       "      <th>POSS_AVG</th>\n",
       "      <th>PIE_AVG</th>\n",
       "      <th>FTA_RATE_AVG</th>\n",
       "      <th>OPP_EFG_PCT_AVG</th>\n",
       "      <th>OPP_FTA_RATE_AVG</th>\n",
       "      <th>OPP_TOV_PCT_AVG</th>\n",
       "      <th>OPP_OREB_PCT_AVG</th>\n",
       "      <th>PTS_OFF_TOV_AVG</th>\n",
       "      <th>PTS_2ND_CHANCE_AVG</th>\n",
       "      <th>PTS_FB_AVG</th>\n",
       "      <th>PTS_PAINT_AVG</th>\n",
       "      <th>OPP_PTS_OFF_TOV_AVG</th>\n",
       "      <th>OPP_PTS_2ND_CHANCE_AVG</th>\n",
       "      <th>OPP_PTS_FB_AVG</th>\n",
       "      <th>OPP_PTS_PAINT_AVG</th>\n",
       "      <th>BLKA_AVG</th>\n",
       "      <th>PFD_AVG</th>\n",
       "      <th>PCT_FGA_2PT_AVG</th>\n",
       "      <th>PCT_FGA_3PT_AVG</th>\n",
       "      <th>PCT_PTS_2PT_AVG</th>\n",
       "      <th>PCT_PTS_2PT_MR_AVG</th>\n",
       "      <th>PCT_PTS_3PT_AVG</th>\n",
       "      <th>PCT_PTS_FB_AVG</th>\n",
       "      <th>PCT_PTS_FT_AVG</th>\n",
       "      <th>PCT_PTS_OFF_TOV_AVG</th>\n",
       "      <th>PCT_PTS_PAINT_AVG</th>\n",
       "      <th>PCT_AST_2PM_AVG</th>\n",
       "      <th>PCT_UAST_2PM_AVG</th>\n",
       "      <th>PCT_AST_3PM_AVG</th>\n",
       "      <th>PCT_UAST_3PM_AVG</th>\n",
       "      <th>PCT_AST_FGM_AVG</th>\n",
       "      <th>PCT_UAST_FGM_AVG</th>\n",
       "      <th>DIST_AVG</th>\n",
       "      <th>ORBC_AVG</th>\n",
       "      <th>DRBC_AVG</th>\n",
       "      <th>RBC_AVG</th>\n",
       "      <th>TCHS_AVG</th>\n",
       "      <th>SAST_AVG</th>\n",
       "      <th>FTAST_AVG</th>\n",
       "      <th>PASS_AVG</th>\n",
       "      <th>CFGM_AVG</th>\n",
       "      <th>CFGA_AVG</th>\n",
       "      <th>CFG_PCT_AVG</th>\n",
       "      <th>UFGM_AVG</th>\n",
       "      <th>UFGA_AVG</th>\n",
       "      <th>UFG_PCT_AVG</th>\n",
       "      <th>DFGM_AVG</th>\n",
       "      <th>DFGA_AVG</th>\n",
       "      <th>DFG_PCT_AVG</th>\n",
       "      <th>OPP_TEAM_ID</th>\n",
       "      <th>OPP_TEAM_ABBREVIATION</th>\n",
       "      <th>FGM_OPP_AVG</th>\n",
       "      <th>FGA_OPP_AVG</th>\n",
       "      <th>FG_PCT_OPP_AVG</th>\n",
       "      <th>FG3M_OPP_AVG</th>\n",
       "      <th>FG3A_OPP_AVG</th>\n",
       "      <th>FG3_PCT_OPP_AVG</th>\n",
       "      <th>FTM_OPP_AVG</th>\n",
       "      <th>FTA_OPP_AVG</th>\n",
       "      <th>FT_PCT_OPP_AVG</th>\n",
       "      <th>OREB_OPP_AVG</th>\n",
       "      <th>DREB_OPP_AVG</th>\n",
       "      <th>REB_OPP_AVG</th>\n",
       "      <th>AST_OPP_AVG</th>\n",
       "      <th>STL_OPP_AVG</th>\n",
       "      <th>BLK_OPP_AVG</th>\n",
       "      <th>TO_OPP_AVG</th>\n",
       "      <th>PF_OPP_AVG</th>\n",
       "      <th>PTS_OPP_AVG</th>\n",
       "      <th>E_OFF_RATING_OPP_AVG</th>\n",
       "      <th>OFF_RATING_OPP_AVG</th>\n",
       "      <th>E_DEF_RATING_OPP_AVG</th>\n",
       "      <th>DEF_RATING_OPP_AVG</th>\n",
       "      <th>E_NET_RATING_OPP_AVG</th>\n",
       "      <th>NET_RATING_OPP_AVG</th>\n",
       "      <th>AST_PCT_OPP_AVG</th>\n",
       "      <th>AST_TOV_OPP_AVG</th>\n",
       "      <th>AST_RATIO_OPP_AVG</th>\n",
       "      <th>OREB_PCT_OPP_AVG</th>\n",
       "      <th>DREB_PCT_OPP_AVG</th>\n",
       "      <th>REB_PCT_OPP_AVG</th>\n",
       "      <th>E_TM_TOV_PCT_OPP_AVG</th>\n",
       "      <th>TM_TOV_PCT_OPP_AVG</th>\n",
       "      <th>EFG_PCT_OPP_AVG</th>\n",
       "      <th>TS_PCT_OPP_AVG</th>\n",
       "      <th>E_USG_PCT_OPP_AVG</th>\n",
       "      <th>E_PACE_OPP_AVG</th>\n",
       "      <th>PACE_OPP_AVG</th>\n",
       "      <th>PACE_PER40_OPP_AVG</th>\n",
       "      <th>POSS_OPP_AVG</th>\n",
       "      <th>PIE_OPP_AVG</th>\n",
       "      <th>FTA_RATE_OPP_AVG</th>\n",
       "      <th>OPP_EFG_PCT_OPP_AVG</th>\n",
       "      <th>OPP_FTA_RATE_OPP_AVG</th>\n",
       "      <th>OPP_TOV_PCT_OPP_AVG</th>\n",
       "      <th>OPP_OREB_PCT_OPP_AVG</th>\n",
       "      <th>PTS_OFF_TOV_OPP_AVG</th>\n",
       "      <th>PTS_2ND_CHANCE_OPP_AVG</th>\n",
       "      <th>PTS_FB_OPP_AVG</th>\n",
       "      <th>PTS_PAINT_OPP_AVG</th>\n",
       "      <th>OPP_PTS_OFF_TOV_OPP_AVG</th>\n",
       "      <th>OPP_PTS_2ND_CHANCE_OPP_AVG</th>\n",
       "      <th>OPP_PTS_FB_OPP_AVG</th>\n",
       "      <th>OPP_PTS_PAINT_OPP_AVG</th>\n",
       "      <th>BLKA_OPP_AVG</th>\n",
       "      <th>PFD_OPP_AVG</th>\n",
       "      <th>PCT_FGA_2PT_OPP_AVG</th>\n",
       "      <th>PCT_FGA_3PT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_2PT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_2PT_MR_OPP_AVG</th>\n",
       "      <th>PCT_PTS_3PT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_FB_OPP_AVG</th>\n",
       "      <th>PCT_PTS_FT_OPP_AVG</th>\n",
       "      <th>PCT_PTS_OFF_TOV_OPP_AVG</th>\n",
       "      <th>PCT_PTS_PAINT_OPP_AVG</th>\n",
       "      <th>PCT_AST_2PM_OPP_AVG</th>\n",
       "      <th>PCT_UAST_2PM_OPP_AVG</th>\n",
       "      <th>PCT_AST_3PM_OPP_AVG</th>\n",
       "      <th>PCT_UAST_3PM_OPP_AVG</th>\n",
       "      <th>PCT_AST_FGM_OPP_AVG</th>\n",
       "      <th>PCT_UAST_FGM_OPP_AVG</th>\n",
       "      <th>DIST_OPP_AVG</th>\n",
       "      <th>ORBC_OPP_AVG</th>\n",
       "      <th>DRBC_OPP_AVG</th>\n",
       "      <th>RBC_OPP_AVG</th>\n",
       "      <th>TCHS_OPP_AVG</th>\n",
       "      <th>SAST_OPP_AVG</th>\n",
       "      <th>FTAST_OPP_AVG</th>\n",
       "      <th>PASS_OPP_AVG</th>\n",
       "      <th>CFGM_OPP_AVG</th>\n",
       "      <th>CFGA_OPP_AVG</th>\n",
       "      <th>CFG_PCT_OPP_AVG</th>\n",
       "      <th>UFGM_OPP_AVG</th>\n",
       "      <th>UFGA_OPP_AVG</th>\n",
       "      <th>UFG_PCT_OPP_AVG</th>\n",
       "      <th>DFGM_OPP_AVG</th>\n",
       "      <th>DFGA_OPP_AVG</th>\n",
       "      <th>DFG_PCT_OPP_AVG</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0021500018</td>\n",
       "      <td>1610612754</td>\n",
       "      <td>IND</td>\n",
       "      <td>32.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.839</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>94.6</td>\n",
       "      <td>95.2</td>\n",
       "      <td>97.1</td>\n",
       "      <td>101.9</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.77</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.430</td>\n",
       "      <td>12.424</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.201</td>\n",
       "      <td>106.90</td>\n",
       "      <td>104.0</td>\n",
       "      <td>86.67</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.300</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.391</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.281</td>\n",
       "      <td>16.82</td>\n",
       "      <td>41.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.483</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1610612763</td>\n",
       "      <td>MEM</td>\n",
       "      <td>29.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.354</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>78.6</td>\n",
       "      <td>78.40</td>\n",
       "      <td>107.60</td>\n",
       "      <td>108.2</td>\n",
       "      <td>-29.00</td>\n",
       "      <td>-29.8</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.940</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.427</td>\n",
       "      <td>16.5490</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>0.4140</td>\n",
       "      <td>0.201</td>\n",
       "      <td>97.58</td>\n",
       "      <td>97.50</td>\n",
       "      <td>81.25</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.2680</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.4740</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.519</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>0.4830</td>\n",
       "      <td>16.650</td>\n",
       "      <td>32.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.581</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.434</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0021500019</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>NYK</td>\n",
       "      <td>42.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.452</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.829</td>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>124.5</td>\n",
       "      <td>97.4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.571</td>\n",
       "      <td>2.18</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.505</td>\n",
       "      <td>10.956</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.198</td>\n",
       "      <td>100.02</td>\n",
       "      <td>98.5</td>\n",
       "      <td>82.08</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.386</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.545</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.429</td>\n",
       "      <td>16.70</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.432</td>\n",
       "      <td>16.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>ATL</td>\n",
       "      <td>37.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.296</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>97.3</td>\n",
       "      <td>96.90</td>\n",
       "      <td>106.60</td>\n",
       "      <td>107.1</td>\n",
       "      <td>-9.30</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>1.470</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>0.404</td>\n",
       "      <td>15.5280</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.201</td>\n",
       "      <td>98.02</td>\n",
       "      <td>98.00</td>\n",
       "      <td>81.67</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.4620</td>\n",
       "      <td>0.1830</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.4440</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.517</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>16.670</td>\n",
       "      <td>26.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>22.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.449</td>\n",
       "      <td>13.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0021500020</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>LAC</td>\n",
       "      <td>42.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.316</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.677</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>108.1</td>\n",
       "      <td>108.8</td>\n",
       "      <td>96.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0.476</td>\n",
       "      <td>1.33</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.462</td>\n",
       "      <td>14.614</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.201</td>\n",
       "      <td>105.28</td>\n",
       "      <td>103.0</td>\n",
       "      <td>85.83</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.524</td>\n",
       "      <td>17.08</td>\n",
       "      <td>40.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.405</td>\n",
       "      <td>24.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.462</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.684</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>DAL</td>\n",
       "      <td>40.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.471</td>\n",
       "      <td>10.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>110.3</td>\n",
       "      <td>106.70</td>\n",
       "      <td>89.20</td>\n",
       "      <td>92.2</td>\n",
       "      <td>21.10</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.7170</td>\n",
       "      <td>0.475</td>\n",
       "      <td>7.9490</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>0.203</td>\n",
       "      <td>103.58</td>\n",
       "      <td>103.50</td>\n",
       "      <td>86.25</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>17.640</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>13.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.271</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.643</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0021500021</td>\n",
       "      <td>1610612748</td>\n",
       "      <td>MIA</td>\n",
       "      <td>36.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>111.5</td>\n",
       "      <td>109.5</td>\n",
       "      <td>99.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.77</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.500</td>\n",
       "      <td>13.943</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.202</td>\n",
       "      <td>94.00</td>\n",
       "      <td>94.5</td>\n",
       "      <td>78.75</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.236</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "      <td>17.32</td>\n",
       "      <td>27.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.441</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>CLE</td>\n",
       "      <td>39.5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.446</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.379</td>\n",
       "      <td>10.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>11.5</td>\n",
       "      <td>40.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>100.6</td>\n",
       "      <td>102.55</td>\n",
       "      <td>86.35</td>\n",
       "      <td>88.7</td>\n",
       "      <td>14.25</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.6955</td>\n",
       "      <td>1.945</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.541</td>\n",
       "      <td>15.0665</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.5085</td>\n",
       "      <td>0.5235</td>\n",
       "      <td>0.199</td>\n",
       "      <td>99.94</td>\n",
       "      <td>97.75</td>\n",
       "      <td>81.46</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>0.1915</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.6955</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>16.885</td>\n",
       "      <td>32.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>417.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>294.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.378</td>\n",
       "      <td>18.5</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.380</td>\n",
       "      <td>12.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0021500022</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>ORL</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.192</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>17.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.4</td>\n",
       "      <td>87.9</td>\n",
       "      <td>89.8</td>\n",
       "      <td>88.9</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.541</td>\n",
       "      <td>1.25</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.533</td>\n",
       "      <td>15.343</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.198</td>\n",
       "      <td>101.14</td>\n",
       "      <td>99.0</td>\n",
       "      <td>82.50</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.304</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.459</td>\n",
       "      <td>18.59</td>\n",
       "      <td>53.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.405</td>\n",
       "      <td>22.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1610612760</td>\n",
       "      <td>OKC</td>\n",
       "      <td>42.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.368</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.9550</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>109.80</td>\n",
       "      <td>101.20</td>\n",
       "      <td>103.9</td>\n",
       "      <td>6.80</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.110</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>0.7710</td>\n",
       "      <td>0.559</td>\n",
       "      <td>18.3260</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.5290</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>0.201</td>\n",
       "      <td>104.20</td>\n",
       "      <td>102.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.5090</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.2320</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.3930</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>16.790</td>\n",
       "      <td>32.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.553</td>\n",
       "      <td>16.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.410</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.621</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GAME_ID     TEAM_ID TEAM_ABBREVIATION  FGM_AVG  FGA_AVG  FG_PCT_AVG  \\\n",
       "34  0021500018  1610612754               IND     32.0     86.0       0.372   \n",
       "36  0021500019  1610612752               NYK     42.0     93.0       0.452   \n",
       "38  0021500020  1610612746               LAC     42.0     80.0       0.525   \n",
       "40  0021500021  1610612748               MIA     36.0     73.0       0.493   \n",
       "42  0021500022  1610612753               ORL     37.0    100.0       0.370   \n",
       "\n",
       "    FG3M_AVG  FG3A_AVG  FG3_PCT_AVG  FTM_AVG  FTA_AVG  FT_PCT_AVG  OREB_AVG  \\\n",
       "34       9.0      23.0        0.391     26.0     31.0       0.839       8.0   \n",
       "36       9.0      23.0        0.391     29.0     35.0       0.829      19.0   \n",
       "38       6.0      19.0        0.316     21.0     31.0       0.677       6.0   \n",
       "40      12.0      20.0        0.600     20.0     21.0       0.952       2.0   \n",
       "42       5.0      26.0        0.192      8.0     12.0       0.667      17.0   \n",
       "\n",
       "    DREB_AVG  REB_AVG  AST_AVG  STL_AVG  BLK_AVG  TO_AVG  PF_AVG  PTS_AVG  \\\n",
       "34      32.0     40.0     23.0     14.0      3.0    13.0    30.0     99.0   \n",
       "36      30.0     49.0     24.0     11.0      7.0    11.0    28.0    122.0   \n",
       "38      36.0     42.0     20.0      8.0      9.0    15.0    19.0    111.0   \n",
       "40      39.0     41.0     23.0      5.0      7.0    13.0    25.0    104.0   \n",
       "42      39.0     56.0     20.0      9.0      6.0    14.0    22.0     87.0   \n",
       "\n",
       "    E_OFF_RATING_AVG  OFF_RATING_AVG  E_DEF_RATING_AVG  DEF_RATING_AVG  \\\n",
       "34              94.6            95.2              97.1           101.9   \n",
       "36             121.5           124.5              97.4            98.0   \n",
       "38             108.1           108.8              96.4           100.0   \n",
       "40             111.5           109.5              99.2           100.0   \n",
       "42              83.4            87.9              89.8            88.9   \n",
       "\n",
       "    E_NET_RATING_AVG  NET_RATING_AVG  AST_PCT_AVG  AST_TOV_AVG  AST_RATIO_AVG  \\\n",
       "34              -2.5            -6.7        0.719         1.77           17.0   \n",
       "36              24.2            26.5        0.571         2.18           16.7   \n",
       "38              11.8             8.8        0.476         1.33           15.5   \n",
       "40              12.3             9.5        0.639         1.77           19.5   \n",
       "42              -6.4            -1.0        0.541         1.25           14.2   \n",
       "\n",
       "    OREB_PCT_AVG  DREB_PCT_AVG  REB_PCT_AVG  E_TM_TOV_PCT_AVG  TM_TOV_PCT_AVG  \\\n",
       "34         0.193         0.700        0.430            12.424            12.5   \n",
       "36         0.389         0.614        0.505            10.956            11.2   \n",
       "38         0.140         0.667        0.462            14.614            14.7   \n",
       "40         0.108         0.764        0.500            13.943            13.7   \n",
       "42         0.397         0.722        0.533            15.343            16.2   \n",
       "\n",
       "    EFG_PCT_AVG  TS_PCT_AVG  E_USG_PCT_AVG  E_PACE_AVG  PACE_AVG  \\\n",
       "34        0.424       0.497          0.201      106.90     104.0   \n",
       "36        0.500       0.563          0.198      100.02      98.5   \n",
       "38        0.563       0.593          0.201      105.28     103.0   \n",
       "40        0.575       0.632          0.202       94.00      94.5   \n",
       "42        0.395       0.413          0.198      101.14      99.0   \n",
       "\n",
       "    PACE_PER40_AVG  POSS_AVG  PIE_AVG  FTA_RATE_AVG  OPP_EFG_PCT_AVG  \\\n",
       "34           86.67     104.0    0.477         0.360            0.494   \n",
       "36           82.08      98.0    0.646         0.376            0.401   \n",
       "38           85.83     102.0    0.571         0.388            0.495   \n",
       "40           78.75      95.0    0.591         0.288            0.429   \n",
       "42           82.50      99.0    0.482         0.120            0.435   \n",
       "\n",
       "    OPP_FTA_RATE_AVG  OPP_TOV_PCT_AVG  OPP_OREB_PCT_AVG  PTS_OFF_TOV_AVG  \\\n",
       "34             0.488            0.192             0.300             18.0   \n",
       "36             0.360            0.181             0.386             25.0   \n",
       "38             0.191            0.167             0.333             22.0   \n",
       "40             0.345            0.095             0.236             11.0   \n",
       "42             0.298            0.184             0.304             15.0   \n",
       "\n",
       "    PTS_2ND_CHANCE_AVG  PTS_FB_AVG  PTS_PAINT_AVG  OPP_PTS_OFF_TOV_AVG  \\\n",
       "34                10.0        20.0           36.0                 12.0   \n",
       "36                17.0        19.0           50.0                 14.0   \n",
       "38                10.0         8.0           36.0                 17.0   \n",
       "40                 5.0        15.0           40.0                 19.0   \n",
       "42                18.0        12.0           46.0                 14.0   \n",
       "\n",
       "    OPP_PTS_2ND_CHANCE_AVG  OPP_PTS_FB_AVG  OPP_PTS_PAINT_AVG  BLKA_AVG  \\\n",
       "34                    22.0             9.0               46.0       2.0   \n",
       "36                    23.0             8.0               38.0       4.0   \n",
       "38                    14.0             8.0               48.0       3.0   \n",
       "40                    13.0             8.0               42.0       1.0   \n",
       "42                    12.0            17.0               30.0       9.0   \n",
       "\n",
       "    PFD_AVG  PCT_FGA_2PT_AVG  PCT_FGA_3PT_AVG  PCT_PTS_2PT_AVG  \\\n",
       "34     24.0            0.733            0.267            0.465   \n",
       "36     27.0            0.753            0.247            0.541   \n",
       "38     27.0            0.763            0.238            0.649   \n",
       "40     16.0            0.726            0.274            0.462   \n",
       "42     14.0            0.740            0.260            0.736   \n",
       "\n",
       "    PCT_PTS_2PT_MR_AVG  PCT_PTS_3PT_AVG  PCT_PTS_FB_AVG  PCT_PTS_FT_AVG  \\\n",
       "34               0.101            0.273           0.202           0.263   \n",
       "36               0.131            0.221           0.156           0.238   \n",
       "38               0.324            0.162           0.072           0.189   \n",
       "40               0.077            0.346           0.144           0.192   \n",
       "42               0.207            0.172           0.138           0.092   \n",
       "\n",
       "    PCT_PTS_OFF_TOV_AVG  PCT_PTS_PAINT_AVG  PCT_AST_2PM_AVG  PCT_UAST_2PM_AVG  \\\n",
       "34                0.182              0.364            0.609             0.391   \n",
       "36                0.205              0.410            0.455             0.545   \n",
       "38                0.198              0.324            0.417             0.583   \n",
       "40                0.106              0.385            0.500             0.500   \n",
       "42                0.172              0.529            0.500             0.500   \n",
       "\n",
       "    PCT_AST_3PM_AVG  PCT_UAST_3PM_AVG  PCT_AST_FGM_AVG  PCT_UAST_FGM_AVG  \\\n",
       "34            1.000             0.000            0.719             0.281   \n",
       "36            1.000             0.000            0.571             0.429   \n",
       "38            0.833             0.167            0.476             0.524   \n",
       "40            0.917             0.083            0.639             0.361   \n",
       "42            0.800             0.200            0.541             0.459   \n",
       "\n",
       "    DIST_AVG  ORBC_AVG  DRBC_AVG  RBC_AVG  TCHS_AVG  SAST_AVG  FTAST_AVG  \\\n",
       "34     16.82      41.0      73.0    108.0     421.0       2.0        0.0   \n",
       "36     16.70      40.0      57.0     95.0     517.0       6.0        5.0   \n",
       "38     17.08      40.0      57.0     92.0     422.0       2.0        0.0   \n",
       "40     17.32      27.0      58.0     85.0     424.0       4.0        0.0   \n",
       "42     18.59      53.0      67.0    116.0     458.0       2.0        1.0   \n",
       "\n",
       "    PASS_AVG  CFGM_AVG  CFGA_AVG  CFG_PCT_AVG  UFGM_AVG  UFGA_AVG  \\\n",
       "34     295.0      22.0      51.0        0.431      14.0      29.0   \n",
       "36     390.0      22.0      48.0        0.458      19.0      44.0   \n",
       "38     292.0      17.0      42.0        0.405      24.0      52.0   \n",
       "40     306.0      15.0      34.0        0.441      18.0      50.0   \n",
       "42     320.0      15.0      37.0        0.405      22.0      63.0   \n",
       "\n",
       "    UFG_PCT_AVG  DFGM_AVG  DFGA_AVG  DFG_PCT_AVG OPP_TEAM_ID  \\\n",
       "34        0.483      14.0      20.0        0.700  1610612763   \n",
       "36        0.432      16.0      33.0        0.485  1610612737   \n",
       "38        0.462      13.0      19.0        0.684  1610612742   \n",
       "40        0.360      17.0      23.0        0.739  1610612739   \n",
       "42        0.349       9.0      18.0        0.500  1610612760   \n",
       "\n",
       "   OPP_TEAM_ABBREVIATION  FGM_OPP_AVG  FGA_OPP_AVG  FG_PCT_OPP_AVG  \\\n",
       "34                   MEM         29.0         82.0           0.354   \n",
       "36                   ATL         37.0         82.0           0.451   \n",
       "38                   DAL         40.0         85.0           0.471   \n",
       "40                   CLE         39.5         89.0           0.446   \n",
       "42                   OKC         42.0         86.0           0.488   \n",
       "\n",
       "    FG3M_OPP_AVG  FG3A_OPP_AVG  FG3_PCT_OPP_AVG  FTM_OPP_AVG  FTA_OPP_AVG  \\\n",
       "34           2.0          16.0            0.125         16.0         22.0   \n",
       "36           8.0          27.0            0.296         12.0         15.0   \n",
       "38          10.0          21.0            0.476         21.0         31.0   \n",
       "40          11.0          29.0            0.379         10.5         17.0   \n",
       "42           7.0          19.0            0.368         21.0         22.0   \n",
       "\n",
       "    FT_PCT_OPP_AVG  OREB_OPP_AVG  DREB_OPP_AVG  REB_OPP_AVG  AST_OPP_AVG  \\\n",
       "34          0.7270          11.0          29.0         40.0         15.0   \n",
       "36          0.8000           7.0          33.0         40.0         22.0   \n",
       "38          0.6770           6.0          42.0         48.0         24.0   \n",
       "40          0.6175          11.5          40.5         52.0         27.5   \n",
       "42          0.9550          11.0          34.0         45.0         21.0   \n",
       "\n",
       "    STL_OPP_AVG  BLK_OPP_AVG  TO_OPP_AVG  PF_OPP_AVG  PTS_OPP_AVG  \\\n",
       "34          8.0          3.0        16.0        18.0         76.0   \n",
       "36          9.0          4.0        15.0        25.0         94.0   \n",
       "38          7.0          3.0         8.0        25.0        111.0   \n",
       "40          6.0          4.5        14.5        23.0        100.5   \n",
       "42          7.0          4.0        19.0        19.0        112.0   \n",
       "\n",
       "    E_OFF_RATING_OPP_AVG  OFF_RATING_OPP_AVG  E_DEF_RATING_OPP_AVG  \\\n",
       "34                  78.6               78.40                107.60   \n",
       "36                  97.3               96.90                106.60   \n",
       "38                 110.3              106.70                 89.20   \n",
       "40                 100.6              102.55                 86.35   \n",
       "42                 108.0              109.80                101.20   \n",
       "\n",
       "    DEF_RATING_OPP_AVG  E_NET_RATING_OPP_AVG  NET_RATING_OPP_AVG  \\\n",
       "34               108.2                -29.00               -29.8   \n",
       "36               107.1                 -9.30               -10.2   \n",
       "38                92.2                 21.10                14.5   \n",
       "40                88.7                 14.25                13.9   \n",
       "42               103.9                  6.80                 5.9   \n",
       "\n",
       "    AST_PCT_OPP_AVG  AST_TOV_OPP_AVG  AST_RATIO_OPP_AVG  OREB_PCT_OPP_AVG  \\\n",
       "34           0.5170            0.940               12.2            0.2140   \n",
       "36           0.5950            1.470               17.5            0.1630   \n",
       "38           0.6000            3.000               18.4            0.1300   \n",
       "40           0.6955            1.945               19.8            0.2975   \n",
       "42           0.5000            1.110               15.5            0.3330   \n",
       "\n",
       "    DREB_PCT_OPP_AVG  REB_PCT_OPP_AVG  E_TM_TOV_PCT_OPP_AVG  \\\n",
       "34            0.6810            0.427               16.5490   \n",
       "36            0.5560            0.404               15.5280   \n",
       "38            0.7170            0.475                7.9490   \n",
       "40            0.7725            0.541               15.0665   \n",
       "42            0.7710            0.559               18.3260   \n",
       "\n",
       "    TM_TOV_PCT_OPP_AVG  EFG_PCT_OPP_AVG  TS_PCT_OPP_AVG  E_USG_PCT_OPP_AVG  \\\n",
       "34                16.5           0.3660          0.4140              0.201   \n",
       "36                15.5           0.5000          0.5300              0.201   \n",
       "38                 7.7           0.5290          0.5630              0.203   \n",
       "40                15.3           0.5085          0.5235              0.199   \n",
       "42                18.6           0.5290          0.5850              0.201   \n",
       "\n",
       "    E_PACE_OPP_AVG  PACE_OPP_AVG  PACE_PER40_OPP_AVG  POSS_OPP_AVG  \\\n",
       "34           97.58         97.50               81.25          97.0   \n",
       "36           98.02         98.00               81.67          97.0   \n",
       "38          103.58        103.50               86.25         104.0   \n",
       "40           99.94         97.75               81.46          98.0   \n",
       "42          104.20        102.00               85.00         102.0   \n",
       "\n",
       "    PIE_OPP_AVG  FTA_RATE_OPP_AVG  OPP_EFG_PCT_OPP_AVG  OPP_FTA_RATE_OPP_AVG  \\\n",
       "34       0.3000            0.2680                0.565                 0.202   \n",
       "36       0.4620            0.1830                0.448                 0.271   \n",
       "38       0.6770            0.3650                0.425                 0.379   \n",
       "40       0.6105            0.1915                0.416                 0.266   \n",
       "42       0.5090            0.2560                0.511                 0.140   \n",
       "\n",
       "    OPP_TOV_PCT_OPP_AVG  OPP_OREB_PCT_OPP_AVG  PTS_OFF_TOV_OPP_AVG  \\\n",
       "34               0.1930                0.3190                 12.0   \n",
       "36               0.1510                0.4440                 19.0   \n",
       "38               0.1690                0.2830                 13.0   \n",
       "40               0.1455                0.2275                 19.0   \n",
       "42               0.1240                0.2290                 16.0   \n",
       "\n",
       "    PTS_2ND_CHANCE_OPP_AVG  PTS_FB_OPP_AVG  PTS_PAINT_OPP_AVG  \\\n",
       "34                     7.0             8.0               36.0   \n",
       "36                     6.0            15.0               42.0   \n",
       "38                     8.0            25.0               48.0   \n",
       "40                    13.0            19.5               45.0   \n",
       "42                    17.0             7.0               44.0   \n",
       "\n",
       "    OPP_PTS_OFF_TOV_OPP_AVG  OPP_PTS_2ND_CHANCE_OPP_AVG  OPP_PTS_FB_OPP_AVG  \\\n",
       "34                     23.0                        14.0                26.0   \n",
       "36                     20.0                        16.0                10.0   \n",
       "38                      4.0                        11.0                17.0   \n",
       "40                     12.5                        10.0                11.5   \n",
       "42                     13.0                        12.0                10.0   \n",
       "\n",
       "    OPP_PTS_PAINT_OPP_AVG  BLKA_OPP_AVG  PFD_OPP_AVG  PCT_FGA_2PT_OPP_AVG  \\\n",
       "34                   48.0           2.0         25.0                0.805   \n",
       "36                   36.0           3.0         15.0                0.671   \n",
       "38                   36.0           3.0         30.0                0.753   \n",
       "40                   34.0           6.5         20.0                0.673   \n",
       "42                   52.0           9.0         18.0                0.779   \n",
       "\n",
       "    PCT_FGA_3PT_OPP_AVG  PCT_PTS_2PT_OPP_AVG  PCT_PTS_2PT_MR_OPP_AVG  \\\n",
       "34                0.195               0.7110                  0.2370   \n",
       "36                0.329               0.6170                  0.1700   \n",
       "38                0.247               0.5410                  0.1080   \n",
       "40                0.327               0.5695                  0.1215   \n",
       "42                0.221               0.6250                  0.2320   \n",
       "\n",
       "    PCT_PTS_3PT_OPP_AVG  PCT_PTS_FB_OPP_AVG  PCT_PTS_FT_OPP_AVG  \\\n",
       "34                0.079               0.105              0.2110   \n",
       "36                0.255               0.160              0.1280   \n",
       "38                0.270               0.225              0.1890   \n",
       "40                0.326               0.191              0.1045   \n",
       "42                0.188               0.063              0.1880   \n",
       "\n",
       "    PCT_PTS_OFF_TOV_OPP_AVG  PCT_PTS_PAINT_OPP_AVG  PCT_AST_2PM_OPP_AVG  \\\n",
       "34                   0.1580                 0.4740                0.481   \n",
       "36                   0.2020                 0.4470                0.483   \n",
       "38                   0.1170                 0.4320                0.533   \n",
       "40                   0.1875                 0.4475                0.632   \n",
       "42                   0.1430                 0.3930                0.457   \n",
       "\n",
       "    PCT_UAST_2PM_OPP_AVG  PCT_AST_3PM_OPP_AVG  PCT_UAST_3PM_OPP_AVG  \\\n",
       "34                 0.519               1.0000                0.0000   \n",
       "36                 0.517               1.0000                0.0000   \n",
       "38                 0.467               0.8000                0.2000   \n",
       "40                 0.368               0.8675                0.1325   \n",
       "42                 0.543               0.7140                0.2860   \n",
       "\n",
       "    PCT_AST_FGM_OPP_AVG  PCT_UAST_FGM_OPP_AVG  DIST_OPP_AVG  ORBC_OPP_AVG  \\\n",
       "34               0.5170                0.4830        16.650          32.0   \n",
       "36               0.5950                0.4050        16.670          26.0   \n",
       "38               0.6000                0.4000        17.640          42.0   \n",
       "40               0.6955                0.3045        16.885          32.5   \n",
       "42               0.5000                0.5000        16.790          32.0   \n",
       "\n",
       "    DRBC_OPP_AVG  RBC_OPP_AVG  TCHS_OPP_AVG  SAST_OPP_AVG  FTAST_OPP_AVG  \\\n",
       "34          65.0         94.0         420.0           6.0            1.0   \n",
       "36          72.0         93.0         430.0           2.0            0.0   \n",
       "38          58.0         95.0         451.0           0.0            2.0   \n",
       "40          66.0         95.5         417.5           5.0            2.5   \n",
       "42          57.0         89.0         375.0           3.0            0.0   \n",
       "\n",
       "    PASS_OPP_AVG  CFGM_OPP_AVG  CFGA_OPP_AVG  CFG_PCT_OPP_AVG  UFGM_OPP_AVG  \\\n",
       "34         303.0          18.0          31.0            0.581          23.0   \n",
       "36         319.0          15.0          33.0            0.455          22.0   \n",
       "38         326.0          21.0          39.0            0.538          13.0   \n",
       "40         294.5          15.0          39.5            0.378          18.5   \n",
       "42         250.0          26.0          47.0            0.553          16.0   \n",
       "\n",
       "    UFGA_OPP_AVG  UFG_PCT_OPP_AVG  DFGM_OPP_AVG  DFGA_OPP_AVG  \\\n",
       "34          53.0            0.434          11.0          18.0   \n",
       "36          49.0            0.449          13.0          26.0   \n",
       "38          48.0            0.271          18.0          28.0   \n",
       "40          48.5            0.380          12.5          17.5   \n",
       "42          39.0            0.410          18.0          29.0   \n",
       "\n",
       "    DFG_PCT_OPP_AVG  PLUS_MINUS  \n",
       "34            0.611          -9  \n",
       "36            0.500         -11  \n",
       "38            0.643          16  \n",
       "40            0.663         -10  \n",
       "42            0.621          -3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.drop(columns=[\"GAME_ID\",\"TEAM_ID\",\"TEAM_ABBREVIATION\",\"OPP_TEAM_ID\",\"OPP_TEAM_ABBREVIATION\",\"PLUS_MINUS\"]).columns\n",
    "target = \"PLUS_MINUS\"\n",
    "X = df[cols].values\n",
    "y = df[target].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of xgboost:  210.3532276060485\n",
      "R2 of xgboost:  -0.009869448428897032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"MSE of xgboost: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 of xgboost: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.056304\n",
      "0:\tlearn: 14.2621086\ttotal: 178ms\tremaining: 2m 58s\n",
      "1:\tlearn: 14.1947176\ttotal: 214ms\tremaining: 1m 46s\n",
      "2:\tlearn: 14.1258260\ttotal: 252ms\tremaining: 1m 23s\n",
      "3:\tlearn: 14.0567839\ttotal: 301ms\tremaining: 1m 14s\n",
      "4:\tlearn: 14.0042597\ttotal: 351ms\tremaining: 1m 9s\n",
      "5:\tlearn: 13.9507126\ttotal: 389ms\tremaining: 1m 4s\n",
      "6:\tlearn: 13.9019447\ttotal: 447ms\tremaining: 1m 3s\n",
      "7:\tlearn: 13.8529162\ttotal: 531ms\tremaining: 1m 5s\n",
      "8:\tlearn: 13.8093295\ttotal: 589ms\tremaining: 1m 4s\n",
      "9:\tlearn: 13.7683502\ttotal: 629ms\tremaining: 1m 2s\n",
      "10:\tlearn: 13.7272353\ttotal: 666ms\tremaining: 59.9s\n",
      "11:\tlearn: 13.6913229\ttotal: 715ms\tremaining: 58.9s\n",
      "12:\tlearn: 13.6584035\ttotal: 753ms\tremaining: 57.2s\n",
      "13:\tlearn: 13.6250547\ttotal: 795ms\tremaining: 56s\n",
      "14:\tlearn: 13.5985370\ttotal: 832ms\tremaining: 54.6s\n",
      "15:\tlearn: 13.5697591\ttotal: 865ms\tremaining: 53.2s\n",
      "16:\tlearn: 13.5425570\ttotal: 903ms\tremaining: 52.2s\n",
      "17:\tlearn: 13.5194190\ttotal: 945ms\tremaining: 51.5s\n",
      "18:\tlearn: 13.4939939\ttotal: 983ms\tremaining: 50.7s\n",
      "19:\tlearn: 13.4726944\ttotal: 1.01s\tremaining: 49.4s\n",
      "20:\tlearn: 13.4507071\ttotal: 1.04s\tremaining: 48.4s\n",
      "21:\tlearn: 13.4320570\ttotal: 1.07s\tremaining: 47.7s\n",
      "22:\tlearn: 13.4157465\ttotal: 1.11s\tremaining: 47.3s\n",
      "23:\tlearn: 13.4004304\ttotal: 1.17s\tremaining: 47.4s\n",
      "24:\tlearn: 13.3825397\ttotal: 1.2s\tremaining: 46.9s\n",
      "25:\tlearn: 13.3658306\ttotal: 1.25s\tremaining: 46.8s\n",
      "26:\tlearn: 13.3501760\ttotal: 1.29s\tremaining: 46.7s\n",
      "27:\tlearn: 13.3357741\ttotal: 1.34s\tremaining: 46.6s\n",
      "28:\tlearn: 13.3221737\ttotal: 1.4s\tremaining: 46.9s\n",
      "29:\tlearn: 13.3085765\ttotal: 1.45s\tremaining: 46.8s\n",
      "30:\tlearn: 13.2940183\ttotal: 1.49s\tremaining: 46.5s\n",
      "31:\tlearn: 13.2810601\ttotal: 1.53s\tremaining: 46.2s\n",
      "32:\tlearn: 13.2674517\ttotal: 1.56s\tremaining: 45.9s\n",
      "33:\tlearn: 13.2559276\ttotal: 1.62s\tremaining: 46s\n",
      "34:\tlearn: 13.2434913\ttotal: 1.68s\tremaining: 46.3s\n",
      "35:\tlearn: 13.2314983\ttotal: 1.75s\tremaining: 46.8s\n",
      "36:\tlearn: 13.2203198\ttotal: 1.79s\tremaining: 46.5s\n",
      "37:\tlearn: 13.2092221\ttotal: 1.83s\tremaining: 46.3s\n",
      "38:\tlearn: 13.1964860\ttotal: 1.86s\tremaining: 45.8s\n",
      "39:\tlearn: 13.1858003\ttotal: 1.89s\tremaining: 45.3s\n",
      "40:\tlearn: 13.1736296\ttotal: 1.92s\tremaining: 45s\n",
      "41:\tlearn: 13.1650088\ttotal: 1.96s\tremaining: 44.6s\n",
      "42:\tlearn: 13.1534063\ttotal: 1.98s\tremaining: 44.2s\n",
      "43:\tlearn: 13.1442919\ttotal: 2.02s\tremaining: 43.8s\n",
      "44:\tlearn: 13.1351726\ttotal: 2.04s\tremaining: 43.4s\n",
      "45:\tlearn: 13.1267567\ttotal: 2.07s\tremaining: 43s\n",
      "46:\tlearn: 13.1185010\ttotal: 2.1s\tremaining: 42.6s\n",
      "47:\tlearn: 13.1097095\ttotal: 2.14s\tremaining: 42.4s\n",
      "48:\tlearn: 13.0995188\ttotal: 2.17s\tremaining: 42.1s\n",
      "49:\tlearn: 13.0892171\ttotal: 2.2s\tremaining: 41.7s\n",
      "50:\tlearn: 13.0812146\ttotal: 2.22s\tremaining: 41.4s\n",
      "51:\tlearn: 13.0716312\ttotal: 2.26s\tremaining: 41.1s\n",
      "52:\tlearn: 13.0596755\ttotal: 2.28s\tremaining: 40.8s\n",
      "53:\tlearn: 13.0522657\ttotal: 2.31s\tremaining: 40.5s\n",
      "54:\tlearn: 13.0428844\ttotal: 2.34s\tremaining: 40.3s\n",
      "55:\tlearn: 13.0340681\ttotal: 2.37s\tremaining: 40s\n",
      "56:\tlearn: 13.0226724\ttotal: 2.4s\tremaining: 39.7s\n",
      "57:\tlearn: 13.0162552\ttotal: 2.44s\tremaining: 39.6s\n",
      "58:\tlearn: 13.0062599\ttotal: 2.48s\tremaining: 39.5s\n",
      "59:\tlearn: 12.9944335\ttotal: 2.51s\tremaining: 39.3s\n",
      "60:\tlearn: 12.9851376\ttotal: 2.54s\tremaining: 39s\n",
      "61:\tlearn: 12.9792893\ttotal: 2.57s\tremaining: 38.9s\n",
      "62:\tlearn: 12.9702788\ttotal: 2.6s\tremaining: 38.6s\n",
      "63:\tlearn: 12.9624675\ttotal: 2.62s\tremaining: 38.4s\n",
      "64:\tlearn: 12.9563681\ttotal: 2.66s\tremaining: 38.2s\n",
      "65:\tlearn: 12.9484840\ttotal: 2.68s\tremaining: 38s\n",
      "66:\tlearn: 12.9389062\ttotal: 2.71s\tremaining: 37.7s\n",
      "67:\tlearn: 12.9324502\ttotal: 2.74s\tremaining: 37.5s\n",
      "68:\tlearn: 12.9233403\ttotal: 2.77s\tremaining: 37.3s\n",
      "69:\tlearn: 12.9152830\ttotal: 2.79s\tremaining: 37.1s\n",
      "70:\tlearn: 12.9075777\ttotal: 2.83s\tremaining: 37s\n",
      "71:\tlearn: 12.8994294\ttotal: 2.87s\tremaining: 37s\n",
      "72:\tlearn: 12.8930965\ttotal: 2.92s\tremaining: 37.1s\n",
      "73:\tlearn: 12.8862109\ttotal: 2.96s\tremaining: 37s\n",
      "74:\tlearn: 12.8790670\ttotal: 2.99s\tremaining: 36.8s\n",
      "75:\tlearn: 12.8706223\ttotal: 3.02s\tremaining: 36.7s\n",
      "76:\tlearn: 12.8627909\ttotal: 3.05s\tremaining: 36.6s\n",
      "77:\tlearn: 12.8573635\ttotal: 3.12s\tremaining: 36.9s\n",
      "78:\tlearn: 12.8490137\ttotal: 3.17s\tremaining: 36.9s\n",
      "79:\tlearn: 12.8418375\ttotal: 3.2s\tremaining: 36.8s\n",
      "80:\tlearn: 12.8335963\ttotal: 3.23s\tremaining: 36.7s\n",
      "81:\tlearn: 12.8261374\ttotal: 3.27s\tremaining: 36.6s\n",
      "82:\tlearn: 12.8210345\ttotal: 3.31s\tremaining: 36.6s\n",
      "83:\tlearn: 12.8152813\ttotal: 3.35s\tremaining: 36.5s\n",
      "84:\tlearn: 12.8095142\ttotal: 3.38s\tremaining: 36.4s\n",
      "85:\tlearn: 12.7993055\ttotal: 3.41s\tremaining: 36.3s\n",
      "86:\tlearn: 12.7910025\ttotal: 3.44s\tremaining: 36.1s\n",
      "87:\tlearn: 12.7831001\ttotal: 3.47s\tremaining: 36s\n",
      "88:\tlearn: 12.7775690\ttotal: 3.5s\tremaining: 35.8s\n",
      "89:\tlearn: 12.7678438\ttotal: 3.57s\tremaining: 36.1s\n",
      "90:\tlearn: 12.7603400\ttotal: 3.6s\tremaining: 36s\n",
      "91:\tlearn: 12.7503834\ttotal: 3.63s\tremaining: 35.8s\n",
      "92:\tlearn: 12.7423262\ttotal: 3.66s\tremaining: 35.7s\n",
      "93:\tlearn: 12.7356510\ttotal: 3.69s\tremaining: 35.6s\n",
      "94:\tlearn: 12.7283395\ttotal: 3.72s\tremaining: 35.5s\n",
      "95:\tlearn: 12.7240196\ttotal: 3.76s\tremaining: 35.4s\n",
      "96:\tlearn: 12.7167459\ttotal: 3.79s\tremaining: 35.3s\n",
      "97:\tlearn: 12.7080678\ttotal: 3.82s\tremaining: 35.2s\n",
      "98:\tlearn: 12.7036833\ttotal: 3.85s\tremaining: 35.1s\n",
      "99:\tlearn: 12.6974889\ttotal: 3.88s\tremaining: 35s\n",
      "100:\tlearn: 12.6916741\ttotal: 3.92s\tremaining: 34.9s\n",
      "101:\tlearn: 12.6854874\ttotal: 3.95s\tremaining: 34.8s\n",
      "102:\tlearn: 12.6766298\ttotal: 3.99s\tremaining: 34.7s\n",
      "103:\tlearn: 12.6716222\ttotal: 4.02s\tremaining: 34.6s\n",
      "104:\tlearn: 12.6664597\ttotal: 4.05s\tremaining: 34.6s\n",
      "105:\tlearn: 12.6594285\ttotal: 4.09s\tremaining: 34.5s\n",
      "106:\tlearn: 12.6541407\ttotal: 4.13s\tremaining: 34.4s\n",
      "107:\tlearn: 12.6504448\ttotal: 4.16s\tremaining: 34.3s\n",
      "108:\tlearn: 12.6444530\ttotal: 4.2s\tremaining: 34.3s\n",
      "109:\tlearn: 12.6359066\ttotal: 4.23s\tremaining: 34.2s\n",
      "110:\tlearn: 12.6300705\ttotal: 4.26s\tremaining: 34.1s\n",
      "111:\tlearn: 12.6228272\ttotal: 4.29s\tremaining: 34s\n",
      "112:\tlearn: 12.6133920\ttotal: 4.32s\tremaining: 33.9s\n",
      "113:\tlearn: 12.6053905\ttotal: 4.35s\tremaining: 33.8s\n",
      "114:\tlearn: 12.5992767\ttotal: 4.38s\tremaining: 33.7s\n",
      "115:\tlearn: 12.5899799\ttotal: 4.42s\tremaining: 33.7s\n",
      "116:\tlearn: 12.5858145\ttotal: 4.45s\tremaining: 33.6s\n",
      "117:\tlearn: 12.5783827\ttotal: 4.47s\tremaining: 33.4s\n",
      "118:\tlearn: 12.5726386\ttotal: 4.51s\tremaining: 33.4s\n",
      "119:\tlearn: 12.5673026\ttotal: 4.53s\tremaining: 33.2s\n",
      "120:\tlearn: 12.5602935\ttotal: 4.56s\tremaining: 33.1s\n",
      "121:\tlearn: 12.5541225\ttotal: 4.59s\tremaining: 33s\n",
      "122:\tlearn: 12.5453117\ttotal: 4.62s\tremaining: 32.9s\n",
      "123:\tlearn: 12.5395715\ttotal: 4.65s\tremaining: 32.8s\n",
      "124:\tlearn: 12.5300649\ttotal: 4.67s\tremaining: 32.7s\n",
      "125:\tlearn: 12.5224602\ttotal: 4.7s\tremaining: 32.6s\n",
      "126:\tlearn: 12.5170751\ttotal: 4.73s\tremaining: 32.5s\n",
      "127:\tlearn: 12.5115023\ttotal: 4.75s\tremaining: 32.4s\n",
      "128:\tlearn: 12.5063838\ttotal: 4.79s\tremaining: 32.3s\n",
      "129:\tlearn: 12.4990144\ttotal: 4.81s\tremaining: 32.2s\n",
      "130:\tlearn: 12.4954288\ttotal: 4.84s\tremaining: 32.1s\n",
      "131:\tlearn: 12.4899478\ttotal: 4.86s\tremaining: 32s\n",
      "132:\tlearn: 12.4813951\ttotal: 4.9s\tremaining: 31.9s\n",
      "133:\tlearn: 12.4719988\ttotal: 4.93s\tremaining: 31.8s\n",
      "134:\tlearn: 12.4658870\ttotal: 4.96s\tremaining: 31.8s\n",
      "135:\tlearn: 12.4603091\ttotal: 4.99s\tremaining: 31.7s\n",
      "136:\tlearn: 12.4558132\ttotal: 5.02s\tremaining: 31.6s\n",
      "137:\tlearn: 12.4520107\ttotal: 5.06s\tremaining: 31.6s\n",
      "138:\tlearn: 12.4433214\ttotal: 5.1s\tremaining: 31.6s\n",
      "139:\tlearn: 12.4388732\ttotal: 5.13s\tremaining: 31.5s\n",
      "140:\tlearn: 12.4324502\ttotal: 5.17s\tremaining: 31.5s\n",
      "141:\tlearn: 12.4286403\ttotal: 5.2s\tremaining: 31.4s\n",
      "142:\tlearn: 12.4247321\ttotal: 5.24s\tremaining: 31.4s\n",
      "143:\tlearn: 12.4197432\ttotal: 5.27s\tremaining: 31.3s\n",
      "144:\tlearn: 12.4142429\ttotal: 5.31s\tremaining: 31.3s\n",
      "145:\tlearn: 12.4065738\ttotal: 5.34s\tremaining: 31.3s\n",
      "146:\tlearn: 12.3967442\ttotal: 5.38s\tremaining: 31.2s\n",
      "147:\tlearn: 12.3918909\ttotal: 5.41s\tremaining: 31.2s\n",
      "148:\tlearn: 12.3850192\ttotal: 5.44s\tremaining: 31.1s\n",
      "149:\tlearn: 12.3791022\ttotal: 5.47s\tremaining: 31s\n",
      "150:\tlearn: 12.3720451\ttotal: 5.51s\tremaining: 31s\n",
      "151:\tlearn: 12.3631934\ttotal: 5.55s\tremaining: 30.9s\n",
      "152:\tlearn: 12.3579862\ttotal: 5.58s\tremaining: 30.9s\n",
      "153:\tlearn: 12.3512789\ttotal: 5.61s\tremaining: 30.8s\n",
      "154:\tlearn: 12.3448743\ttotal: 5.64s\tremaining: 30.8s\n",
      "155:\tlearn: 12.3376130\ttotal: 5.67s\tremaining: 30.7s\n",
      "156:\tlearn: 12.3327192\ttotal: 5.69s\tremaining: 30.6s\n",
      "157:\tlearn: 12.3257908\ttotal: 5.73s\tremaining: 30.5s\n",
      "158:\tlearn: 12.3198691\ttotal: 5.75s\tremaining: 30.4s\n",
      "159:\tlearn: 12.3131385\ttotal: 5.78s\tremaining: 30.4s\n",
      "160:\tlearn: 12.3044245\ttotal: 5.82s\tremaining: 30.3s\n",
      "161:\tlearn: 12.2960111\ttotal: 5.85s\tremaining: 30.3s\n",
      "162:\tlearn: 12.2907015\ttotal: 5.88s\tremaining: 30.2s\n",
      "163:\tlearn: 12.2855689\ttotal: 5.91s\tremaining: 30.1s\n",
      "164:\tlearn: 12.2797267\ttotal: 5.95s\tremaining: 30.1s\n",
      "165:\tlearn: 12.2715386\ttotal: 5.98s\tremaining: 30s\n",
      "166:\tlearn: 12.2664317\ttotal: 6.02s\tremaining: 30s\n",
      "167:\tlearn: 12.2606971\ttotal: 6.05s\tremaining: 30s\n",
      "168:\tlearn: 12.2545102\ttotal: 6.09s\tremaining: 29.9s\n",
      "169:\tlearn: 12.2480136\ttotal: 6.12s\tremaining: 29.9s\n",
      "170:\tlearn: 12.2428202\ttotal: 6.15s\tremaining: 29.8s\n",
      "171:\tlearn: 12.2336649\ttotal: 6.18s\tremaining: 29.8s\n",
      "172:\tlearn: 12.2245098\ttotal: 6.21s\tremaining: 29.7s\n",
      "173:\tlearn: 12.2190567\ttotal: 6.24s\tremaining: 29.6s\n",
      "174:\tlearn: 12.2119573\ttotal: 6.26s\tremaining: 29.5s\n",
      "175:\tlearn: 12.2079401\ttotal: 6.29s\tremaining: 29.4s\n",
      "176:\tlearn: 12.1991980\ttotal: 6.32s\tremaining: 29.4s\n",
      "177:\tlearn: 12.1909140\ttotal: 6.35s\tremaining: 29.3s\n",
      "178:\tlearn: 12.1831036\ttotal: 6.38s\tremaining: 29.2s\n",
      "179:\tlearn: 12.1768142\ttotal: 6.4s\tremaining: 29.2s\n",
      "180:\tlearn: 12.1710095\ttotal: 6.45s\tremaining: 29.2s\n",
      "181:\tlearn: 12.1612593\ttotal: 6.5s\tremaining: 29.2s\n",
      "182:\tlearn: 12.1538314\ttotal: 6.54s\tremaining: 29.2s\n",
      "183:\tlearn: 12.1443207\ttotal: 6.57s\tremaining: 29.2s\n",
      "184:\tlearn: 12.1393425\ttotal: 6.61s\tremaining: 29.1s\n",
      "185:\tlearn: 12.1312374\ttotal: 6.64s\tremaining: 29.1s\n",
      "186:\tlearn: 12.1241358\ttotal: 6.67s\tremaining: 29s\n",
      "187:\tlearn: 12.1169641\ttotal: 6.71s\tremaining: 29s\n",
      "188:\tlearn: 12.1105134\ttotal: 6.74s\tremaining: 28.9s\n",
      "189:\tlearn: 12.1032362\ttotal: 6.76s\tremaining: 28.8s\n",
      "190:\tlearn: 12.0949768\ttotal: 6.79s\tremaining: 28.7s\n",
      "191:\tlearn: 12.0884781\ttotal: 6.82s\tremaining: 28.7s\n",
      "192:\tlearn: 12.0817904\ttotal: 6.84s\tremaining: 28.6s\n",
      "193:\tlearn: 12.0717602\ttotal: 6.87s\tremaining: 28.6s\n",
      "194:\tlearn: 12.0635928\ttotal: 6.91s\tremaining: 28.5s\n",
      "195:\tlearn: 12.0552479\ttotal: 6.95s\tremaining: 28.5s\n",
      "196:\tlearn: 12.0486264\ttotal: 6.98s\tremaining: 28.5s\n",
      "197:\tlearn: 12.0420722\ttotal: 7.02s\tremaining: 28.4s\n",
      "198:\tlearn: 12.0346639\ttotal: 7.05s\tremaining: 28.4s\n",
      "199:\tlearn: 12.0272816\ttotal: 7.09s\tremaining: 28.3s\n",
      "200:\tlearn: 12.0196232\ttotal: 7.12s\tremaining: 28.3s\n",
      "201:\tlearn: 12.0110506\ttotal: 7.14s\tremaining: 28.2s\n",
      "202:\tlearn: 12.0033567\ttotal: 7.18s\tremaining: 28.2s\n",
      "203:\tlearn: 11.9934673\ttotal: 7.21s\tremaining: 28.1s\n",
      "204:\tlearn: 11.9856275\ttotal: 7.23s\tremaining: 28.1s\n",
      "205:\tlearn: 11.9734402\ttotal: 7.27s\tremaining: 28s\n",
      "206:\tlearn: 11.9663335\ttotal: 7.3s\tremaining: 28s\n",
      "207:\tlearn: 11.9591834\ttotal: 7.33s\tremaining: 27.9s\n",
      "208:\tlearn: 11.9512472\ttotal: 7.35s\tremaining: 27.8s\n",
      "209:\tlearn: 11.9448466\ttotal: 7.38s\tremaining: 27.8s\n",
      "210:\tlearn: 11.9344909\ttotal: 7.41s\tremaining: 27.7s\n",
      "211:\tlearn: 11.9225879\ttotal: 7.45s\tremaining: 27.7s\n",
      "212:\tlearn: 11.9173629\ttotal: 7.48s\tremaining: 27.6s\n",
      "213:\tlearn: 11.9101585\ttotal: 7.51s\tremaining: 27.6s\n",
      "214:\tlearn: 11.9046796\ttotal: 7.54s\tremaining: 27.5s\n",
      "215:\tlearn: 11.8962087\ttotal: 7.57s\tremaining: 27.5s\n",
      "216:\tlearn: 11.8883779\ttotal: 7.6s\tremaining: 27.4s\n",
      "217:\tlearn: 11.8795774\ttotal: 7.63s\tremaining: 27.4s\n",
      "218:\tlearn: 11.8722756\ttotal: 7.67s\tremaining: 27.4s\n",
      "219:\tlearn: 11.8639285\ttotal: 7.71s\tremaining: 27.4s\n",
      "220:\tlearn: 11.8542702\ttotal: 7.75s\tremaining: 27.3s\n",
      "221:\tlearn: 11.8437441\ttotal: 7.79s\tremaining: 27.3s\n",
      "222:\tlearn: 11.8359434\ttotal: 7.82s\tremaining: 27.3s\n",
      "223:\tlearn: 11.8283086\ttotal: 7.86s\tremaining: 27.2s\n",
      "224:\tlearn: 11.8193623\ttotal: 7.89s\tremaining: 27.2s\n",
      "225:\tlearn: 11.8113369\ttotal: 7.92s\tremaining: 27.1s\n",
      "226:\tlearn: 11.8021077\ttotal: 7.95s\tremaining: 27.1s\n",
      "227:\tlearn: 11.7932011\ttotal: 7.97s\tremaining: 27s\n",
      "228:\tlearn: 11.7871143\ttotal: 8s\tremaining: 26.9s\n",
      "229:\tlearn: 11.7829665\ttotal: 8.02s\tremaining: 26.9s\n",
      "230:\tlearn: 11.7758156\ttotal: 8.05s\tremaining: 26.8s\n",
      "231:\tlearn: 11.7702171\ttotal: 8.08s\tremaining: 26.8s\n",
      "232:\tlearn: 11.7620280\ttotal: 8.11s\tremaining: 26.7s\n",
      "233:\tlearn: 11.7546333\ttotal: 8.14s\tremaining: 26.6s\n",
      "234:\tlearn: 11.7484161\ttotal: 8.16s\tremaining: 26.6s\n",
      "235:\tlearn: 11.7385741\ttotal: 8.19s\tremaining: 26.5s\n",
      "236:\tlearn: 11.7320316\ttotal: 8.21s\tremaining: 26.4s\n",
      "237:\tlearn: 11.7260897\ttotal: 8.24s\tremaining: 26.4s\n",
      "238:\tlearn: 11.7177122\ttotal: 8.27s\tremaining: 26.3s\n",
      "239:\tlearn: 11.7117066\ttotal: 8.3s\tremaining: 26.3s\n",
      "240:\tlearn: 11.7031962\ttotal: 8.33s\tremaining: 26.2s\n",
      "241:\tlearn: 11.6941094\ttotal: 8.36s\tremaining: 26.2s\n",
      "242:\tlearn: 11.6853907\ttotal: 8.39s\tremaining: 26.1s\n",
      "243:\tlearn: 11.6777952\ttotal: 8.41s\tremaining: 26.1s\n",
      "244:\tlearn: 11.6703483\ttotal: 8.44s\tremaining: 26s\n",
      "245:\tlearn: 11.6621094\ttotal: 8.47s\tremaining: 26s\n",
      "246:\tlearn: 11.6553377\ttotal: 8.51s\tremaining: 25.9s\n",
      "247:\tlearn: 11.6477167\ttotal: 8.54s\tremaining: 25.9s\n",
      "248:\tlearn: 11.6400758\ttotal: 8.57s\tremaining: 25.8s\n",
      "249:\tlearn: 11.6320850\ttotal: 8.6s\tremaining: 25.8s\n",
      "250:\tlearn: 11.6248094\ttotal: 8.63s\tremaining: 25.8s\n",
      "251:\tlearn: 11.6175244\ttotal: 8.66s\tremaining: 25.7s\n",
      "252:\tlearn: 11.6063890\ttotal: 8.7s\tremaining: 25.7s\n",
      "253:\tlearn: 11.5959645\ttotal: 8.73s\tremaining: 25.7s\n",
      "254:\tlearn: 11.5851492\ttotal: 8.76s\tremaining: 25.6s\n",
      "255:\tlearn: 11.5786922\ttotal: 8.79s\tremaining: 25.6s\n",
      "256:\tlearn: 11.5715226\ttotal: 8.82s\tremaining: 25.5s\n",
      "257:\tlearn: 11.5658804\ttotal: 8.85s\tremaining: 25.5s\n",
      "258:\tlearn: 11.5537158\ttotal: 8.88s\tremaining: 25.4s\n",
      "259:\tlearn: 11.5442611\ttotal: 8.91s\tremaining: 25.4s\n",
      "260:\tlearn: 11.5358645\ttotal: 8.95s\tremaining: 25.3s\n",
      "261:\tlearn: 11.5282133\ttotal: 8.97s\tremaining: 25.3s\n",
      "262:\tlearn: 11.5207381\ttotal: 9s\tremaining: 25.2s\n",
      "263:\tlearn: 11.5102737\ttotal: 9.03s\tremaining: 25.2s\n",
      "264:\tlearn: 11.5021615\ttotal: 9.06s\tremaining: 25.1s\n",
      "265:\tlearn: 11.4937163\ttotal: 9.09s\tremaining: 25.1s\n",
      "266:\tlearn: 11.4842065\ttotal: 9.12s\tremaining: 25s\n",
      "267:\tlearn: 11.4734580\ttotal: 9.16s\tremaining: 25s\n",
      "268:\tlearn: 11.4643974\ttotal: 9.19s\tremaining: 25s\n",
      "269:\tlearn: 11.4543796\ttotal: 9.21s\tremaining: 24.9s\n",
      "270:\tlearn: 11.4474027\ttotal: 9.24s\tremaining: 24.9s\n",
      "271:\tlearn: 11.4383055\ttotal: 9.27s\tremaining: 24.8s\n",
      "272:\tlearn: 11.4307723\ttotal: 9.29s\tremaining: 24.8s\n",
      "273:\tlearn: 11.4248946\ttotal: 9.32s\tremaining: 24.7s\n",
      "274:\tlearn: 11.4179344\ttotal: 9.35s\tremaining: 24.6s\n",
      "275:\tlearn: 11.4121482\ttotal: 9.38s\tremaining: 24.6s\n",
      "276:\tlearn: 11.4039325\ttotal: 9.4s\tremaining: 24.5s\n",
      "277:\tlearn: 11.3966669\ttotal: 9.43s\tremaining: 24.5s\n",
      "278:\tlearn: 11.3881592\ttotal: 9.46s\tremaining: 24.4s\n",
      "279:\tlearn: 11.3821076\ttotal: 9.48s\tremaining: 24.4s\n",
      "280:\tlearn: 11.3743309\ttotal: 9.51s\tremaining: 24.3s\n",
      "281:\tlearn: 11.3664209\ttotal: 9.54s\tremaining: 24.3s\n",
      "282:\tlearn: 11.3614089\ttotal: 9.56s\tremaining: 24.2s\n",
      "283:\tlearn: 11.3544440\ttotal: 9.59s\tremaining: 24.2s\n",
      "284:\tlearn: 11.3462093\ttotal: 9.63s\tremaining: 24.2s\n",
      "285:\tlearn: 11.3397234\ttotal: 9.67s\tremaining: 24.1s\n",
      "286:\tlearn: 11.3326248\ttotal: 9.7s\tremaining: 24.1s\n",
      "287:\tlearn: 11.3236106\ttotal: 9.73s\tremaining: 24.1s\n",
      "288:\tlearn: 11.3170601\ttotal: 9.76s\tremaining: 24s\n",
      "289:\tlearn: 11.3106344\ttotal: 9.79s\tremaining: 24s\n",
      "290:\tlearn: 11.3007372\ttotal: 9.83s\tremaining: 23.9s\n",
      "291:\tlearn: 11.2943362\ttotal: 9.86s\tremaining: 23.9s\n",
      "292:\tlearn: 11.2885054\ttotal: 9.89s\tremaining: 23.9s\n",
      "293:\tlearn: 11.2818451\ttotal: 9.92s\tremaining: 23.8s\n",
      "294:\tlearn: 11.2760760\ttotal: 9.95s\tremaining: 23.8s\n",
      "295:\tlearn: 11.2661812\ttotal: 9.98s\tremaining: 23.7s\n",
      "296:\tlearn: 11.2589150\ttotal: 10s\tremaining: 23.7s\n",
      "297:\tlearn: 11.2506246\ttotal: 10.1s\tremaining: 23.7s\n",
      "298:\tlearn: 11.2431089\ttotal: 10.1s\tremaining: 23.7s\n",
      "299:\tlearn: 11.2358898\ttotal: 10.1s\tremaining: 23.6s\n",
      "300:\tlearn: 11.2278925\ttotal: 10.2s\tremaining: 23.6s\n",
      "301:\tlearn: 11.2218341\ttotal: 10.2s\tremaining: 23.6s\n",
      "302:\tlearn: 11.2146070\ttotal: 10.2s\tremaining: 23.5s\n",
      "303:\tlearn: 11.2101805\ttotal: 10.3s\tremaining: 23.5s\n",
      "304:\tlearn: 11.2021308\ttotal: 10.3s\tremaining: 23.5s\n",
      "305:\tlearn: 11.1947843\ttotal: 10.3s\tremaining: 23.4s\n",
      "306:\tlearn: 11.1862571\ttotal: 10.4s\tremaining: 23.4s\n",
      "307:\tlearn: 11.1784808\ttotal: 10.4s\tremaining: 23.4s\n",
      "308:\tlearn: 11.1719513\ttotal: 10.4s\tremaining: 23.4s\n",
      "309:\tlearn: 11.1652914\ttotal: 10.5s\tremaining: 23.3s\n",
      "310:\tlearn: 11.1576741\ttotal: 10.5s\tremaining: 23.3s\n",
      "311:\tlearn: 11.1472013\ttotal: 10.6s\tremaining: 23.3s\n",
      "312:\tlearn: 11.1408463\ttotal: 10.6s\tremaining: 23.3s\n",
      "313:\tlearn: 11.1332068\ttotal: 10.6s\tremaining: 23.3s\n",
      "314:\tlearn: 11.1256328\ttotal: 10.7s\tremaining: 23.2s\n",
      "315:\tlearn: 11.1187643\ttotal: 10.7s\tremaining: 23.2s\n",
      "316:\tlearn: 11.1096092\ttotal: 10.7s\tremaining: 23.1s\n",
      "317:\tlearn: 11.1019296\ttotal: 10.8s\tremaining: 23.1s\n",
      "318:\tlearn: 11.0933902\ttotal: 10.8s\tremaining: 23.1s\n",
      "319:\tlearn: 11.0867488\ttotal: 10.8s\tremaining: 23s\n",
      "320:\tlearn: 11.0798373\ttotal: 10.9s\tremaining: 23s\n",
      "321:\tlearn: 11.0740306\ttotal: 10.9s\tremaining: 23s\n",
      "322:\tlearn: 11.0661723\ttotal: 10.9s\tremaining: 22.9s\n",
      "323:\tlearn: 11.0568241\ttotal: 11s\tremaining: 22.9s\n",
      "324:\tlearn: 11.0500372\ttotal: 11s\tremaining: 22.8s\n",
      "325:\tlearn: 11.0423283\ttotal: 11s\tremaining: 22.8s\n",
      "326:\tlearn: 11.0339456\ttotal: 11.1s\tremaining: 22.8s\n",
      "327:\tlearn: 11.0288086\ttotal: 11.1s\tremaining: 22.7s\n",
      "328:\tlearn: 11.0209261\ttotal: 11.1s\tremaining: 22.7s\n",
      "329:\tlearn: 11.0146773\ttotal: 11.2s\tremaining: 22.7s\n",
      "330:\tlearn: 11.0066296\ttotal: 11.2s\tremaining: 22.7s\n",
      "331:\tlearn: 10.9996557\ttotal: 11.3s\tremaining: 22.6s\n",
      "332:\tlearn: 10.9939820\ttotal: 11.3s\tremaining: 22.6s\n",
      "333:\tlearn: 10.9868264\ttotal: 11.3s\tremaining: 22.6s\n",
      "334:\tlearn: 10.9802997\ttotal: 11.3s\tremaining: 22.5s\n",
      "335:\tlearn: 10.9709001\ttotal: 11.4s\tremaining: 22.5s\n",
      "336:\tlearn: 10.9643812\ttotal: 11.4s\tremaining: 22.5s\n",
      "337:\tlearn: 10.9588689\ttotal: 11.5s\tremaining: 22.4s\n",
      "338:\tlearn: 10.9517806\ttotal: 11.5s\tremaining: 22.4s\n",
      "339:\tlearn: 10.9466457\ttotal: 11.5s\tremaining: 22.4s\n",
      "340:\tlearn: 10.9377722\ttotal: 11.6s\tremaining: 22.3s\n",
      "341:\tlearn: 10.9299437\ttotal: 11.6s\tremaining: 22.3s\n",
      "342:\tlearn: 10.9214405\ttotal: 11.6s\tremaining: 22.3s\n",
      "343:\tlearn: 10.9163853\ttotal: 11.6s\tremaining: 22.2s\n",
      "344:\tlearn: 10.9096574\ttotal: 11.7s\tremaining: 22.2s\n",
      "345:\tlearn: 10.8987198\ttotal: 11.7s\tremaining: 22.1s\n",
      "346:\tlearn: 10.8918805\ttotal: 11.7s\tremaining: 22.1s\n",
      "347:\tlearn: 10.8825398\ttotal: 11.8s\tremaining: 22s\n",
      "348:\tlearn: 10.8758203\ttotal: 11.8s\tremaining: 22s\n",
      "349:\tlearn: 10.8705779\ttotal: 11.8s\tremaining: 22s\n",
      "350:\tlearn: 10.8613520\ttotal: 11.9s\tremaining: 21.9s\n",
      "351:\tlearn: 10.8540283\ttotal: 11.9s\tremaining: 21.9s\n",
      "352:\tlearn: 10.8440323\ttotal: 11.9s\tremaining: 21.8s\n",
      "353:\tlearn: 10.8373776\ttotal: 11.9s\tremaining: 21.8s\n",
      "354:\tlearn: 10.8312392\ttotal: 12s\tremaining: 21.8s\n",
      "355:\tlearn: 10.8259743\ttotal: 12s\tremaining: 21.7s\n",
      "356:\tlearn: 10.8196545\ttotal: 12s\tremaining: 21.7s\n",
      "357:\tlearn: 10.8138215\ttotal: 12.1s\tremaining: 21.6s\n",
      "358:\tlearn: 10.8068805\ttotal: 12.1s\tremaining: 21.6s\n",
      "359:\tlearn: 10.7991555\ttotal: 12.1s\tremaining: 21.6s\n",
      "360:\tlearn: 10.7928566\ttotal: 12.2s\tremaining: 21.5s\n",
      "361:\tlearn: 10.7881091\ttotal: 12.2s\tremaining: 21.5s\n",
      "362:\tlearn: 10.7824365\ttotal: 12.2s\tremaining: 21.4s\n",
      "363:\tlearn: 10.7767110\ttotal: 12.3s\tremaining: 21.4s\n",
      "364:\tlearn: 10.7682958\ttotal: 12.3s\tremaining: 21.4s\n",
      "365:\tlearn: 10.7623637\ttotal: 12.3s\tremaining: 21.3s\n",
      "366:\tlearn: 10.7529936\ttotal: 12.4s\tremaining: 21.3s\n",
      "367:\tlearn: 10.7477631\ttotal: 12.4s\tremaining: 21.3s\n",
      "368:\tlearn: 10.7407153\ttotal: 12.4s\tremaining: 21.2s\n",
      "369:\tlearn: 10.7361069\ttotal: 12.4s\tremaining: 21.2s\n",
      "370:\tlearn: 10.7309448\ttotal: 12.5s\tremaining: 21.2s\n",
      "371:\tlearn: 10.7266617\ttotal: 12.5s\tremaining: 21.1s\n",
      "372:\tlearn: 10.7195385\ttotal: 12.5s\tremaining: 21.1s\n",
      "373:\tlearn: 10.7139975\ttotal: 12.6s\tremaining: 21.1s\n",
      "374:\tlearn: 10.7077643\ttotal: 12.6s\tremaining: 21s\n",
      "375:\tlearn: 10.7001102\ttotal: 12.6s\tremaining: 21s\n",
      "376:\tlearn: 10.6945569\ttotal: 12.7s\tremaining: 21s\n",
      "377:\tlearn: 10.6885484\ttotal: 12.7s\tremaining: 20.9s\n",
      "378:\tlearn: 10.6820129\ttotal: 12.7s\tremaining: 20.9s\n",
      "379:\tlearn: 10.6723859\ttotal: 12.8s\tremaining: 20.8s\n",
      "380:\tlearn: 10.6666229\ttotal: 12.8s\tremaining: 20.8s\n",
      "381:\tlearn: 10.6617222\ttotal: 12.8s\tremaining: 20.8s\n",
      "382:\tlearn: 10.6534017\ttotal: 12.9s\tremaining: 20.7s\n",
      "383:\tlearn: 10.6472317\ttotal: 12.9s\tremaining: 20.7s\n",
      "384:\tlearn: 10.6424472\ttotal: 12.9s\tremaining: 20.7s\n",
      "385:\tlearn: 10.6349023\ttotal: 13s\tremaining: 20.6s\n",
      "386:\tlearn: 10.6293284\ttotal: 13s\tremaining: 20.6s\n",
      "387:\tlearn: 10.6228406\ttotal: 13s\tremaining: 20.6s\n",
      "388:\tlearn: 10.6175600\ttotal: 13.1s\tremaining: 20.5s\n",
      "389:\tlearn: 10.6095652\ttotal: 13.1s\tremaining: 20.5s\n",
      "390:\tlearn: 10.6037680\ttotal: 13.1s\tremaining: 20.5s\n",
      "391:\tlearn: 10.5972478\ttotal: 13.2s\tremaining: 20.4s\n",
      "392:\tlearn: 10.5910570\ttotal: 13.2s\tremaining: 20.4s\n",
      "393:\tlearn: 10.5855633\ttotal: 13.2s\tremaining: 20.4s\n",
      "394:\tlearn: 10.5775811\ttotal: 13.3s\tremaining: 20.3s\n",
      "395:\tlearn: 10.5717066\ttotal: 13.3s\tremaining: 20.3s\n",
      "396:\tlearn: 10.5651875\ttotal: 13.3s\tremaining: 20.2s\n",
      "397:\tlearn: 10.5593254\ttotal: 13.4s\tremaining: 20.2s\n",
      "398:\tlearn: 10.5542086\ttotal: 13.4s\tremaining: 20.2s\n",
      "399:\tlearn: 10.5456492\ttotal: 13.4s\tremaining: 20.1s\n",
      "400:\tlearn: 10.5355631\ttotal: 13.4s\tremaining: 20.1s\n",
      "401:\tlearn: 10.5289698\ttotal: 13.5s\tremaining: 20s\n",
      "402:\tlearn: 10.5239328\ttotal: 13.5s\tremaining: 20s\n",
      "403:\tlearn: 10.5176808\ttotal: 13.5s\tremaining: 19.9s\n",
      "404:\tlearn: 10.5095139\ttotal: 13.5s\tremaining: 19.9s\n",
      "405:\tlearn: 10.5029335\ttotal: 13.6s\tremaining: 19.9s\n",
      "406:\tlearn: 10.4959409\ttotal: 13.6s\tremaining: 19.8s\n",
      "407:\tlearn: 10.4887087\ttotal: 13.6s\tremaining: 19.8s\n",
      "408:\tlearn: 10.4822784\ttotal: 13.7s\tremaining: 19.7s\n",
      "409:\tlearn: 10.4766988\ttotal: 13.7s\tremaining: 19.7s\n",
      "410:\tlearn: 10.4698419\ttotal: 13.7s\tremaining: 19.7s\n",
      "411:\tlearn: 10.4637027\ttotal: 13.7s\tremaining: 19.6s\n",
      "412:\tlearn: 10.4570464\ttotal: 13.8s\tremaining: 19.6s\n",
      "413:\tlearn: 10.4499339\ttotal: 13.8s\tremaining: 19.5s\n",
      "414:\tlearn: 10.4451071\ttotal: 13.8s\tremaining: 19.5s\n",
      "415:\tlearn: 10.4389487\ttotal: 13.9s\tremaining: 19.4s\n",
      "416:\tlearn: 10.4329089\ttotal: 13.9s\tremaining: 19.4s\n",
      "417:\tlearn: 10.4232474\ttotal: 13.9s\tremaining: 19.4s\n",
      "418:\tlearn: 10.4156128\ttotal: 13.9s\tremaining: 19.3s\n",
      "419:\tlearn: 10.4096693\ttotal: 14s\tremaining: 19.3s\n",
      "420:\tlearn: 10.4046462\ttotal: 14s\tremaining: 19.2s\n",
      "421:\tlearn: 10.3984509\ttotal: 14s\tremaining: 19.2s\n",
      "422:\tlearn: 10.3915879\ttotal: 14s\tremaining: 19.2s\n",
      "423:\tlearn: 10.3842728\ttotal: 14.1s\tremaining: 19.1s\n",
      "424:\tlearn: 10.3771808\ttotal: 14.1s\tremaining: 19.1s\n",
      "425:\tlearn: 10.3709493\ttotal: 14.1s\tremaining: 19s\n",
      "426:\tlearn: 10.3645064\ttotal: 14.2s\tremaining: 19s\n",
      "427:\tlearn: 10.3582302\ttotal: 14.2s\tremaining: 19s\n",
      "428:\tlearn: 10.3520801\ttotal: 14.2s\tremaining: 18.9s\n",
      "429:\tlearn: 10.3447694\ttotal: 14.2s\tremaining: 18.9s\n",
      "430:\tlearn: 10.3372364\ttotal: 14.3s\tremaining: 18.8s\n",
      "431:\tlearn: 10.3318938\ttotal: 14.3s\tremaining: 18.8s\n",
      "432:\tlearn: 10.3232561\ttotal: 14.3s\tremaining: 18.8s\n",
      "433:\tlearn: 10.3186148\ttotal: 14.4s\tremaining: 18.7s\n",
      "434:\tlearn: 10.3139092\ttotal: 14.4s\tremaining: 18.7s\n",
      "435:\tlearn: 10.3047274\ttotal: 14.4s\tremaining: 18.6s\n",
      "436:\tlearn: 10.3001012\ttotal: 14.4s\tremaining: 18.6s\n",
      "437:\tlearn: 10.2928056\ttotal: 14.5s\tremaining: 18.6s\n",
      "438:\tlearn: 10.2880378\ttotal: 14.5s\tremaining: 18.5s\n",
      "439:\tlearn: 10.2813747\ttotal: 14.5s\tremaining: 18.5s\n",
      "440:\tlearn: 10.2759108\ttotal: 14.5s\tremaining: 18.4s\n",
      "441:\tlearn: 10.2703734\ttotal: 14.6s\tremaining: 18.4s\n",
      "442:\tlearn: 10.2655142\ttotal: 14.6s\tremaining: 18.4s\n",
      "443:\tlearn: 10.2589555\ttotal: 14.6s\tremaining: 18.3s\n",
      "444:\tlearn: 10.2518334\ttotal: 14.7s\tremaining: 18.3s\n",
      "445:\tlearn: 10.2453715\ttotal: 14.7s\tremaining: 18.2s\n",
      "446:\tlearn: 10.2364588\ttotal: 14.7s\tremaining: 18.2s\n",
      "447:\tlearn: 10.2282935\ttotal: 14.8s\tremaining: 18.2s\n",
      "448:\tlearn: 10.2190408\ttotal: 14.8s\tremaining: 18.1s\n",
      "449:\tlearn: 10.2102146\ttotal: 14.8s\tremaining: 18.1s\n",
      "450:\tlearn: 10.2041941\ttotal: 14.9s\tremaining: 18.1s\n",
      "451:\tlearn: 10.1964495\ttotal: 14.9s\tremaining: 18s\n",
      "452:\tlearn: 10.1875172\ttotal: 14.9s\tremaining: 18s\n",
      "453:\tlearn: 10.1800510\ttotal: 14.9s\tremaining: 18s\n",
      "454:\tlearn: 10.1723218\ttotal: 15s\tremaining: 17.9s\n",
      "455:\tlearn: 10.1663318\ttotal: 15s\tremaining: 17.9s\n",
      "456:\tlearn: 10.1598282\ttotal: 15s\tremaining: 17.9s\n",
      "457:\tlearn: 10.1521239\ttotal: 15.1s\tremaining: 17.8s\n",
      "458:\tlearn: 10.1459970\ttotal: 15.1s\tremaining: 17.8s\n",
      "459:\tlearn: 10.1410869\ttotal: 15.1s\tremaining: 17.8s\n",
      "460:\tlearn: 10.1335923\ttotal: 15.2s\tremaining: 17.8s\n",
      "461:\tlearn: 10.1276259\ttotal: 15.2s\tremaining: 17.7s\n",
      "462:\tlearn: 10.1214866\ttotal: 15.2s\tremaining: 17.7s\n",
      "463:\tlearn: 10.1133250\ttotal: 15.3s\tremaining: 17.6s\n",
      "464:\tlearn: 10.1085705\ttotal: 15.3s\tremaining: 17.6s\n",
      "465:\tlearn: 10.1006778\ttotal: 15.3s\tremaining: 17.6s\n",
      "466:\tlearn: 10.0927269\ttotal: 15.4s\tremaining: 17.5s\n",
      "467:\tlearn: 10.0874390\ttotal: 15.4s\tremaining: 17.5s\n",
      "468:\tlearn: 10.0805755\ttotal: 15.4s\tremaining: 17.5s\n",
      "469:\tlearn: 10.0750291\ttotal: 15.5s\tremaining: 17.4s\n",
      "470:\tlearn: 10.0695633\ttotal: 15.5s\tremaining: 17.4s\n",
      "471:\tlearn: 10.0632876\ttotal: 15.5s\tremaining: 17.4s\n",
      "472:\tlearn: 10.0580483\ttotal: 15.6s\tremaining: 17.3s\n",
      "473:\tlearn: 10.0529952\ttotal: 15.6s\tremaining: 17.3s\n",
      "474:\tlearn: 10.0471764\ttotal: 15.6s\tremaining: 17.3s\n",
      "475:\tlearn: 10.0407876\ttotal: 15.6s\tremaining: 17.2s\n",
      "476:\tlearn: 10.0350066\ttotal: 15.7s\tremaining: 17.2s\n",
      "477:\tlearn: 10.0257022\ttotal: 15.7s\tremaining: 17.1s\n",
      "478:\tlearn: 10.0188644\ttotal: 15.7s\tremaining: 17.1s\n",
      "479:\tlearn: 10.0143673\ttotal: 15.8s\tremaining: 17.1s\n",
      "480:\tlearn: 10.0098589\ttotal: 15.8s\tremaining: 17s\n",
      "481:\tlearn: 10.0039214\ttotal: 15.8s\tremaining: 17s\n",
      "482:\tlearn: 9.9976941\ttotal: 15.8s\tremaining: 16.9s\n",
      "483:\tlearn: 9.9918531\ttotal: 15.9s\tremaining: 16.9s\n",
      "484:\tlearn: 9.9851185\ttotal: 15.9s\tremaining: 16.9s\n",
      "485:\tlearn: 9.9766575\ttotal: 15.9s\tremaining: 16.8s\n",
      "486:\tlearn: 9.9701621\ttotal: 15.9s\tremaining: 16.8s\n",
      "487:\tlearn: 9.9630649\ttotal: 16s\tremaining: 16.8s\n",
      "488:\tlearn: 9.9573969\ttotal: 16s\tremaining: 16.7s\n",
      "489:\tlearn: 9.9512761\ttotal: 16s\tremaining: 16.7s\n",
      "490:\tlearn: 9.9468704\ttotal: 16.1s\tremaining: 16.6s\n",
      "491:\tlearn: 9.9378653\ttotal: 16.1s\tremaining: 16.6s\n",
      "492:\tlearn: 9.9317777\ttotal: 16.1s\tremaining: 16.6s\n",
      "493:\tlearn: 9.9241343\ttotal: 16.1s\tremaining: 16.5s\n",
      "494:\tlearn: 9.9170941\ttotal: 16.2s\tremaining: 16.5s\n",
      "495:\tlearn: 9.9094799\ttotal: 16.2s\tremaining: 16.4s\n",
      "496:\tlearn: 9.9039469\ttotal: 16.2s\tremaining: 16.4s\n",
      "497:\tlearn: 9.8971394\ttotal: 16.2s\tremaining: 16.4s\n",
      "498:\tlearn: 9.8916018\ttotal: 16.3s\tremaining: 16.3s\n",
      "499:\tlearn: 9.8888542\ttotal: 16.3s\tremaining: 16.3s\n",
      "500:\tlearn: 9.8820281\ttotal: 16.3s\tremaining: 16.3s\n",
      "501:\tlearn: 9.8765612\ttotal: 16.4s\tremaining: 16.2s\n",
      "502:\tlearn: 9.8722920\ttotal: 16.4s\tremaining: 16.2s\n",
      "503:\tlearn: 9.8668783\ttotal: 16.4s\tremaining: 16.2s\n",
      "504:\tlearn: 9.8605046\ttotal: 16.5s\tremaining: 16.1s\n",
      "505:\tlearn: 9.8549925\ttotal: 16.5s\tremaining: 16.1s\n",
      "506:\tlearn: 9.8515346\ttotal: 16.5s\tremaining: 16s\n",
      "507:\tlearn: 9.8447449\ttotal: 16.5s\tremaining: 16s\n",
      "508:\tlearn: 9.8394489\ttotal: 16.6s\tremaining: 16s\n",
      "509:\tlearn: 9.8362438\ttotal: 16.6s\tremaining: 15.9s\n",
      "510:\tlearn: 9.8291047\ttotal: 16.6s\tremaining: 15.9s\n",
      "511:\tlearn: 9.8240996\ttotal: 16.6s\tremaining: 15.9s\n",
      "512:\tlearn: 9.8171650\ttotal: 16.7s\tremaining: 15.8s\n",
      "513:\tlearn: 9.8132002\ttotal: 16.7s\tremaining: 15.8s\n",
      "514:\tlearn: 9.8093441\ttotal: 16.7s\tremaining: 15.7s\n",
      "515:\tlearn: 9.8027810\ttotal: 16.7s\tremaining: 15.7s\n",
      "516:\tlearn: 9.7957467\ttotal: 16.8s\tremaining: 15.7s\n",
      "517:\tlearn: 9.7900860\ttotal: 16.8s\tremaining: 15.6s\n",
      "518:\tlearn: 9.7873420\ttotal: 16.8s\tremaining: 15.6s\n",
      "519:\tlearn: 9.7814205\ttotal: 16.9s\tremaining: 15.6s\n",
      "520:\tlearn: 9.7773223\ttotal: 16.9s\tremaining: 15.5s\n",
      "521:\tlearn: 9.7731934\ttotal: 16.9s\tremaining: 15.5s\n",
      "522:\tlearn: 9.7664808\ttotal: 16.9s\tremaining: 15.4s\n",
      "523:\tlearn: 9.7604214\ttotal: 17s\tremaining: 15.4s\n",
      "524:\tlearn: 9.7555007\ttotal: 17s\tremaining: 15.4s\n",
      "525:\tlearn: 9.7498474\ttotal: 17s\tremaining: 15.4s\n",
      "526:\tlearn: 9.7442012\ttotal: 17.1s\tremaining: 15.3s\n",
      "527:\tlearn: 9.7390120\ttotal: 17.1s\tremaining: 15.3s\n",
      "528:\tlearn: 9.7322668\ttotal: 17.1s\tremaining: 15.3s\n",
      "529:\tlearn: 9.7259174\ttotal: 17.2s\tremaining: 15.2s\n",
      "530:\tlearn: 9.7201442\ttotal: 17.2s\tremaining: 15.2s\n",
      "531:\tlearn: 9.7147085\ttotal: 17.2s\tremaining: 15.2s\n",
      "532:\tlearn: 9.7065324\ttotal: 17.3s\tremaining: 15.1s\n",
      "533:\tlearn: 9.7000945\ttotal: 17.3s\tremaining: 15.1s\n",
      "534:\tlearn: 9.6948340\ttotal: 17.3s\tremaining: 15.1s\n",
      "535:\tlearn: 9.6882220\ttotal: 17.4s\tremaining: 15s\n",
      "536:\tlearn: 9.6835221\ttotal: 17.4s\tremaining: 15s\n",
      "537:\tlearn: 9.6795189\ttotal: 17.4s\tremaining: 15s\n",
      "538:\tlearn: 9.6742811\ttotal: 17.5s\tremaining: 14.9s\n",
      "539:\tlearn: 9.6708003\ttotal: 17.5s\tremaining: 14.9s\n",
      "540:\tlearn: 9.6650165\ttotal: 17.5s\tremaining: 14.9s\n",
      "541:\tlearn: 9.6582978\ttotal: 17.5s\tremaining: 14.8s\n",
      "542:\tlearn: 9.6528626\ttotal: 17.6s\tremaining: 14.8s\n",
      "543:\tlearn: 9.6462176\ttotal: 17.6s\tremaining: 14.8s\n",
      "544:\tlearn: 9.6424280\ttotal: 17.6s\tremaining: 14.7s\n",
      "545:\tlearn: 9.6390652\ttotal: 17.7s\tremaining: 14.7s\n",
      "546:\tlearn: 9.6342181\ttotal: 17.7s\tremaining: 14.7s\n",
      "547:\tlearn: 9.6282930\ttotal: 17.7s\tremaining: 14.6s\n",
      "548:\tlearn: 9.6239252\ttotal: 17.8s\tremaining: 14.6s\n",
      "549:\tlearn: 9.6193311\ttotal: 17.8s\tremaining: 14.6s\n",
      "550:\tlearn: 9.6143333\ttotal: 17.8s\tremaining: 14.5s\n",
      "551:\tlearn: 9.6066131\ttotal: 17.9s\tremaining: 14.5s\n",
      "552:\tlearn: 9.6002629\ttotal: 17.9s\tremaining: 14.5s\n",
      "553:\tlearn: 9.5940157\ttotal: 17.9s\tremaining: 14.4s\n",
      "554:\tlearn: 9.5892047\ttotal: 17.9s\tremaining: 14.4s\n",
      "555:\tlearn: 9.5858677\ttotal: 18s\tremaining: 14.3s\n",
      "556:\tlearn: 9.5809513\ttotal: 18s\tremaining: 14.3s\n",
      "557:\tlearn: 9.5747525\ttotal: 18s\tremaining: 14.3s\n",
      "558:\tlearn: 9.5687225\ttotal: 18s\tremaining: 14.2s\n",
      "559:\tlearn: 9.5616107\ttotal: 18.1s\tremaining: 14.2s\n",
      "560:\tlearn: 9.5535772\ttotal: 18.1s\tremaining: 14.2s\n",
      "561:\tlearn: 9.5457269\ttotal: 18.1s\tremaining: 14.1s\n",
      "562:\tlearn: 9.5415966\ttotal: 18.2s\tremaining: 14.1s\n",
      "563:\tlearn: 9.5352370\ttotal: 18.2s\tremaining: 14.1s\n",
      "564:\tlearn: 9.5304082\ttotal: 18.2s\tremaining: 14s\n",
      "565:\tlearn: 9.5273617\ttotal: 18.2s\tremaining: 14s\n",
      "566:\tlearn: 9.5224403\ttotal: 18.3s\tremaining: 13.9s\n",
      "567:\tlearn: 9.5176037\ttotal: 18.3s\tremaining: 13.9s\n",
      "568:\tlearn: 9.5112774\ttotal: 18.3s\tremaining: 13.9s\n",
      "569:\tlearn: 9.5064405\ttotal: 18.3s\tremaining: 13.8s\n",
      "570:\tlearn: 9.5013276\ttotal: 18.4s\tremaining: 13.8s\n",
      "571:\tlearn: 9.4947345\ttotal: 18.4s\tremaining: 13.8s\n",
      "572:\tlearn: 9.4902578\ttotal: 18.4s\tremaining: 13.7s\n",
      "573:\tlearn: 9.4848965\ttotal: 18.5s\tremaining: 13.7s\n",
      "574:\tlearn: 9.4807029\ttotal: 18.5s\tremaining: 13.7s\n",
      "575:\tlearn: 9.4744087\ttotal: 18.5s\tremaining: 13.6s\n",
      "576:\tlearn: 9.4695579\ttotal: 18.5s\tremaining: 13.6s\n",
      "577:\tlearn: 9.4635809\ttotal: 18.6s\tremaining: 13.6s\n",
      "578:\tlearn: 9.4571924\ttotal: 18.6s\tremaining: 13.5s\n",
      "579:\tlearn: 9.4512181\ttotal: 18.6s\tremaining: 13.5s\n",
      "580:\tlearn: 9.4449448\ttotal: 18.6s\tremaining: 13.4s\n",
      "581:\tlearn: 9.4399211\ttotal: 18.7s\tremaining: 13.4s\n",
      "582:\tlearn: 9.4339282\ttotal: 18.7s\tremaining: 13.4s\n",
      "583:\tlearn: 9.4280775\ttotal: 18.7s\tremaining: 13.3s\n",
      "584:\tlearn: 9.4230392\ttotal: 18.8s\tremaining: 13.3s\n",
      "585:\tlearn: 9.4176883\ttotal: 18.8s\tremaining: 13.3s\n",
      "586:\tlearn: 9.4105618\ttotal: 18.8s\tremaining: 13.2s\n",
      "587:\tlearn: 9.4067498\ttotal: 18.8s\tremaining: 13.2s\n",
      "588:\tlearn: 9.3998911\ttotal: 18.9s\tremaining: 13.2s\n",
      "589:\tlearn: 9.3924645\ttotal: 18.9s\tremaining: 13.1s\n",
      "590:\tlearn: 9.3875190\ttotal: 18.9s\tremaining: 13.1s\n",
      "591:\tlearn: 9.3802248\ttotal: 18.9s\tremaining: 13.1s\n",
      "592:\tlearn: 9.3739378\ttotal: 19s\tremaining: 13s\n",
      "593:\tlearn: 9.3700365\ttotal: 19s\tremaining: 13s\n",
      "594:\tlearn: 9.3662335\ttotal: 19s\tremaining: 13s\n",
      "595:\tlearn: 9.3609756\ttotal: 19.1s\tremaining: 12.9s\n",
      "596:\tlearn: 9.3541043\ttotal: 19.1s\tremaining: 12.9s\n",
      "597:\tlearn: 9.3482524\ttotal: 19.1s\tremaining: 12.9s\n",
      "598:\tlearn: 9.3448278\ttotal: 19.2s\tremaining: 12.8s\n",
      "599:\tlearn: 9.3410881\ttotal: 19.2s\tremaining: 12.8s\n",
      "600:\tlearn: 9.3376630\ttotal: 19.3s\tremaining: 12.8s\n",
      "601:\tlearn: 9.3328206\ttotal: 19.3s\tremaining: 12.8s\n",
      "602:\tlearn: 9.3286212\ttotal: 19.3s\tremaining: 12.7s\n",
      "603:\tlearn: 9.3242313\ttotal: 19.4s\tremaining: 12.7s\n",
      "604:\tlearn: 9.3183730\ttotal: 19.4s\tremaining: 12.7s\n",
      "605:\tlearn: 9.3134089\ttotal: 19.4s\tremaining: 12.6s\n",
      "606:\tlearn: 9.3086497\ttotal: 19.5s\tremaining: 12.6s\n",
      "607:\tlearn: 9.3043823\ttotal: 19.5s\tremaining: 12.6s\n",
      "608:\tlearn: 9.2979493\ttotal: 19.5s\tremaining: 12.5s\n",
      "609:\tlearn: 9.2908790\ttotal: 19.6s\tremaining: 12.5s\n",
      "610:\tlearn: 9.2851625\ttotal: 19.6s\tremaining: 12.5s\n",
      "611:\tlearn: 9.2804074\ttotal: 19.6s\tremaining: 12.4s\n",
      "612:\tlearn: 9.2765304\ttotal: 19.6s\tremaining: 12.4s\n",
      "613:\tlearn: 9.2709482\ttotal: 19.7s\tremaining: 12.4s\n",
      "614:\tlearn: 9.2648400\ttotal: 19.7s\tremaining: 12.3s\n",
      "615:\tlearn: 9.2588890\ttotal: 19.7s\tremaining: 12.3s\n",
      "616:\tlearn: 9.2531391\ttotal: 19.8s\tremaining: 12.3s\n",
      "617:\tlearn: 9.2459594\ttotal: 19.8s\tremaining: 12.2s\n",
      "618:\tlearn: 9.2409502\ttotal: 19.8s\tremaining: 12.2s\n",
      "619:\tlearn: 9.2347647\ttotal: 19.9s\tremaining: 12.2s\n",
      "620:\tlearn: 9.2294987\ttotal: 19.9s\tremaining: 12.1s\n",
      "621:\tlearn: 9.2255322\ttotal: 19.9s\tremaining: 12.1s\n",
      "622:\tlearn: 9.2186369\ttotal: 20s\tremaining: 12.1s\n",
      "623:\tlearn: 9.2126958\ttotal: 20s\tremaining: 12s\n",
      "624:\tlearn: 9.2089245\ttotal: 20s\tremaining: 12s\n",
      "625:\tlearn: 9.2027609\ttotal: 20s\tremaining: 12s\n",
      "626:\tlearn: 9.1966008\ttotal: 20.1s\tremaining: 11.9s\n",
      "627:\tlearn: 9.1913407\ttotal: 20.1s\tremaining: 11.9s\n",
      "628:\tlearn: 9.1857266\ttotal: 20.1s\tremaining: 11.9s\n",
      "629:\tlearn: 9.1804626\ttotal: 20.2s\tremaining: 11.9s\n",
      "630:\tlearn: 9.1744935\ttotal: 20.2s\tremaining: 11.8s\n",
      "631:\tlearn: 9.1707193\ttotal: 20.3s\tremaining: 11.8s\n",
      "632:\tlearn: 9.1657371\ttotal: 20.3s\tremaining: 11.8s\n",
      "633:\tlearn: 9.1592139\ttotal: 20.3s\tremaining: 11.7s\n",
      "634:\tlearn: 9.1526473\ttotal: 20.4s\tremaining: 11.7s\n",
      "635:\tlearn: 9.1455336\ttotal: 20.4s\tremaining: 11.7s\n",
      "636:\tlearn: 9.1413956\ttotal: 20.4s\tremaining: 11.6s\n",
      "637:\tlearn: 9.1350607\ttotal: 20.4s\tremaining: 11.6s\n",
      "638:\tlearn: 9.1302540\ttotal: 20.5s\tremaining: 11.6s\n",
      "639:\tlearn: 9.1247508\ttotal: 20.5s\tremaining: 11.5s\n",
      "640:\tlearn: 9.1203512\ttotal: 20.5s\tremaining: 11.5s\n",
      "641:\tlearn: 9.1153404\ttotal: 20.6s\tremaining: 11.5s\n",
      "642:\tlearn: 9.1102044\ttotal: 20.6s\tremaining: 11.4s\n",
      "643:\tlearn: 9.1060875\ttotal: 20.6s\tremaining: 11.4s\n",
      "644:\tlearn: 9.0990808\ttotal: 20.6s\tremaining: 11.4s\n",
      "645:\tlearn: 9.0963014\ttotal: 20.7s\tremaining: 11.3s\n",
      "646:\tlearn: 9.0915724\ttotal: 20.7s\tremaining: 11.3s\n",
      "647:\tlearn: 9.0858117\ttotal: 20.7s\tremaining: 11.3s\n",
      "648:\tlearn: 9.0805831\ttotal: 20.8s\tremaining: 11.2s\n",
      "649:\tlearn: 9.0760026\ttotal: 20.8s\tremaining: 11.2s\n",
      "650:\tlearn: 9.0712028\ttotal: 20.8s\tremaining: 11.2s\n",
      "651:\tlearn: 9.0673534\ttotal: 20.8s\tremaining: 11.1s\n",
      "652:\tlearn: 9.0609769\ttotal: 20.9s\tremaining: 11.1s\n",
      "653:\tlearn: 9.0559481\ttotal: 20.9s\tremaining: 11.1s\n",
      "654:\tlearn: 9.0512569\ttotal: 20.9s\tremaining: 11s\n",
      "655:\tlearn: 9.0457762\ttotal: 20.9s\tremaining: 11s\n",
      "656:\tlearn: 9.0386764\ttotal: 21s\tremaining: 10.9s\n",
      "657:\tlearn: 9.0327677\ttotal: 21s\tremaining: 10.9s\n",
      "658:\tlearn: 9.0272311\ttotal: 21s\tremaining: 10.9s\n",
      "659:\tlearn: 9.0213025\ttotal: 21.1s\tremaining: 10.8s\n",
      "660:\tlearn: 9.0140487\ttotal: 21.1s\tremaining: 10.8s\n",
      "661:\tlearn: 9.0073155\ttotal: 21.1s\tremaining: 10.8s\n",
      "662:\tlearn: 9.0021159\ttotal: 21.1s\tremaining: 10.7s\n",
      "663:\tlearn: 8.9957205\ttotal: 21.2s\tremaining: 10.7s\n",
      "664:\tlearn: 8.9917867\ttotal: 21.2s\tremaining: 10.7s\n",
      "665:\tlearn: 8.9847668\ttotal: 21.2s\tremaining: 10.6s\n",
      "666:\tlearn: 8.9796728\ttotal: 21.2s\tremaining: 10.6s\n",
      "667:\tlearn: 8.9753160\ttotal: 21.3s\tremaining: 10.6s\n",
      "668:\tlearn: 8.9678309\ttotal: 21.3s\tremaining: 10.5s\n",
      "669:\tlearn: 8.9615996\ttotal: 21.3s\tremaining: 10.5s\n",
      "670:\tlearn: 8.9554868\ttotal: 21.3s\tremaining: 10.5s\n",
      "671:\tlearn: 8.9500077\ttotal: 21.4s\tremaining: 10.4s\n",
      "672:\tlearn: 8.9443946\ttotal: 21.4s\tremaining: 10.4s\n",
      "673:\tlearn: 8.9393819\ttotal: 21.4s\tremaining: 10.4s\n",
      "674:\tlearn: 8.9342961\ttotal: 21.5s\tremaining: 10.3s\n",
      "675:\tlearn: 8.9298298\ttotal: 21.5s\tremaining: 10.3s\n",
      "676:\tlearn: 8.9231557\ttotal: 21.5s\tremaining: 10.3s\n",
      "677:\tlearn: 8.9183686\ttotal: 21.5s\tremaining: 10.2s\n",
      "678:\tlearn: 8.9139381\ttotal: 21.6s\tremaining: 10.2s\n",
      "679:\tlearn: 8.9098361\ttotal: 21.6s\tremaining: 10.2s\n",
      "680:\tlearn: 8.9051631\ttotal: 21.6s\tremaining: 10.1s\n",
      "681:\tlearn: 8.8995855\ttotal: 21.7s\tremaining: 10.1s\n",
      "682:\tlearn: 8.8941883\ttotal: 21.7s\tremaining: 10.1s\n",
      "683:\tlearn: 8.8892755\ttotal: 21.8s\tremaining: 10s\n",
      "684:\tlearn: 8.8841308\ttotal: 21.8s\tremaining: 10s\n",
      "685:\tlearn: 8.8782783\ttotal: 21.8s\tremaining: 9.99s\n",
      "686:\tlearn: 8.8735757\ttotal: 21.9s\tremaining: 9.96s\n",
      "687:\tlearn: 8.8684465\ttotal: 21.9s\tremaining: 9.93s\n",
      "688:\tlearn: 8.8644894\ttotal: 21.9s\tremaining: 9.89s\n",
      "689:\tlearn: 8.8592715\ttotal: 21.9s\tremaining: 9.86s\n",
      "690:\tlearn: 8.8521386\ttotal: 22s\tremaining: 9.83s\n",
      "691:\tlearn: 8.8476155\ttotal: 22s\tremaining: 9.8s\n",
      "692:\tlearn: 8.8420048\ttotal: 22s\tremaining: 9.76s\n",
      "693:\tlearn: 8.8371113\ttotal: 22.1s\tremaining: 9.73s\n",
      "694:\tlearn: 8.8333734\ttotal: 22.1s\tremaining: 9.7s\n",
      "695:\tlearn: 8.8285986\ttotal: 22.1s\tremaining: 9.66s\n",
      "696:\tlearn: 8.8245114\ttotal: 22.2s\tremaining: 9.63s\n",
      "697:\tlearn: 8.8213239\ttotal: 22.2s\tremaining: 9.6s\n",
      "698:\tlearn: 8.8181259\ttotal: 22.2s\tremaining: 9.56s\n",
      "699:\tlearn: 8.8155081\ttotal: 22.2s\tremaining: 9.53s\n",
      "700:\tlearn: 8.8126113\ttotal: 22.3s\tremaining: 9.5s\n",
      "701:\tlearn: 8.8072539\ttotal: 22.3s\tremaining: 9.47s\n",
      "702:\tlearn: 8.8043350\ttotal: 22.3s\tremaining: 9.44s\n",
      "703:\tlearn: 8.7995136\ttotal: 22.4s\tremaining: 9.4s\n",
      "704:\tlearn: 8.7930703\ttotal: 22.4s\tremaining: 9.37s\n",
      "705:\tlearn: 8.7863868\ttotal: 22.4s\tremaining: 9.34s\n",
      "706:\tlearn: 8.7815619\ttotal: 22.5s\tremaining: 9.3s\n",
      "707:\tlearn: 8.7767895\ttotal: 22.5s\tremaining: 9.27s\n",
      "708:\tlearn: 8.7711520\ttotal: 22.5s\tremaining: 9.24s\n",
      "709:\tlearn: 8.7685425\ttotal: 22.5s\tremaining: 9.21s\n",
      "710:\tlearn: 8.7619003\ttotal: 22.6s\tremaining: 9.18s\n",
      "711:\tlearn: 8.7581408\ttotal: 22.6s\tremaining: 9.14s\n",
      "712:\tlearn: 8.7537566\ttotal: 22.6s\tremaining: 9.11s\n",
      "713:\tlearn: 8.7484906\ttotal: 22.7s\tremaining: 9.08s\n",
      "714:\tlearn: 8.7430480\ttotal: 22.7s\tremaining: 9.04s\n",
      "715:\tlearn: 8.7384010\ttotal: 22.7s\tremaining: 9.01s\n",
      "716:\tlearn: 8.7326652\ttotal: 22.8s\tremaining: 8.98s\n",
      "717:\tlearn: 8.7305361\ttotal: 22.8s\tremaining: 8.95s\n",
      "718:\tlearn: 8.7249494\ttotal: 22.8s\tremaining: 8.91s\n",
      "719:\tlearn: 8.7186440\ttotal: 22.8s\tremaining: 8.88s\n",
      "720:\tlearn: 8.7138551\ttotal: 22.9s\tremaining: 8.85s\n",
      "721:\tlearn: 8.7098653\ttotal: 22.9s\tremaining: 8.81s\n",
      "722:\tlearn: 8.7056797\ttotal: 22.9s\tremaining: 8.78s\n",
      "723:\tlearn: 8.7012059\ttotal: 22.9s\tremaining: 8.74s\n",
      "724:\tlearn: 8.6957895\ttotal: 23s\tremaining: 8.71s\n",
      "725:\tlearn: 8.6897466\ttotal: 23s\tremaining: 8.68s\n",
      "726:\tlearn: 8.6841752\ttotal: 23s\tremaining: 8.64s\n",
      "727:\tlearn: 8.6786260\ttotal: 23s\tremaining: 8.61s\n",
      "728:\tlearn: 8.6741721\ttotal: 23.1s\tremaining: 8.58s\n",
      "729:\tlearn: 8.6696620\ttotal: 23.1s\tremaining: 8.54s\n",
      "730:\tlearn: 8.6656817\ttotal: 23.1s\tremaining: 8.51s\n",
      "731:\tlearn: 8.6622202\ttotal: 23.2s\tremaining: 8.48s\n",
      "732:\tlearn: 8.6565229\ttotal: 23.2s\tremaining: 8.44s\n",
      "733:\tlearn: 8.6514953\ttotal: 23.2s\tremaining: 8.41s\n",
      "734:\tlearn: 8.6480424\ttotal: 23.2s\tremaining: 8.38s\n",
      "735:\tlearn: 8.6426693\ttotal: 23.3s\tremaining: 8.34s\n",
      "736:\tlearn: 8.6385630\ttotal: 23.3s\tremaining: 8.31s\n",
      "737:\tlearn: 8.6338808\ttotal: 23.3s\tremaining: 8.28s\n",
      "738:\tlearn: 8.6292314\ttotal: 23.3s\tremaining: 8.24s\n",
      "739:\tlearn: 8.6224923\ttotal: 23.4s\tremaining: 8.21s\n",
      "740:\tlearn: 8.6179566\ttotal: 23.4s\tremaining: 8.18s\n",
      "741:\tlearn: 8.6112122\ttotal: 23.4s\tremaining: 8.14s\n",
      "742:\tlearn: 8.6047838\ttotal: 23.4s\tremaining: 8.11s\n",
      "743:\tlearn: 8.5991918\ttotal: 23.5s\tremaining: 8.08s\n",
      "744:\tlearn: 8.5940913\ttotal: 23.5s\tremaining: 8.04s\n",
      "745:\tlearn: 8.5878665\ttotal: 23.5s\tremaining: 8.01s\n",
      "746:\tlearn: 8.5828322\ttotal: 23.6s\tremaining: 7.98s\n",
      "747:\tlearn: 8.5790696\ttotal: 23.6s\tremaining: 7.94s\n",
      "748:\tlearn: 8.5750716\ttotal: 23.6s\tremaining: 7.91s\n",
      "749:\tlearn: 8.5689736\ttotal: 23.6s\tremaining: 7.88s\n",
      "750:\tlearn: 8.5637390\ttotal: 23.7s\tremaining: 7.84s\n",
      "751:\tlearn: 8.5589891\ttotal: 23.7s\tremaining: 7.81s\n",
      "752:\tlearn: 8.5536010\ttotal: 23.7s\tremaining: 7.78s\n",
      "753:\tlearn: 8.5495139\ttotal: 23.7s\tremaining: 7.75s\n",
      "754:\tlearn: 8.5440151\ttotal: 23.8s\tremaining: 7.71s\n",
      "755:\tlearn: 8.5392509\ttotal: 23.8s\tremaining: 7.68s\n",
      "756:\tlearn: 8.5341026\ttotal: 23.8s\tremaining: 7.64s\n",
      "757:\tlearn: 8.5301049\ttotal: 23.8s\tremaining: 7.61s\n",
      "758:\tlearn: 8.5261732\ttotal: 23.9s\tremaining: 7.58s\n",
      "759:\tlearn: 8.5229498\ttotal: 23.9s\tremaining: 7.54s\n",
      "760:\tlearn: 8.5163282\ttotal: 23.9s\tremaining: 7.51s\n",
      "761:\tlearn: 8.5123744\ttotal: 23.9s\tremaining: 7.48s\n",
      "762:\tlearn: 8.5091291\ttotal: 24s\tremaining: 7.45s\n",
      "763:\tlearn: 8.5052298\ttotal: 24s\tremaining: 7.42s\n",
      "764:\tlearn: 8.5027329\ttotal: 24s\tremaining: 7.38s\n",
      "765:\tlearn: 8.4988384\ttotal: 24.1s\tremaining: 7.35s\n",
      "766:\tlearn: 8.4920570\ttotal: 24.1s\tremaining: 7.32s\n",
      "767:\tlearn: 8.4857354\ttotal: 24.1s\tremaining: 7.29s\n",
      "768:\tlearn: 8.4812116\ttotal: 24.2s\tremaining: 7.26s\n",
      "769:\tlearn: 8.4759081\ttotal: 24.2s\tremaining: 7.22s\n",
      "770:\tlearn: 8.4725770\ttotal: 24.2s\tremaining: 7.19s\n",
      "771:\tlearn: 8.4671119\ttotal: 24.2s\tremaining: 7.16s\n",
      "772:\tlearn: 8.4614209\ttotal: 24.3s\tremaining: 7.13s\n",
      "773:\tlearn: 8.4569377\ttotal: 24.3s\tremaining: 7.09s\n",
      "774:\tlearn: 8.4542442\ttotal: 24.3s\tremaining: 7.06s\n",
      "775:\tlearn: 8.4494211\ttotal: 24.4s\tremaining: 7.03s\n",
      "776:\tlearn: 8.4429638\ttotal: 24.4s\tremaining: 7s\n",
      "777:\tlearn: 8.4364337\ttotal: 24.4s\tremaining: 6.96s\n",
      "778:\tlearn: 8.4321094\ttotal: 24.4s\tremaining: 6.93s\n",
      "779:\tlearn: 8.4270107\ttotal: 24.5s\tremaining: 6.9s\n",
      "780:\tlearn: 8.4230736\ttotal: 24.5s\tremaining: 6.86s\n",
      "781:\tlearn: 8.4188717\ttotal: 24.5s\tremaining: 6.83s\n",
      "782:\tlearn: 8.4137026\ttotal: 24.5s\tremaining: 6.8s\n",
      "783:\tlearn: 8.4085238\ttotal: 24.6s\tremaining: 6.77s\n",
      "784:\tlearn: 8.4037014\ttotal: 24.6s\tremaining: 6.74s\n",
      "785:\tlearn: 8.3996183\ttotal: 24.6s\tremaining: 6.7s\n",
      "786:\tlearn: 8.3942548\ttotal: 24.6s\tremaining: 6.67s\n",
      "787:\tlearn: 8.3901225\ttotal: 24.7s\tremaining: 6.64s\n",
      "788:\tlearn: 8.3868262\ttotal: 24.7s\tremaining: 6.6s\n",
      "789:\tlearn: 8.3831248\ttotal: 24.7s\tremaining: 6.57s\n",
      "790:\tlearn: 8.3767758\ttotal: 24.8s\tremaining: 6.54s\n",
      "791:\tlearn: 8.3695710\ttotal: 24.8s\tremaining: 6.51s\n",
      "792:\tlearn: 8.3644062\ttotal: 24.8s\tremaining: 6.48s\n",
      "793:\tlearn: 8.3608369\ttotal: 24.8s\tremaining: 6.45s\n",
      "794:\tlearn: 8.3558820\ttotal: 24.9s\tremaining: 6.42s\n",
      "795:\tlearn: 8.3520288\ttotal: 24.9s\tremaining: 6.38s\n",
      "796:\tlearn: 8.3475575\ttotal: 24.9s\tremaining: 6.35s\n",
      "797:\tlearn: 8.3455327\ttotal: 25s\tremaining: 6.32s\n",
      "798:\tlearn: 8.3411085\ttotal: 25s\tremaining: 6.29s\n",
      "799:\tlearn: 8.3361977\ttotal: 25s\tremaining: 6.26s\n",
      "800:\tlearn: 8.3315715\ttotal: 25.1s\tremaining: 6.22s\n",
      "801:\tlearn: 8.3268864\ttotal: 25.1s\tremaining: 6.19s\n",
      "802:\tlearn: 8.3224147\ttotal: 25.1s\tremaining: 6.16s\n",
      "803:\tlearn: 8.3189143\ttotal: 25.1s\tremaining: 6.13s\n",
      "804:\tlearn: 8.3162170\ttotal: 25.2s\tremaining: 6.1s\n",
      "805:\tlearn: 8.3130928\ttotal: 25.2s\tremaining: 6.07s\n",
      "806:\tlearn: 8.3079437\ttotal: 25.2s\tremaining: 6.04s\n",
      "807:\tlearn: 8.3040093\ttotal: 25.3s\tremaining: 6.01s\n",
      "808:\tlearn: 8.2997695\ttotal: 25.3s\tremaining: 5.97s\n",
      "809:\tlearn: 8.2941460\ttotal: 25.3s\tremaining: 5.94s\n",
      "810:\tlearn: 8.2900464\ttotal: 25.4s\tremaining: 5.91s\n",
      "811:\tlearn: 8.2864290\ttotal: 25.4s\tremaining: 5.88s\n",
      "812:\tlearn: 8.2826732\ttotal: 25.4s\tremaining: 5.85s\n",
      "813:\tlearn: 8.2788401\ttotal: 25.5s\tremaining: 5.82s\n",
      "814:\tlearn: 8.2748689\ttotal: 25.5s\tremaining: 5.79s\n",
      "815:\tlearn: 8.2710799\ttotal: 25.5s\tremaining: 5.75s\n",
      "816:\tlearn: 8.2657317\ttotal: 25.6s\tremaining: 5.72s\n",
      "817:\tlearn: 8.2614722\ttotal: 25.6s\tremaining: 5.69s\n",
      "818:\tlearn: 8.2575463\ttotal: 25.6s\tremaining: 5.66s\n",
      "819:\tlearn: 8.2539509\ttotal: 25.6s\tremaining: 5.63s\n",
      "820:\tlearn: 8.2496990\ttotal: 25.7s\tremaining: 5.6s\n",
      "821:\tlearn: 8.2472708\ttotal: 25.7s\tremaining: 5.56s\n",
      "822:\tlearn: 8.2421701\ttotal: 25.7s\tremaining: 5.53s\n",
      "823:\tlearn: 8.2375496\ttotal: 25.7s\tremaining: 5.5s\n",
      "824:\tlearn: 8.2327046\ttotal: 25.8s\tremaining: 5.47s\n",
      "825:\tlearn: 8.2282408\ttotal: 25.8s\tremaining: 5.43s\n",
      "826:\tlearn: 8.2244103\ttotal: 25.8s\tremaining: 5.4s\n",
      "827:\tlearn: 8.2192212\ttotal: 25.9s\tremaining: 5.37s\n",
      "828:\tlearn: 8.2165520\ttotal: 25.9s\tremaining: 5.34s\n",
      "829:\tlearn: 8.2128061\ttotal: 25.9s\tremaining: 5.31s\n",
      "830:\tlearn: 8.2091619\ttotal: 26s\tremaining: 5.28s\n",
      "831:\tlearn: 8.2041349\ttotal: 26s\tremaining: 5.25s\n",
      "832:\tlearn: 8.2004603\ttotal: 26s\tremaining: 5.21s\n",
      "833:\tlearn: 8.1971387\ttotal: 26s\tremaining: 5.18s\n",
      "834:\tlearn: 8.1907745\ttotal: 26.1s\tremaining: 5.15s\n",
      "835:\tlearn: 8.1853517\ttotal: 26.1s\tremaining: 5.12s\n",
      "836:\tlearn: 8.1806192\ttotal: 26.1s\tremaining: 5.09s\n",
      "837:\tlearn: 8.1752590\ttotal: 26.1s\tremaining: 5.05s\n",
      "838:\tlearn: 8.1703624\ttotal: 26.2s\tremaining: 5.02s\n",
      "839:\tlearn: 8.1662780\ttotal: 26.2s\tremaining: 4.99s\n",
      "840:\tlearn: 8.1636104\ttotal: 26.2s\tremaining: 4.96s\n",
      "841:\tlearn: 8.1611401\ttotal: 26.3s\tremaining: 4.93s\n",
      "842:\tlearn: 8.1545541\ttotal: 26.3s\tremaining: 4.89s\n",
      "843:\tlearn: 8.1489245\ttotal: 26.3s\tremaining: 4.86s\n",
      "844:\tlearn: 8.1446974\ttotal: 26.3s\tremaining: 4.83s\n",
      "845:\tlearn: 8.1399945\ttotal: 26.4s\tremaining: 4.8s\n",
      "846:\tlearn: 8.1336574\ttotal: 26.4s\tremaining: 4.77s\n",
      "847:\tlearn: 8.1313307\ttotal: 26.4s\tremaining: 4.74s\n",
      "848:\tlearn: 8.1267850\ttotal: 26.5s\tremaining: 4.71s\n",
      "849:\tlearn: 8.1220615\ttotal: 26.5s\tremaining: 4.67s\n",
      "850:\tlearn: 8.1187230\ttotal: 26.5s\tremaining: 4.64s\n",
      "851:\tlearn: 8.1131138\ttotal: 26.5s\tremaining: 4.61s\n",
      "852:\tlearn: 8.1088618\ttotal: 26.6s\tremaining: 4.58s\n",
      "853:\tlearn: 8.1046627\ttotal: 26.6s\tremaining: 4.55s\n",
      "854:\tlearn: 8.1014419\ttotal: 26.6s\tremaining: 4.51s\n",
      "855:\tlearn: 8.0972784\ttotal: 26.7s\tremaining: 4.48s\n",
      "856:\tlearn: 8.0939499\ttotal: 26.7s\tremaining: 4.45s\n",
      "857:\tlearn: 8.0878310\ttotal: 26.7s\tremaining: 4.42s\n",
      "858:\tlearn: 8.0834429\ttotal: 26.8s\tremaining: 4.39s\n",
      "859:\tlearn: 8.0789518\ttotal: 26.8s\tremaining: 4.36s\n",
      "860:\tlearn: 8.0733037\ttotal: 26.8s\tremaining: 4.33s\n",
      "861:\tlearn: 8.0675614\ttotal: 26.8s\tremaining: 4.3s\n",
      "862:\tlearn: 8.0650672\ttotal: 26.9s\tremaining: 4.26s\n",
      "863:\tlearn: 8.0618906\ttotal: 26.9s\tremaining: 4.23s\n",
      "864:\tlearn: 8.0579509\ttotal: 26.9s\tremaining: 4.2s\n",
      "865:\tlearn: 8.0546016\ttotal: 27s\tremaining: 4.17s\n",
      "866:\tlearn: 8.0495141\ttotal: 27s\tremaining: 4.14s\n",
      "867:\tlearn: 8.0452290\ttotal: 27s\tremaining: 4.11s\n",
      "868:\tlearn: 8.0413175\ttotal: 27s\tremaining: 4.08s\n",
      "869:\tlearn: 8.0373405\ttotal: 27.1s\tremaining: 4.04s\n",
      "870:\tlearn: 8.0338923\ttotal: 27.1s\tremaining: 4.01s\n",
      "871:\tlearn: 8.0303401\ttotal: 27.1s\tremaining: 3.98s\n",
      "872:\tlearn: 8.0256607\ttotal: 27.2s\tremaining: 3.95s\n",
      "873:\tlearn: 8.0217644\ttotal: 27.2s\tremaining: 3.92s\n",
      "874:\tlearn: 8.0171756\ttotal: 27.2s\tremaining: 3.89s\n",
      "875:\tlearn: 8.0134309\ttotal: 27.3s\tremaining: 3.86s\n",
      "876:\tlearn: 8.0095604\ttotal: 27.3s\tremaining: 3.83s\n",
      "877:\tlearn: 8.0058161\ttotal: 27.3s\tremaining: 3.8s\n",
      "878:\tlearn: 8.0010975\ttotal: 27.4s\tremaining: 3.77s\n",
      "879:\tlearn: 7.9969886\ttotal: 27.4s\tremaining: 3.74s\n",
      "880:\tlearn: 7.9937775\ttotal: 27.5s\tremaining: 3.71s\n",
      "881:\tlearn: 7.9908339\ttotal: 27.5s\tremaining: 3.68s\n",
      "882:\tlearn: 7.9870019\ttotal: 27.5s\tremaining: 3.65s\n",
      "883:\tlearn: 7.9836478\ttotal: 27.6s\tremaining: 3.62s\n",
      "884:\tlearn: 7.9791089\ttotal: 27.6s\tremaining: 3.59s\n",
      "885:\tlearn: 7.9759039\ttotal: 27.6s\tremaining: 3.56s\n",
      "886:\tlearn: 7.9717622\ttotal: 27.7s\tremaining: 3.53s\n",
      "887:\tlearn: 7.9666342\ttotal: 27.7s\tremaining: 3.5s\n",
      "888:\tlearn: 7.9622437\ttotal: 27.7s\tremaining: 3.46s\n",
      "889:\tlearn: 7.9579098\ttotal: 27.8s\tremaining: 3.43s\n",
      "890:\tlearn: 7.9530159\ttotal: 27.8s\tremaining: 3.4s\n",
      "891:\tlearn: 7.9470854\ttotal: 27.9s\tremaining: 3.37s\n",
      "892:\tlearn: 7.9433401\ttotal: 27.9s\tremaining: 3.34s\n",
      "893:\tlearn: 7.9378943\ttotal: 27.9s\tremaining: 3.31s\n",
      "894:\tlearn: 7.9340696\ttotal: 27.9s\tremaining: 3.28s\n",
      "895:\tlearn: 7.9316288\ttotal: 28s\tremaining: 3.25s\n",
      "896:\tlearn: 7.9277560\ttotal: 28s\tremaining: 3.22s\n",
      "897:\tlearn: 7.9238560\ttotal: 28s\tremaining: 3.19s\n",
      "898:\tlearn: 7.9197585\ttotal: 28.1s\tremaining: 3.15s\n",
      "899:\tlearn: 7.9170442\ttotal: 28.1s\tremaining: 3.12s\n",
      "900:\tlearn: 7.9135446\ttotal: 28.1s\tremaining: 3.09s\n",
      "901:\tlearn: 7.9094075\ttotal: 28.2s\tremaining: 3.06s\n",
      "902:\tlearn: 7.9047494\ttotal: 28.2s\tremaining: 3.03s\n",
      "903:\tlearn: 7.8988650\ttotal: 28.2s\tremaining: 3s\n",
      "904:\tlearn: 7.8949997\ttotal: 28.3s\tremaining: 2.97s\n",
      "905:\tlearn: 7.8908669\ttotal: 28.3s\tremaining: 2.94s\n",
      "906:\tlearn: 7.8873613\ttotal: 28.3s\tremaining: 2.9s\n",
      "907:\tlearn: 7.8840514\ttotal: 28.4s\tremaining: 2.87s\n",
      "908:\tlearn: 7.8795902\ttotal: 28.4s\tremaining: 2.84s\n",
      "909:\tlearn: 7.8763036\ttotal: 28.4s\tremaining: 2.81s\n",
      "910:\tlearn: 7.8725761\ttotal: 28.5s\tremaining: 2.78s\n",
      "911:\tlearn: 7.8677027\ttotal: 28.5s\tremaining: 2.75s\n",
      "912:\tlearn: 7.8641401\ttotal: 28.5s\tremaining: 2.72s\n",
      "913:\tlearn: 7.8595075\ttotal: 28.5s\tremaining: 2.69s\n",
      "914:\tlearn: 7.8550996\ttotal: 28.6s\tremaining: 2.65s\n",
      "915:\tlearn: 7.8511785\ttotal: 28.6s\tremaining: 2.62s\n",
      "916:\tlearn: 7.8474687\ttotal: 28.7s\tremaining: 2.59s\n",
      "917:\tlearn: 7.8417462\ttotal: 28.7s\tremaining: 2.56s\n",
      "918:\tlearn: 7.8372003\ttotal: 28.7s\tremaining: 2.53s\n",
      "919:\tlearn: 7.8336902\ttotal: 28.8s\tremaining: 2.5s\n",
      "920:\tlearn: 7.8286727\ttotal: 28.8s\tremaining: 2.47s\n",
      "921:\tlearn: 7.8248237\ttotal: 28.8s\tremaining: 2.44s\n",
      "922:\tlearn: 7.8211768\ttotal: 28.9s\tremaining: 2.41s\n",
      "923:\tlearn: 7.8168147\ttotal: 28.9s\tremaining: 2.38s\n",
      "924:\tlearn: 7.8122186\ttotal: 28.9s\tremaining: 2.35s\n",
      "925:\tlearn: 7.8085377\ttotal: 29s\tremaining: 2.31s\n",
      "926:\tlearn: 7.8052369\ttotal: 29s\tremaining: 2.28s\n",
      "927:\tlearn: 7.8018555\ttotal: 29s\tremaining: 2.25s\n",
      "928:\tlearn: 7.7992377\ttotal: 29s\tremaining: 2.22s\n",
      "929:\tlearn: 7.7940311\ttotal: 29.1s\tremaining: 2.19s\n",
      "930:\tlearn: 7.7906563\ttotal: 29.1s\tremaining: 2.16s\n",
      "931:\tlearn: 7.7867409\ttotal: 29.1s\tremaining: 2.13s\n",
      "932:\tlearn: 7.7830404\ttotal: 29.2s\tremaining: 2.09s\n",
      "933:\tlearn: 7.7783585\ttotal: 29.2s\tremaining: 2.06s\n",
      "934:\tlearn: 7.7743951\ttotal: 29.2s\tremaining: 2.03s\n",
      "935:\tlearn: 7.7689718\ttotal: 29.2s\tremaining: 2s\n",
      "936:\tlearn: 7.7642289\ttotal: 29.3s\tremaining: 1.97s\n",
      "937:\tlearn: 7.7610788\ttotal: 29.3s\tremaining: 1.94s\n",
      "938:\tlearn: 7.7575266\ttotal: 29.3s\tremaining: 1.91s\n",
      "939:\tlearn: 7.7539377\ttotal: 29.4s\tremaining: 1.88s\n",
      "940:\tlearn: 7.7496809\ttotal: 29.4s\tremaining: 1.84s\n",
      "941:\tlearn: 7.7450965\ttotal: 29.5s\tremaining: 1.81s\n",
      "942:\tlearn: 7.7410114\ttotal: 29.5s\tremaining: 1.78s\n",
      "943:\tlearn: 7.7345955\ttotal: 29.5s\tremaining: 1.75s\n",
      "944:\tlearn: 7.7304829\ttotal: 29.6s\tremaining: 1.72s\n",
      "945:\tlearn: 7.7271485\ttotal: 29.6s\tremaining: 1.69s\n",
      "946:\tlearn: 7.7229124\ttotal: 29.6s\tremaining: 1.66s\n",
      "947:\tlearn: 7.7202814\ttotal: 29.7s\tremaining: 1.63s\n",
      "948:\tlearn: 7.7162107\ttotal: 29.7s\tremaining: 1.59s\n",
      "949:\tlearn: 7.7117490\ttotal: 29.7s\tremaining: 1.56s\n",
      "950:\tlearn: 7.7073911\ttotal: 29.8s\tremaining: 1.53s\n",
      "951:\tlearn: 7.7032845\ttotal: 29.8s\tremaining: 1.5s\n",
      "952:\tlearn: 7.6980387\ttotal: 29.8s\tremaining: 1.47s\n",
      "953:\tlearn: 7.6912264\ttotal: 29.9s\tremaining: 1.44s\n",
      "954:\tlearn: 7.6863585\ttotal: 29.9s\tremaining: 1.41s\n",
      "955:\tlearn: 7.6811328\ttotal: 29.9s\tremaining: 1.38s\n",
      "956:\tlearn: 7.6774708\ttotal: 30s\tremaining: 1.34s\n",
      "957:\tlearn: 7.6733283\ttotal: 30s\tremaining: 1.31s\n",
      "958:\tlearn: 7.6691382\ttotal: 30s\tremaining: 1.28s\n",
      "959:\tlearn: 7.6654245\ttotal: 30s\tremaining: 1.25s\n",
      "960:\tlearn: 7.6608809\ttotal: 30.1s\tremaining: 1.22s\n",
      "961:\tlearn: 7.6564735\ttotal: 30.1s\tremaining: 1.19s\n",
      "962:\tlearn: 7.6521581\ttotal: 30.1s\tremaining: 1.16s\n",
      "963:\tlearn: 7.6480520\ttotal: 30.2s\tremaining: 1.13s\n",
      "964:\tlearn: 7.6442992\ttotal: 30.2s\tremaining: 1.09s\n",
      "965:\tlearn: 7.6408676\ttotal: 30.2s\tremaining: 1.06s\n",
      "966:\tlearn: 7.6359346\ttotal: 30.3s\tremaining: 1.03s\n",
      "967:\tlearn: 7.6310918\ttotal: 30.3s\tremaining: 1s\n",
      "968:\tlearn: 7.6269503\ttotal: 30.3s\tremaining: 970ms\n",
      "969:\tlearn: 7.6221787\ttotal: 30.3s\tremaining: 939ms\n",
      "970:\tlearn: 7.6178453\ttotal: 30.4s\tremaining: 907ms\n",
      "971:\tlearn: 7.6140430\ttotal: 30.4s\tremaining: 876ms\n",
      "972:\tlearn: 7.6083938\ttotal: 30.4s\tremaining: 845ms\n",
      "973:\tlearn: 7.6045461\ttotal: 30.5s\tremaining: 813ms\n",
      "974:\tlearn: 7.6003772\ttotal: 30.5s\tremaining: 782ms\n",
      "975:\tlearn: 7.5964430\ttotal: 30.5s\tremaining: 751ms\n",
      "976:\tlearn: 7.5922132\ttotal: 30.6s\tremaining: 719ms\n",
      "977:\tlearn: 7.5881184\ttotal: 30.6s\tremaining: 688ms\n",
      "978:\tlearn: 7.5851579\ttotal: 30.6s\tremaining: 657ms\n",
      "979:\tlearn: 7.5806550\ttotal: 30.7s\tremaining: 626ms\n",
      "980:\tlearn: 7.5762335\ttotal: 30.7s\tremaining: 594ms\n",
      "981:\tlearn: 7.5728726\ttotal: 30.7s\tremaining: 563ms\n",
      "982:\tlearn: 7.5692388\ttotal: 30.7s\tremaining: 532ms\n",
      "983:\tlearn: 7.5644170\ttotal: 30.8s\tremaining: 500ms\n",
      "984:\tlearn: 7.5608533\ttotal: 30.8s\tremaining: 469ms\n",
      "985:\tlearn: 7.5561126\ttotal: 30.8s\tremaining: 438ms\n",
      "986:\tlearn: 7.5521364\ttotal: 30.9s\tremaining: 406ms\n",
      "987:\tlearn: 7.5489206\ttotal: 30.9s\tremaining: 375ms\n",
      "988:\tlearn: 7.5452641\ttotal: 30.9s\tremaining: 344ms\n",
      "989:\tlearn: 7.5422272\ttotal: 30.9s\tremaining: 313ms\n",
      "990:\tlearn: 7.5361697\ttotal: 31s\tremaining: 281ms\n",
      "991:\tlearn: 7.5324977\ttotal: 31s\tremaining: 250ms\n",
      "992:\tlearn: 7.5284395\ttotal: 31s\tremaining: 219ms\n",
      "993:\tlearn: 7.5255661\ttotal: 31.1s\tremaining: 188ms\n",
      "994:\tlearn: 7.5234029\ttotal: 31.1s\tremaining: 156ms\n",
      "995:\tlearn: 7.5196412\ttotal: 31.1s\tremaining: 125ms\n",
      "996:\tlearn: 7.5169657\ttotal: 31.2s\tremaining: 93.8ms\n",
      "997:\tlearn: 7.5124385\ttotal: 31.2s\tremaining: 62.5ms\n",
      "998:\tlearn: 7.5086344\ttotal: 31.2s\tremaining: 31.3ms\n",
      "999:\tlearn: 7.5039680\ttotal: 31.3s\tremaining: 0us\n",
      "MSE of catboost:  182.85599914357783\n",
      "R2 of catboost:  0.12213998758852396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat = CatBoostRegressor(random_state=42, verbose=0)\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat.predict(X_test)\n",
    "\n",
    "print(\"MSE of catboost: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 of catboost: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of linear regression: 181.90\n",
      "Variance score of linear regression: 0.13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error of linear regression: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of linear regression: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of random forest: 182.96\n",
      "R2 score of random forest: 0.12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error of random forest: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of random forest: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimum maximum scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of xgboost:  210.3532276060485\n",
      "R2 of xgboost:  -0.009869448428897032\n"
     ]
    }
   ],
   "source": [
    "# use xgboost\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(\"MSE of xgboost: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 of xgboost: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of catboost:  182.85665635468584\n",
      "R2 of catboost:  0.12213683243171136\n"
     ]
    }
   ],
   "source": [
    "# use catboost\n",
    "cat = CatBoostRegressor(random_state=42, verbose=0)\n",
    "\n",
    "cat.fit(X_train, y_train)\n",
    "\n",
    "y_pred = cat.predict(X_test)\n",
    "\n",
    "print(\"MSE of catboost: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 of catboost: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of linear regression: 181.90\n",
      "R2 score of linear regression: 0.13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error of linear regression: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of linear regression: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of random forest: 182.95\n",
      "R2 score of random forest: 0.12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Mean squared error of random forest: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of random forest: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# perform full pca on the data\n",
    "# try to find the optimal number of components\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=None)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "plt.plot(np.cumsum(explained_variance))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pca where 90% of the variance is explained\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7511, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of xgboost:  213.11391313942192\n",
      "R2 of xgboost:  -0.02312302199466476\n"
     ]
    }
   ],
   "source": [
    "# use xgboost\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test_pca)\n",
    "\n",
    "print(\"MSE of xgboost: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 of xgboost: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of catboost:  187.50919087852128\n",
      "R2 of catboost:  0.09980081920836581\n"
     ]
    }
   ],
   "source": [
    "# USE catboost\n",
    "cat = CatBoostRegressor(random_state=42, verbose=0)\n",
    "cat.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = cat.predict(X_test_pca)\n",
    "\n",
    "print(\"MSE of catboost: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 of catboost: \", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of linear regression: 178.87\n",
      "R2 score of linear regression: 0.14\n"
     ]
    }
   ],
   "source": [
    "# use linear regression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Mean squared error of linear regression: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of linear regression: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of random forest: 182.99\n",
      "R2 score of random forest: 0.12\n"
     ]
    }
   ],
   "source": [
    "# use random forest\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Mean squared error of random forest: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of random forest: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17, 'max_features': 13, 'min_samples_leaf': 23, 'min_samples_split': 4, 'n_estimators': 105}\n",
      "-183.6721127755454\n",
      "RandomForestRegressor(max_depth=17, max_features=13, min_samples_leaf=23,\n",
      "                      min_samples_split=4, n_estimators=105, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# perform random grid search on random forest\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_depth': randint(low=1, high=20),\n",
    "        'min_samples_split': randint(low=2, high=20),\n",
    "        'min_samples_leaf': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=20),\n",
    "    }\n",
    "\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(model, param_distributions=param_distribs,\n",
    "                                n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(X_train_pca, y_train)\n",
    "\n",
    "print(rnd_search.best_params_)\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the best model from the random search\n",
    "model = RandomForestRegressor(max_depth=17, max_features=13, min_samples_leaf=23,\n",
    "                      min_samples_split=4, n_estimators=105, random_state=42)#rnd_search.best_estimator_\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "print(\"Mean squared error of random forest: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "print('R2 score of random forest: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END learning_rate=0.19727005942368125, max_delta_step=7, max_depth=17, n_estimators=70, subsample=0.40921304830970556; total time=   9.0s\n",
      "[CV] END learning_rate=0.19727005942368125, max_delta_step=7, max_depth=17, n_estimators=70, subsample=0.40921304830970556; total time=  13.3s\n",
      "[CV] END learning_rate=0.19727005942368125, max_delta_step=7, max_depth=17, n_estimators=70, subsample=0.40921304830970556; total time=  11.6s\n",
      "[CV] END learning_rate=0.19727005942368125, max_delta_step=7, max_depth=17, n_estimators=70, subsample=0.40921304830970556; total time=  13.1s\n",
      "[CV] END learning_rate=0.19727005942368125, max_delta_step=7, max_depth=17, n_estimators=70, subsample=0.40921304830970556; total time=   9.9s\n",
      "[CV] END learning_rate=0.08799726016810132, max_delta_step=7, max_depth=9, n_estimators=149, subsample=0.40000677254535855; total time=   5.7s\n",
      "[CV] END learning_rate=0.08799726016810132, max_delta_step=7, max_depth=9, n_estimators=149, subsample=0.40000677254535855; total time=   7.4s\n",
      "[CV] END learning_rate=0.08799726016810132, max_delta_step=7, max_depth=9, n_estimators=149, subsample=0.40000677254535855; total time=  12.0s\n",
      "[CV] END learning_rate=0.08799726016810132, max_delta_step=7, max_depth=9, n_estimators=149, subsample=0.40000677254535855; total time=  12.0s\n",
      "[CV] END learning_rate=0.08799726016810132, max_delta_step=7, max_depth=9, n_estimators=149, subsample=0.40000677254535855; total time=   7.8s\n",
      "[CV] END learning_rate=0.33544423647442645, max_delta_step=4, max_depth=6, n_estimators=137, subsample=0.8827098485602951; total time=   2.4s\n",
      "[CV] END learning_rate=0.33544423647442645, max_delta_step=4, max_depth=6, n_estimators=137, subsample=0.8827098485602951; total time=   3.0s\n",
      "[CV] END learning_rate=0.33544423647442645, max_delta_step=4, max_depth=6, n_estimators=137, subsample=0.8827098485602951; total time=   3.3s\n",
      "[CV] END learning_rate=0.33544423647442645, max_delta_step=4, max_depth=6, n_estimators=137, subsample=0.8827098485602951; total time=   1.7s\n",
      "[CV] END learning_rate=0.33544423647442645, max_delta_step=4, max_depth=6, n_estimators=137, subsample=0.8827098485602951; total time=   1.9s\n",
      "[CV] END learning_rate=0.11616955533913807, max_delta_step=4, max_depth=5, n_estimators=107, subsample=0.6673295021425665; total time=   0.6s\n",
      "[CV] END learning_rate=0.11616955533913807, max_delta_step=4, max_depth=5, n_estimators=107, subsample=0.6673295021425665; total time=   0.6s\n",
      "[CV] END learning_rate=0.11616955533913807, max_delta_step=4, max_depth=5, n_estimators=107, subsample=0.6673295021425665; total time=   0.5s\n",
      "[CV] END learning_rate=0.11616955533913807, max_delta_step=4, max_depth=5, n_estimators=107, subsample=0.6673295021425665; total time=   0.5s\n",
      "[CV] END learning_rate=0.11616955533913807, max_delta_step=4, max_depth=5, n_estimators=107, subsample=0.6673295021425665; total time=   0.7s\n",
      "[CV] END learning_rate=0.2259725093210579, max_delta_step=0, max_depth=15, n_estimators=108, subsample=0.5799026802006788; total time=  19.4s\n",
      "[CV] END learning_rate=0.2259725093210579, max_delta_step=0, max_depth=15, n_estimators=108, subsample=0.5799026802006788; total time=  19.6s\n",
      "[CV] END learning_rate=0.2259725093210579, max_delta_step=0, max_depth=15, n_estimators=108, subsample=0.5799026802006788; total time=  19.2s\n",
      "[CV] END learning_rate=0.2259725093210579, max_delta_step=0, max_depth=15, n_estimators=108, subsample=0.5799026802006788; total time=  23.1s\n",
      "[CV] END learning_rate=0.2259725093210579, max_delta_step=0, max_depth=15, n_estimators=108, subsample=0.5799026802006788; total time=  19.7s\n",
      "[CV] END learning_rate=0.033332831606807715, max_delta_step=2, max_depth=16, n_estimators=104, subsample=0.9882616200647516; total time=  19.7s\n",
      "[CV] END learning_rate=0.033332831606807715, max_delta_step=2, max_depth=16, n_estimators=104, subsample=0.9882616200647516; total time=  20.0s\n",
      "[CV] END learning_rate=0.033332831606807715, max_delta_step=2, max_depth=16, n_estimators=104, subsample=0.9882616200647516; total time=  19.1s\n",
      "[CV] END learning_rate=0.033332831606807715, max_delta_step=2, max_depth=16, n_estimators=104, subsample=0.9882616200647516; total time=  19.6s\n",
      "[CV] END learning_rate=0.033332831606807715, max_delta_step=2, max_depth=16, n_estimators=104, subsample=0.9882616200647516; total time=  19.0s\n",
      "[CV] END learning_rate=0.24338144662398997, max_delta_step=4, max_depth=7, n_estimators=184, subsample=0.41936688658110405; total time=   3.1s\n",
      "[CV] END learning_rate=0.24338144662398997, max_delta_step=4, max_depth=7, n_estimators=184, subsample=0.41936688658110405; total time=   3.2s\n",
      "[CV] END learning_rate=0.24338144662398997, max_delta_step=4, max_depth=7, n_estimators=184, subsample=0.41936688658110405; total time=   3.2s\n",
      "[CV] END learning_rate=0.24338144662398997, max_delta_step=4, max_depth=7, n_estimators=184, subsample=0.41936688658110405; total time=   3.1s\n",
      "[CV] END learning_rate=0.24338144662398997, max_delta_step=4, max_depth=7, n_estimators=184, subsample=0.41936688658110405; total time=   3.2s\n",
      "[CV] END learning_rate=0.04252579649263976, max_delta_step=3, max_depth=13, n_estimators=109, subsample=0.6943017524918775; total time=  15.1s\n",
      "[CV] END learning_rate=0.04252579649263976, max_delta_step=3, max_depth=13, n_estimators=109, subsample=0.6943017524918775; total time=  14.2s\n",
      "[CV] END learning_rate=0.04252579649263976, max_delta_step=3, max_depth=13, n_estimators=109, subsample=0.6943017524918775; total time=  14.2s\n",
      "[CV] END learning_rate=0.04252579649263976, max_delta_step=3, max_depth=13, n_estimators=109, subsample=0.6943017524918775; total time=  14.5s\n",
      "[CV] END learning_rate=0.04252579649263976, max_delta_step=3, max_depth=13, n_estimators=109, subsample=0.6943017524918775; total time=  14.3s\n",
      "[CV] END learning_rate=0.20270825126995806, max_delta_step=9, max_depth=9, n_estimators=179, subsample=0.7789631185585097; total time=   8.3s\n",
      "[CV] END learning_rate=0.20270825126995806, max_delta_step=9, max_depth=9, n_estimators=179, subsample=0.7789631185585097; total time=   8.1s\n",
      "[CV] END learning_rate=0.20270825126995806, max_delta_step=9, max_depth=9, n_estimators=179, subsample=0.7789631185585097; total time=   8.2s\n",
      "[CV] END learning_rate=0.20270825126995806, max_delta_step=9, max_depth=9, n_estimators=179, subsample=0.7789631185585097; total time=   7.9s\n",
      "[CV] END learning_rate=0.20270825126995806, max_delta_step=9, max_depth=9, n_estimators=179, subsample=0.7789631185585097; total time=   8.1s\n",
      "[CV] END learning_rate=0.23007624686980066, max_delta_step=6, max_depth=16, n_estimators=57, subsample=0.32407196478065287; total time=   8.5s\n",
      "[CV] END learning_rate=0.23007624686980066, max_delta_step=6, max_depth=16, n_estimators=57, subsample=0.32407196478065287; total time=   8.0s\n",
      "[CV] END learning_rate=0.23007624686980066, max_delta_step=6, max_depth=16, n_estimators=57, subsample=0.32407196478065287; total time=   8.3s\n",
      "[CV] END learning_rate=0.23007624686980066, max_delta_step=6, max_depth=16, n_estimators=57, subsample=0.32407196478065287; total time=   8.4s\n",
      "[CV] END learning_rate=0.23007624686980066, max_delta_step=6, max_depth=16, n_estimators=57, subsample=0.32407196478065287; total time=   8.2s\n",
      "[CV] END learning_rate=0.46466020103939104, max_delta_step=3, max_depth=6, n_estimators=153, subsample=0.8287529872223567; total time=   1.6s\n",
      "[CV] END learning_rate=0.46466020103939104, max_delta_step=3, max_depth=6, n_estimators=153, subsample=0.8287529872223567; total time=   1.7s\n",
      "[CV] END learning_rate=0.46466020103939104, max_delta_step=3, max_depth=6, n_estimators=153, subsample=0.8287529872223567; total time=   1.7s\n",
      "[CV] END learning_rate=0.46466020103939104, max_delta_step=3, max_depth=6, n_estimators=153, subsample=0.8287529872223567; total time=   1.8s\n",
      "[CV] END learning_rate=0.46466020103939104, max_delta_step=3, max_depth=6, n_estimators=153, subsample=0.8287529872223567; total time=   1.6s\n",
      "[CV] END learning_rate=0.22257793724562236, max_delta_step=5, max_depth=14, n_estimators=53, subsample=0.42939811886786894; total time=   7.0s\n",
      "[CV] END learning_rate=0.22257793724562236, max_delta_step=5, max_depth=14, n_estimators=53, subsample=0.42939811886786894; total time=   7.0s\n",
      "[CV] END learning_rate=0.22257793724562236, max_delta_step=5, max_depth=14, n_estimators=53, subsample=0.42939811886786894; total time=   6.9s\n",
      "[CV] END learning_rate=0.22257793724562236, max_delta_step=5, max_depth=14, n_estimators=53, subsample=0.42939811886786894; total time=   7.3s\n",
      "[CV] END learning_rate=0.22257793724562236, max_delta_step=5, max_depth=14, n_estimators=53, subsample=0.42939811886786894; total time=   6.9s\n",
      "[CV] END learning_rate=0.4947923138822793, max_delta_step=9, max_depth=16, n_estimators=211, subsample=0.57660516520127; total time=  16.6s\n",
      "[CV] END learning_rate=0.4947923138822793, max_delta_step=9, max_depth=16, n_estimators=211, subsample=0.57660516520127; total time=  16.3s\n",
      "[CV] END learning_rate=0.4947923138822793, max_delta_step=9, max_depth=16, n_estimators=211, subsample=0.57660516520127; total time=  16.6s\n",
      "[CV] END learning_rate=0.4947923138822793, max_delta_step=9, max_depth=16, n_estimators=211, subsample=0.57660516520127; total time=  16.5s\n",
      "[CV] END learning_rate=0.4947923138822793, max_delta_step=9, max_depth=16, n_estimators=211, subsample=0.57660516520127; total time=  15.0s\n",
      "[CV] END learning_rate=0.4733294328968971, max_delta_step=7, max_depth=18, n_estimators=239, subsample=0.527731231534285; total time=  19.9s\n",
      "[CV] END learning_rate=0.4733294328968971, max_delta_step=7, max_depth=18, n_estimators=239, subsample=0.527731231534285; total time=  20.0s\n",
      "[CV] END learning_rate=0.4733294328968971, max_delta_step=7, max_depth=18, n_estimators=239, subsample=0.527731231534285; total time=  19.6s\n",
      "[CV] END learning_rate=0.4733294328968971, max_delta_step=7, max_depth=18, n_estimators=239, subsample=0.527731231534285; total time=  19.8s\n",
      "[CV] END learning_rate=0.4733294328968971, max_delta_step=7, max_depth=18, n_estimators=239, subsample=0.527731231534285; total time=  20.0s\n",
      "[CV] END learning_rate=0.204338644844741, max_delta_step=1, max_depth=19, n_estimators=102, subsample=0.7107258159646936; total time=  20.9s\n",
      "[CV] END learning_rate=0.204338644844741, max_delta_step=1, max_depth=19, n_estimators=102, subsample=0.7107258159646936; total time=  20.9s\n",
      "[CV] END learning_rate=0.204338644844741, max_delta_step=1, max_depth=19, n_estimators=102, subsample=0.7107258159646936; total time=  21.2s\n",
      "[CV] END learning_rate=0.204338644844741, max_delta_step=1, max_depth=19, n_estimators=102, subsample=0.7107258159646936; total time=  20.6s\n",
      "[CV] END learning_rate=0.204338644844741, max_delta_step=1, max_depth=19, n_estimators=102, subsample=0.7107258159646936; total time=  20.8s\n",
      "[CV] END learning_rate=0.492627653632069, max_delta_step=8, max_depth=17, n_estimators=64, subsample=0.4156868573441017; total time=  10.3s\n",
      "[CV] END learning_rate=0.492627653632069, max_delta_step=8, max_depth=17, n_estimators=64, subsample=0.4156868573441017; total time=  10.1s\n",
      "[CV] END learning_rate=0.492627653632069, max_delta_step=8, max_depth=17, n_estimators=64, subsample=0.4156868573441017; total time=  10.0s\n",
      "[CV] END learning_rate=0.492627653632069, max_delta_step=8, max_depth=17, n_estimators=64, subsample=0.4156868573441017; total time=  10.2s\n",
      "[CV] END learning_rate=0.492627653632069, max_delta_step=8, max_depth=17, n_estimators=64, subsample=0.4156868573441017; total time=  10.4s\n",
      "[CV] END learning_rate=0.017818203370596968, max_delta_step=8, max_depth=12, n_estimators=178, subsample=0.43910097707392065; total time=  17.5s\n",
      "[CV] END learning_rate=0.017818203370596968, max_delta_step=8, max_depth=12, n_estimators=178, subsample=0.43910097707392065; total time=  17.5s\n",
      "[CV] END learning_rate=0.017818203370596968, max_delta_step=8, max_depth=12, n_estimators=178, subsample=0.43910097707392065; total time=  17.4s\n",
      "[CV] END learning_rate=0.017818203370596968, max_delta_step=8, max_depth=12, n_estimators=178, subsample=0.43910097707392065; total time=  18.0s\n",
      "[CV] END learning_rate=0.017818203370596968, max_delta_step=8, max_depth=12, n_estimators=178, subsample=0.43910097707392065; total time=  17.1s\n",
      "[CV] END learning_rate=0.0127610585618012, max_delta_step=2, max_depth=5, n_estimators=185, subsample=0.810305017628691; total time=   1.3s\n",
      "[CV] END learning_rate=0.0127610585618012, max_delta_step=2, max_depth=5, n_estimators=185, subsample=0.810305017628691; total time=   1.2s\n",
      "[CV] END learning_rate=0.0127610585618012, max_delta_step=2, max_depth=5, n_estimators=185, subsample=0.810305017628691; total time=   1.2s\n",
      "[CV] END learning_rate=0.0127610585618012, max_delta_step=2, max_depth=5, n_estimators=185, subsample=0.810305017628691; total time=   1.1s\n",
      "[CV] END learning_rate=0.0127610585618012, max_delta_step=2, max_depth=5, n_estimators=185, subsample=0.810305017628691; total time=   1.6s\n",
      "[CV] END learning_rate=0.3956351733429729, max_delta_step=4, max_depth=14, n_estimators=90, subsample=0.9404717728806464; total time=  13.5s\n",
      "[CV] END learning_rate=0.3956351733429729, max_delta_step=4, max_depth=14, n_estimators=90, subsample=0.9404717728806464; total time=  13.6s\n",
      "[CV] END learning_rate=0.3956351733429729, max_delta_step=4, max_depth=14, n_estimators=90, subsample=0.9404717728806464; total time=  14.0s\n",
      "[CV] END learning_rate=0.3956351733429729, max_delta_step=4, max_depth=14, n_estimators=90, subsample=0.9404717728806464; total time=  13.2s\n",
      "[CV] END learning_rate=0.3956351733429729, max_delta_step=4, max_depth=14, n_estimators=90, subsample=0.9404717728806464; total time=  14.0s\n",
      "[CV] END learning_rate=0.43501928889489966, max_delta_step=1, max_depth=5, n_estimators=97, subsample=0.5595727765387865; total time=   0.6s\n",
      "[CV] END learning_rate=0.43501928889489966, max_delta_step=1, max_depth=5, n_estimators=97, subsample=0.5595727765387865; total time=   0.6s\n",
      "[CV] END learning_rate=0.43501928889489966, max_delta_step=1, max_depth=5, n_estimators=97, subsample=0.5595727765387865; total time=   0.7s\n",
      "[CV] END learning_rate=0.43501928889489966, max_delta_step=1, max_depth=5, n_estimators=97, subsample=0.5595727765387865; total time=   0.6s\n",
      "[CV] END learning_rate=0.43501928889489966, max_delta_step=1, max_depth=5, n_estimators=97, subsample=0.5595727765387865; total time=   0.7s\n",
      "[CV] END learning_rate=0.34442062633180365, max_delta_step=4, max_depth=7, n_estimators=221, subsample=0.7462902299486491; total time=   3.8s\n",
      "[CV] END learning_rate=0.34442062633180365, max_delta_step=4, max_depth=7, n_estimators=221, subsample=0.7462902299486491; total time=   3.9s\n",
      "[CV] END learning_rate=0.34442062633180365, max_delta_step=4, max_depth=7, n_estimators=221, subsample=0.7462902299486491; total time=   3.9s\n",
      "[CV] END learning_rate=0.34442062633180365, max_delta_step=4, max_depth=7, n_estimators=221, subsample=0.7462902299486491; total time=   3.8s\n",
      "[CV] END learning_rate=0.34442062633180365, max_delta_step=4, max_depth=7, n_estimators=221, subsample=0.7462902299486491; total time=   3.8s\n",
      "[CV] END learning_rate=0.4536063712881633, max_delta_step=0, max_depth=7, n_estimators=150, subsample=0.9801984667723727; total time=   2.8s\n",
      "[CV] END learning_rate=0.4536063712881633, max_delta_step=0, max_depth=7, n_estimators=150, subsample=0.9801984667723727; total time=   2.6s\n",
      "[CV] END learning_rate=0.4536063712881633, max_delta_step=0, max_depth=7, n_estimators=150, subsample=0.9801984667723727; total time=   2.6s\n",
      "[CV] END learning_rate=0.4536063712881633, max_delta_step=0, max_depth=7, n_estimators=150, subsample=0.9801984667723727; total time=   2.6s\n",
      "[CV] END learning_rate=0.4536063712881633, max_delta_step=0, max_depth=7, n_estimators=150, subsample=0.9801984667723727; total time=   2.5s\n",
      "[CV] END learning_rate=0.43445691213304194, max_delta_step=4, max_depth=14, n_estimators=191, subsample=0.6456569174550735; total time=  16.2s\n",
      "[CV] END learning_rate=0.43445691213304194, max_delta_step=4, max_depth=14, n_estimators=191, subsample=0.6456569174550735; total time=  16.0s\n",
      "[CV] END learning_rate=0.43445691213304194, max_delta_step=4, max_depth=14, n_estimators=191, subsample=0.6456569174550735; total time=  15.8s\n",
      "[CV] END learning_rate=0.43445691213304194, max_delta_step=4, max_depth=14, n_estimators=191, subsample=0.6456569174550735; total time=  16.2s\n",
      "[CV] END learning_rate=0.43445691213304194, max_delta_step=4, max_depth=14, n_estimators=191, subsample=0.6456569174550735; total time=  15.9s\n",
      "[CV] END learning_rate=0.27136641469099704, max_delta_step=9, max_depth=14, n_estimators=173, subsample=0.37552399889531307; total time=  18.4s\n",
      "[CV] END learning_rate=0.27136641469099704, max_delta_step=9, max_depth=14, n_estimators=173, subsample=0.37552399889531307; total time=  18.2s\n",
      "[CV] END learning_rate=0.27136641469099704, max_delta_step=9, max_depth=14, n_estimators=173, subsample=0.37552399889531307; total time=  18.5s\n",
      "[CV] END learning_rate=0.27136641469099704, max_delta_step=9, max_depth=14, n_estimators=173, subsample=0.37552399889531307; total time=  18.0s\n",
      "[CV] END learning_rate=0.27136641469099704, max_delta_step=9, max_depth=14, n_estimators=173, subsample=0.37552399889531307; total time=  18.3s\n",
      "[CV] END learning_rate=0.025714592843367128, max_delta_step=6, max_depth=5, n_estimators=101, subsample=0.6942929003834686; total time=   0.6s\n",
      "[CV] END learning_rate=0.025714592843367128, max_delta_step=6, max_depth=5, n_estimators=101, subsample=0.6942929003834686; total time=   0.8s\n",
      "[CV] END learning_rate=0.025714592843367128, max_delta_step=6, max_depth=5, n_estimators=101, subsample=0.6942929003834686; total time=   0.7s\n",
      "[CV] END learning_rate=0.025714592843367128, max_delta_step=6, max_depth=5, n_estimators=101, subsample=0.6942929003834686; total time=   0.6s\n",
      "[CV] END learning_rate=0.025714592843367128, max_delta_step=6, max_depth=5, n_estimators=101, subsample=0.6942929003834686; total time=   0.7s\n",
      "[CV] END learning_rate=0.35775804321306376, max_delta_step=4, max_depth=11, n_estimators=192, subsample=0.828885796980134; total time=  12.4s\n",
      "[CV] END learning_rate=0.35775804321306376, max_delta_step=4, max_depth=11, n_estimators=192, subsample=0.828885796980134; total time=  12.6s\n",
      "[CV] END learning_rate=0.35775804321306376, max_delta_step=4, max_depth=11, n_estimators=192, subsample=0.828885796980134; total time=  12.2s\n",
      "[CV] END learning_rate=0.35775804321306376, max_delta_step=4, max_depth=11, n_estimators=192, subsample=0.828885796980134; total time=  12.3s\n",
      "[CV] END learning_rate=0.35775804321306376, max_delta_step=4, max_depth=11, n_estimators=192, subsample=0.828885796980134; total time=  12.7s\n",
      "[CV] END learning_rate=0.12439908274581123, max_delta_step=6, max_depth=15, n_estimators=135, subsample=0.9163274873106804; total time=  29.2s\n",
      "[CV] END learning_rate=0.12439908274581123, max_delta_step=6, max_depth=15, n_estimators=135, subsample=0.9163274873106804; total time=  29.7s\n",
      "[CV] END learning_rate=0.12439908274581123, max_delta_step=6, max_depth=15, n_estimators=135, subsample=0.9163274873106804; total time=  29.0s\n",
      "[CV] END learning_rate=0.12439908274581123, max_delta_step=6, max_depth=15, n_estimators=135, subsample=0.9163274873106804; total time=  28.7s\n",
      "[CV] END learning_rate=0.12439908274581123, max_delta_step=6, max_depth=15, n_estimators=135, subsample=0.9163274873106804; total time=  30.6s\n",
      "[CV] END learning_rate=0.32217702406689663, max_delta_step=8, max_depth=9, n_estimators=183, subsample=0.6195741993380371; total time=   7.7s\n",
      "[CV] END learning_rate=0.32217702406689663, max_delta_step=8, max_depth=9, n_estimators=183, subsample=0.6195741993380371; total time=   8.0s\n",
      "[CV] END learning_rate=0.32217702406689663, max_delta_step=8, max_depth=9, n_estimators=183, subsample=0.6195741993380371; total time=   7.9s\n",
      "[CV] END learning_rate=0.32217702406689663, max_delta_step=8, max_depth=9, n_estimators=183, subsample=0.6195741993380371; total time=   8.1s\n",
      "[CV] END learning_rate=0.32217702406689663, max_delta_step=8, max_depth=9, n_estimators=183, subsample=0.6195741993380371; total time=   8.3s\n",
      "[CV] END learning_rate=0.11922021860841679, max_delta_step=3, max_depth=18, n_estimators=239, subsample=0.6775395693409555; total time=  49.3s\n",
      "[CV] END learning_rate=0.11922021860841679, max_delta_step=3, max_depth=18, n_estimators=239, subsample=0.6775395693409555; total time=  46.2s\n",
      "[CV] END learning_rate=0.11922021860841679, max_delta_step=3, max_depth=18, n_estimators=239, subsample=0.6775395693409555; total time=  47.0s\n",
      "[CV] END learning_rate=0.11922021860841679, max_delta_step=3, max_depth=18, n_estimators=239, subsample=0.6775395693409555; total time=  46.4s\n",
      "[CV] END learning_rate=0.11922021860841679, max_delta_step=3, max_depth=18, n_estimators=239, subsample=0.6775395693409555; total time=  47.9s\n",
      "[CV] END learning_rate=0.4137200775820313, max_delta_step=8, max_depth=11, n_estimators=239, subsample=0.37703634716937373; total time=  15.4s\n",
      "[CV] END learning_rate=0.4137200775820313, max_delta_step=8, max_depth=11, n_estimators=239, subsample=0.37703634716937373; total time=  15.6s\n",
      "[CV] END learning_rate=0.4137200775820313, max_delta_step=8, max_depth=11, n_estimators=239, subsample=0.37703634716937373; total time=  15.5s\n",
      "[CV] END learning_rate=0.4137200775820313, max_delta_step=8, max_depth=11, n_estimators=239, subsample=0.37703634716937373; total time=  15.5s\n",
      "[CV] END learning_rate=0.4137200775820313, max_delta_step=8, max_depth=11, n_estimators=239, subsample=0.37703634716937373; total time=  15.0s\n",
      "[CV] END learning_rate=0.12396758127097084, max_delta_step=8, max_depth=8, n_estimators=52, subsample=0.30486649137183347; total time=   1.4s\n",
      "[CV] END learning_rate=0.12396758127097084, max_delta_step=8, max_depth=8, n_estimators=52, subsample=0.30486649137183347; total time=   1.2s\n",
      "[CV] END learning_rate=0.12396758127097084, max_delta_step=8, max_depth=8, n_estimators=52, subsample=0.30486649137183347; total time=   1.3s\n",
      "[CV] END learning_rate=0.12396758127097084, max_delta_step=8, max_depth=8, n_estimators=52, subsample=0.30486649137183347; total time=   1.2s\n",
      "[CV] END learning_rate=0.12396758127097084, max_delta_step=8, max_depth=8, n_estimators=52, subsample=0.30486649137183347; total time=   1.2s\n",
      "[CV] END learning_rate=0.2653736512887829, max_delta_step=8, max_depth=18, n_estimators=214, subsample=0.7847052230231892; total time=  25.0s\n",
      "[CV] END learning_rate=0.2653736512887829, max_delta_step=8, max_depth=18, n_estimators=214, subsample=0.7847052230231892; total time=  24.4s\n",
      "[CV] END learning_rate=0.2653736512887829, max_delta_step=8, max_depth=18, n_estimators=214, subsample=0.7847052230231892; total time=  24.8s\n",
      "[CV] END learning_rate=0.2653736512887829, max_delta_step=8, max_depth=18, n_estimators=214, subsample=0.7847052230231892; total time=  25.1s\n",
      "[CV] END learning_rate=0.2653736512887829, max_delta_step=8, max_depth=18, n_estimators=214, subsample=0.7847052230231892; total time=  25.0s\n",
      "[CV] END learning_rate=0.14470616689926075, max_delta_step=7, max_depth=19, n_estimators=108, subsample=0.5262420524145286; total time=  24.7s\n",
      "[CV] END learning_rate=0.14470616689926075, max_delta_step=7, max_depth=19, n_estimators=108, subsample=0.5262420524145286; total time=  23.7s\n",
      "[CV] END learning_rate=0.14470616689926075, max_delta_step=7, max_depth=19, n_estimators=108, subsample=0.5262420524145286; total time=  23.9s\n",
      "[CV] END learning_rate=0.14470616689926075, max_delta_step=7, max_depth=19, n_estimators=108, subsample=0.5262420524145286; total time=  24.3s\n",
      "[CV] END learning_rate=0.14470616689926075, max_delta_step=7, max_depth=19, n_estimators=108, subsample=0.5262420524145286; total time=  23.7s\n",
      "[CV] END learning_rate=0.26939531087168306, max_delta_step=8, max_depth=8, n_estimators=162, subsample=0.3454245729762871; total time=   4.3s\n",
      "[CV] END learning_rate=0.26939531087168306, max_delta_step=8, max_depth=8, n_estimators=162, subsample=0.3454245729762871; total time=   4.2s\n",
      "[CV] END learning_rate=0.26939531087168306, max_delta_step=8, max_depth=8, n_estimators=162, subsample=0.3454245729762871; total time=   4.1s\n",
      "[CV] END learning_rate=0.26939531087168306, max_delta_step=8, max_depth=8, n_estimators=162, subsample=0.3454245729762871; total time=   4.2s\n",
      "[CV] END learning_rate=0.26939531087168306, max_delta_step=8, max_depth=8, n_estimators=162, subsample=0.3454245729762871; total time=   4.2s\n",
      "[CV] END learning_rate=0.13695770696717235, max_delta_step=6, max_depth=6, n_estimators=180, subsample=0.5106148168717387; total time=   1.9s\n",
      "[CV] END learning_rate=0.13695770696717235, max_delta_step=6, max_depth=6, n_estimators=180, subsample=0.5106148168717387; total time=   1.8s\n",
      "[CV] END learning_rate=0.13695770696717235, max_delta_step=6, max_depth=6, n_estimators=180, subsample=0.5106148168717387; total time=   2.0s\n",
      "[CV] END learning_rate=0.13695770696717235, max_delta_step=6, max_depth=6, n_estimators=180, subsample=0.5106148168717387; total time=   2.0s\n",
      "[CV] END learning_rate=0.13695770696717235, max_delta_step=6, max_depth=6, n_estimators=180, subsample=0.5106148168717387; total time=   2.0s\n",
      "[CV] END learning_rate=0.15242024718873382, max_delta_step=0, max_depth=15, n_estimators=162, subsample=0.983630469082857; total time=  30.0s\n",
      "[CV] END learning_rate=0.15242024718873382, max_delta_step=0, max_depth=15, n_estimators=162, subsample=0.983630469082857; total time=  31.3s\n",
      "[CV] END learning_rate=0.15242024718873382, max_delta_step=0, max_depth=15, n_estimators=162, subsample=0.983630469082857; total time=  31.0s\n",
      "[CV] END learning_rate=0.15242024718873382, max_delta_step=0, max_depth=15, n_estimators=162, subsample=0.983630469082857; total time=  30.6s\n",
      "[CV] END learning_rate=0.15242024718873382, max_delta_step=0, max_depth=15, n_estimators=162, subsample=0.983630469082857; total time=  31.9s\n",
      "[CV] END learning_rate=0.21551850665911565, max_delta_step=6, max_depth=9, n_estimators=178, subsample=0.46769332346688064; total time=   7.3s\n",
      "[CV] END learning_rate=0.21551850665911565, max_delta_step=6, max_depth=9, n_estimators=178, subsample=0.46769332346688064; total time=   7.2s\n",
      "[CV] END learning_rate=0.21551850665911565, max_delta_step=6, max_depth=9, n_estimators=178, subsample=0.46769332346688064; total time=   7.3s\n",
      "[CV] END learning_rate=0.21551850665911565, max_delta_step=6, max_depth=9, n_estimators=178, subsample=0.46769332346688064; total time=   7.4s\n",
      "[CV] END learning_rate=0.21551850665911565, max_delta_step=6, max_depth=9, n_estimators=178, subsample=0.46769332346688064; total time=   7.1s\n",
      "[CV] END learning_rate=0.08244743604561154, max_delta_step=9, max_depth=10, n_estimators=209, subsample=0.7148877067155754; total time=  13.4s\n",
      "[CV] END learning_rate=0.08244743604561154, max_delta_step=9, max_depth=10, n_estimators=209, subsample=0.7148877067155754; total time=  13.9s\n",
      "[CV] END learning_rate=0.08244743604561154, max_delta_step=9, max_depth=10, n_estimators=209, subsample=0.7148877067155754; total time=  13.3s\n",
      "[CV] END learning_rate=0.08244743604561154, max_delta_step=9, max_depth=10, n_estimators=209, subsample=0.7148877067155754; total time=  13.5s\n",
      "[CV] END learning_rate=0.08244743604561154, max_delta_step=9, max_depth=10, n_estimators=209, subsample=0.7148877067155754; total time=  13.3s\n",
      "[CV] END learning_rate=0.050426663166357626, max_delta_step=7, max_depth=15, n_estimators=194, subsample=0.8097514440283016; total time=  40.9s\n",
      "[CV] END learning_rate=0.050426663166357626, max_delta_step=7, max_depth=15, n_estimators=194, subsample=0.8097514440283016; total time=  40.1s\n",
      "[CV] END learning_rate=0.050426663166357626, max_delta_step=7, max_depth=15, n_estimators=194, subsample=0.8097514440283016; total time=  40.2s\n",
      "[CV] END learning_rate=0.050426663166357626, max_delta_step=7, max_depth=15, n_estimators=194, subsample=0.8097514440283016; total time=  40.4s\n",
      "[CV] END learning_rate=0.050426663166357626, max_delta_step=7, max_depth=15, n_estimators=194, subsample=0.8097514440283016; total time=  40.5s\n",
      "[CV] END learning_rate=0.19389156635962662, max_delta_step=3, max_depth=6, n_estimators=247, subsample=0.5791771097111871; total time=   2.7s\n",
      "[CV] END learning_rate=0.19389156635962662, max_delta_step=3, max_depth=6, n_estimators=247, subsample=0.5791771097111871; total time=   2.7s\n",
      "[CV] END learning_rate=0.19389156635962662, max_delta_step=3, max_depth=6, n_estimators=247, subsample=0.5791771097111871; total time=   2.8s\n",
      "[CV] END learning_rate=0.19389156635962662, max_delta_step=3, max_depth=6, n_estimators=247, subsample=0.5791771097111871; total time=   2.8s\n",
      "[CV] END learning_rate=0.19389156635962662, max_delta_step=3, max_depth=6, n_estimators=247, subsample=0.5791771097111871; total time=   2.7s\n",
      "[CV] END learning_rate=0.418215936609692, max_delta_step=0, max_depth=13, n_estimators=173, subsample=0.6557391437185031; total time=  14.1s\n",
      "[CV] END learning_rate=0.418215936609692, max_delta_step=0, max_depth=13, n_estimators=173, subsample=0.6557391437185031; total time=  13.3s\n",
      "[CV] END learning_rate=0.418215936609692, max_delta_step=0, max_depth=13, n_estimators=173, subsample=0.6557391437185031; total time=  13.6s\n",
      "[CV] END learning_rate=0.418215936609692, max_delta_step=0, max_depth=13, n_estimators=173, subsample=0.6557391437185031; total time=  13.7s\n",
      "[CV] END learning_rate=0.418215936609692, max_delta_step=0, max_depth=13, n_estimators=173, subsample=0.6557391437185031; total time=  13.7s\n",
      "[CV] END learning_rate=0.35790640339544094, max_delta_step=2, max_depth=8, n_estimators=236, subsample=0.4541687332958838; total time=   6.7s\n",
      "[CV] END learning_rate=0.35790640339544094, max_delta_step=2, max_depth=8, n_estimators=236, subsample=0.4541687332958838; total time=   6.3s\n",
      "[CV] END learning_rate=0.35790640339544094, max_delta_step=2, max_depth=8, n_estimators=236, subsample=0.4541687332958838; total time=   6.4s\n",
      "[CV] END learning_rate=0.35790640339544094, max_delta_step=2, max_depth=8, n_estimators=236, subsample=0.4541687332958838; total time=   6.4s\n",
      "[CV] END learning_rate=0.35790640339544094, max_delta_step=2, max_depth=8, n_estimators=236, subsample=0.4541687332958838; total time=   6.5s\n",
      "[CV] END learning_rate=0.3655747662190089, max_delta_step=2, max_depth=8, n_estimators=145, subsample=0.3673235857639945; total time=   3.9s\n",
      "[CV] END learning_rate=0.3655747662190089, max_delta_step=2, max_depth=8, n_estimators=145, subsample=0.3673235857639945; total time=   4.0s\n",
      "[CV] END learning_rate=0.3655747662190089, max_delta_step=2, max_depth=8, n_estimators=145, subsample=0.3673235857639945; total time=   4.2s\n",
      "[CV] END learning_rate=0.3655747662190089, max_delta_step=2, max_depth=8, n_estimators=145, subsample=0.3673235857639945; total time=   4.0s\n",
      "[CV] END learning_rate=0.3655747662190089, max_delta_step=2, max_depth=8, n_estimators=145, subsample=0.3673235857639945; total time=   3.9s\n",
      "[CV] END learning_rate=0.480261632244802, max_delta_step=7, max_depth=11, n_estimators=131, subsample=0.8863970741351295; total time=   8.6s\n",
      "[CV] END learning_rate=0.480261632244802, max_delta_step=7, max_depth=11, n_estimators=131, subsample=0.8863970741351295; total time=   9.1s\n",
      "[CV] END learning_rate=0.480261632244802, max_delta_step=7, max_depth=11, n_estimators=131, subsample=0.8863970741351295; total time=   8.6s\n",
      "[CV] END learning_rate=0.480261632244802, max_delta_step=7, max_depth=11, n_estimators=131, subsample=0.8863970741351295; total time=   8.8s\n",
      "[CV] END learning_rate=0.480261632244802, max_delta_step=7, max_depth=11, n_estimators=131, subsample=0.8863970741351295; total time=   8.5s\n",
      "[CV] END learning_rate=0.34784505851964037, max_delta_step=8, max_depth=13, n_estimators=227, subsample=0.9472855327949938; total time=  13.3s\n",
      "[CV] END learning_rate=0.34784505851964037, max_delta_step=8, max_depth=13, n_estimators=227, subsample=0.9472855327949938; total time=  13.4s\n",
      "[CV] END learning_rate=0.34784505851964037, max_delta_step=8, max_depth=13, n_estimators=227, subsample=0.9472855327949938; total time=  13.1s\n",
      "[CV] END learning_rate=0.34784505851964037, max_delta_step=8, max_depth=13, n_estimators=227, subsample=0.9472855327949938; total time=  13.0s\n",
      "[CV] END learning_rate=0.34784505851964037, max_delta_step=8, max_depth=13, n_estimators=227, subsample=0.9472855327949938; total time=  13.2s\n",
      "[CV] END learning_rate=0.4486696766904905, max_delta_step=2, max_depth=11, n_estimators=193, subsample=0.872055540140851; total time=  12.1s\n",
      "[CV] END learning_rate=0.4486696766904905, max_delta_step=2, max_depth=11, n_estimators=193, subsample=0.872055540140851; total time=  11.3s\n",
      "[CV] END learning_rate=0.4486696766904905, max_delta_step=2, max_depth=11, n_estimators=193, subsample=0.872055540140851; total time=  12.1s\n",
      "[CV] END learning_rate=0.4486696766904905, max_delta_step=2, max_depth=11, n_estimators=193, subsample=0.872055540140851; total time=  12.3s\n",
      "[CV] END learning_rate=0.4486696766904905, max_delta_step=2, max_depth=11, n_estimators=193, subsample=0.872055540140851; total time=  12.2s\n",
      "[CV] END learning_rate=0.2876004057997312, max_delta_step=0, max_depth=6, n_estimators=178, subsample=0.36517193746412946; total time=   1.9s\n",
      "[CV] END learning_rate=0.2876004057997312, max_delta_step=0, max_depth=6, n_estimators=178, subsample=0.36517193746412946; total time=   1.9s\n",
      "[CV] END learning_rate=0.2876004057997312, max_delta_step=0, max_depth=6, n_estimators=178, subsample=0.36517193746412946; total time=   1.9s\n",
      "[CV] END learning_rate=0.2876004057997312, max_delta_step=0, max_depth=6, n_estimators=178, subsample=0.36517193746412946; total time=   1.8s\n",
      "[CV] END learning_rate=0.2876004057997312, max_delta_step=0, max_depth=6, n_estimators=178, subsample=0.36517193746412946; total time=   1.9s\n",
      "[CV] END learning_rate=0.4586078789766634, max_delta_step=4, max_depth=15, n_estimators=58, subsample=0.4952099468145273; total time=   8.8s\n",
      "[CV] END learning_rate=0.4586078789766634, max_delta_step=4, max_depth=15, n_estimators=58, subsample=0.4952099468145273; total time=   9.3s\n",
      "[CV] END learning_rate=0.4586078789766634, max_delta_step=4, max_depth=15, n_estimators=58, subsample=0.4952099468145273; total time=   8.3s\n",
      "[CV] END learning_rate=0.4586078789766634, max_delta_step=4, max_depth=15, n_estimators=58, subsample=0.4952099468145273; total time=   9.1s\n",
      "[CV] END learning_rate=0.4586078789766634, max_delta_step=4, max_depth=15, n_estimators=58, subsample=0.4952099468145273; total time=   9.0s\n",
      "[CV] END learning_rate=0.36017891498638566, max_delta_step=2, max_depth=8, n_estimators=201, subsample=0.583155688985533; total time=   6.2s\n",
      "[CV] END learning_rate=0.36017891498638566, max_delta_step=2, max_depth=8, n_estimators=201, subsample=0.583155688985533; total time=   5.6s\n",
      "[CV] END learning_rate=0.36017891498638566, max_delta_step=2, max_depth=8, n_estimators=201, subsample=0.583155688985533; total time=   5.8s\n",
      "[CV] END learning_rate=0.36017891498638566, max_delta_step=2, max_depth=8, n_estimators=201, subsample=0.583155688985533; total time=   5.9s\n",
      "[CV] END learning_rate=0.36017891498638566, max_delta_step=2, max_depth=8, n_estimators=201, subsample=0.583155688985533; total time=   5.7s\n",
      "[CV] END learning_rate=0.4538850493804799, max_delta_step=3, max_depth=15, n_estimators=162, subsample=0.4131400998662296; total time=  18.3s\n",
      "[CV] END learning_rate=0.4538850493804799, max_delta_step=3, max_depth=15, n_estimators=162, subsample=0.4131400998662296; total time=  17.7s\n",
      "[CV] END learning_rate=0.4538850493804799, max_delta_step=3, max_depth=15, n_estimators=162, subsample=0.4131400998662296; total time=  18.7s\n",
      "[CV] END learning_rate=0.4538850493804799, max_delta_step=3, max_depth=15, n_estimators=162, subsample=0.4131400998662296; total time=  17.0s\n",
      "[CV] END learning_rate=0.4538850493804799, max_delta_step=3, max_depth=15, n_estimators=162, subsample=0.4131400998662296; total time=  19.4s\n",
      "[CV] END learning_rate=0.45927709426353963, max_delta_step=3, max_depth=18, n_estimators=161, subsample=0.37103008000622245; total time=  24.2s\n",
      "[CV] END learning_rate=0.45927709426353963, max_delta_step=3, max_depth=18, n_estimators=161, subsample=0.37103008000622245; total time=  22.6s\n",
      "[CV] END learning_rate=0.45927709426353963, max_delta_step=3, max_depth=18, n_estimators=161, subsample=0.37103008000622245; total time=  21.5s\n",
      "[CV] END learning_rate=0.45927709426353963, max_delta_step=3, max_depth=18, n_estimators=161, subsample=0.37103008000622245; total time=  21.5s\n",
      "[CV] END learning_rate=0.45927709426353963, max_delta_step=3, max_depth=18, n_estimators=161, subsample=0.37103008000622245; total time=  22.8s\n",
      "[CV] END learning_rate=0.3417508845540279, max_delta_step=1, max_depth=18, n_estimators=131, subsample=0.6399296275103585; total time=  32.6s\n",
      "[CV] END learning_rate=0.3417508845540279, max_delta_step=1, max_depth=18, n_estimators=131, subsample=0.6399296275103585; total time=  33.5s\n",
      "[CV] END learning_rate=0.3417508845540279, max_delta_step=1, max_depth=18, n_estimators=131, subsample=0.6399296275103585; total time=  33.1s\n",
      "[CV] END learning_rate=0.3417508845540279, max_delta_step=1, max_depth=18, n_estimators=131, subsample=0.6399296275103585; total time=  33.0s\n",
      "[CV] END learning_rate=0.3417508845540279, max_delta_step=1, max_depth=18, n_estimators=131, subsample=0.6399296275103585; total time=  32.7s\n",
      "[CV] END learning_rate=0.23421207149312367, max_delta_step=8, max_depth=8, n_estimators=210, subsample=0.3126527545308646; total time=   5.5s\n",
      "[CV] END learning_rate=0.23421207149312367, max_delta_step=8, max_depth=8, n_estimators=210, subsample=0.3126527545308646; total time=   5.6s\n",
      "[CV] END learning_rate=0.23421207149312367, max_delta_step=8, max_depth=8, n_estimators=210, subsample=0.3126527545308646; total time=   5.5s\n",
      "[CV] END learning_rate=0.23421207149312367, max_delta_step=8, max_depth=8, n_estimators=210, subsample=0.3126527545308646; total time=   5.6s\n",
      "[CV] END learning_rate=0.23421207149312367, max_delta_step=8, max_depth=8, n_estimators=210, subsample=0.3126527545308646; total time=   5.4s\n",
      "[CV] END learning_rate=0.2569468575917173, max_delta_step=3, max_depth=12, n_estimators=177, subsample=0.8209193661395935; total time=  19.3s\n",
      "[CV] END learning_rate=0.2569468575917173, max_delta_step=3, max_depth=12, n_estimators=177, subsample=0.8209193661395935; total time=  19.3s\n",
      "[CV] END learning_rate=0.2569468575917173, max_delta_step=3, max_depth=12, n_estimators=177, subsample=0.8209193661395935; total time=  19.2s\n",
      "[CV] END learning_rate=0.2569468575917173, max_delta_step=3, max_depth=12, n_estimators=177, subsample=0.8209193661395935; total time=  18.1s\n",
      "[CV] END learning_rate=0.2569468575917173, max_delta_step=3, max_depth=12, n_estimators=177, subsample=0.8209193661395935; total time=  20.6s\n",
      "[CV] END learning_rate=0.37046996212606464, max_delta_step=0, max_depth=16, n_estimators=236, subsample=0.5574010621416035; total time=  21.3s\n",
      "[CV] END learning_rate=0.37046996212606464, max_delta_step=0, max_depth=16, n_estimators=236, subsample=0.5574010621416035; total time=  19.7s\n",
      "[CV] END learning_rate=0.37046996212606464, max_delta_step=0, max_depth=16, n_estimators=236, subsample=0.5574010621416035; total time=  20.3s\n",
      "[CV] END learning_rate=0.37046996212606464, max_delta_step=0, max_depth=16, n_estimators=236, subsample=0.5574010621416035; total time=  20.3s\n",
      "[CV] END learning_rate=0.37046996212606464, max_delta_step=0, max_depth=16, n_estimators=236, subsample=0.5574010621416035; total time=  20.6s\n",
      "[CV] END learning_rate=0.14260118384086273, max_delta_step=5, max_depth=10, n_estimators=158, subsample=0.6407195070716185; total time=   9.9s\n",
      "[CV] END learning_rate=0.14260118384086273, max_delta_step=5, max_depth=10, n_estimators=158, subsample=0.6407195070716185; total time=  10.3s\n",
      "[CV] END learning_rate=0.14260118384086273, max_delta_step=5, max_depth=10, n_estimators=158, subsample=0.6407195070716185; total time=   9.8s\n",
      "[CV] END learning_rate=0.14260118384086273, max_delta_step=5, max_depth=10, n_estimators=158, subsample=0.6407195070716185; total time=  10.1s\n",
      "[CV] END learning_rate=0.14260118384086273, max_delta_step=5, max_depth=10, n_estimators=158, subsample=0.6407195070716185; total time=  10.1s\n",
      "[CV] END learning_rate=0.463049393859277, max_delta_step=1, max_depth=9, n_estimators=79, subsample=0.7515723534213954; total time=   4.2s\n",
      "[CV] END learning_rate=0.463049393859277, max_delta_step=1, max_depth=9, n_estimators=79, subsample=0.7515723534213954; total time=   4.0s\n",
      "[CV] END learning_rate=0.463049393859277, max_delta_step=1, max_depth=9, n_estimators=79, subsample=0.7515723534213954; total time=   4.0s\n",
      "[CV] END learning_rate=0.463049393859277, max_delta_step=1, max_depth=9, n_estimators=79, subsample=0.7515723534213954; total time=   4.0s\n",
      "[CV] END learning_rate=0.463049393859277, max_delta_step=1, max_depth=9, n_estimators=79, subsample=0.7515723534213954; total time=   4.0s\n",
      "[CV] END learning_rate=0.34446202983154983, max_delta_step=0, max_depth=9, n_estimators=110, subsample=0.6494353659193266; total time=   4.7s\n",
      "[CV] END learning_rate=0.34446202983154983, max_delta_step=0, max_depth=9, n_estimators=110, subsample=0.6494353659193266; total time=   5.3s\n",
      "[CV] END learning_rate=0.34446202983154983, max_delta_step=0, max_depth=9, n_estimators=110, subsample=0.6494353659193266; total time=   5.1s\n",
      "[CV] END learning_rate=0.34446202983154983, max_delta_step=0, max_depth=9, n_estimators=110, subsample=0.6494353659193266; total time=   5.0s\n",
      "[CV] END learning_rate=0.34446202983154983, max_delta_step=0, max_depth=9, n_estimators=110, subsample=0.6494353659193266; total time=   5.2s\n",
      "[CV] END learning_rate=0.29600209960459156, max_delta_step=0, max_depth=5, n_estimators=221, subsample=0.95832100904704; total time=   1.5s\n",
      "[CV] END learning_rate=0.29600209960459156, max_delta_step=0, max_depth=5, n_estimators=221, subsample=0.95832100904704; total time=   1.7s\n",
      "[CV] END learning_rate=0.29600209960459156, max_delta_step=0, max_depth=5, n_estimators=221, subsample=0.95832100904704; total time=   1.3s\n",
      "[CV] END learning_rate=0.29600209960459156, max_delta_step=0, max_depth=5, n_estimators=221, subsample=0.95832100904704; total time=   1.5s\n",
      "[CV] END learning_rate=0.29600209960459156, max_delta_step=0, max_depth=5, n_estimators=221, subsample=0.95832100904704; total time=   1.5s\n",
      "[CV] END learning_rate=0.4869642885012937, max_delta_step=4, max_depth=10, n_estimators=148, subsample=0.8234031417281897; total time=   9.6s\n",
      "[CV] END learning_rate=0.4869642885012937, max_delta_step=4, max_depth=10, n_estimators=148, subsample=0.8234031417281897; total time=   9.0s\n",
      "[CV] END learning_rate=0.4869642885012937, max_delta_step=4, max_depth=10, n_estimators=148, subsample=0.8234031417281897; total time=   8.8s\n",
      "[CV] END learning_rate=0.4869642885012937, max_delta_step=4, max_depth=10, n_estimators=148, subsample=0.8234031417281897; total time=   8.8s\n",
      "[CV] END learning_rate=0.4869642885012937, max_delta_step=4, max_depth=10, n_estimators=148, subsample=0.8234031417281897; total time=   9.2s\n",
      "[CV] END learning_rate=0.4865359235119766, max_delta_step=0, max_depth=18, n_estimators=230, subsample=0.7006047284195868; total time=  15.6s\n",
      "[CV] END learning_rate=0.4865359235119766, max_delta_step=0, max_depth=18, n_estimators=230, subsample=0.7006047284195868; total time=  15.3s\n",
      "[CV] END learning_rate=0.4865359235119766, max_delta_step=0, max_depth=18, n_estimators=230, subsample=0.7006047284195868; total time=  15.2s\n",
      "[CV] END learning_rate=0.4865359235119766, max_delta_step=0, max_depth=18, n_estimators=230, subsample=0.7006047284195868; total time=  15.3s\n",
      "[CV] END learning_rate=0.4865359235119766, max_delta_step=0, max_depth=18, n_estimators=230, subsample=0.7006047284195868; total time=  16.1s\n",
      "[CV] END learning_rate=0.5001657918580228, max_delta_step=3, max_depth=19, n_estimators=209, subsample=0.8957956700617997; total time=  21.0s\n",
      "[CV] END learning_rate=0.5001657918580228, max_delta_step=3, max_depth=19, n_estimators=209, subsample=0.8957956700617997; total time=  19.9s\n",
      "[CV] END learning_rate=0.5001657918580228, max_delta_step=3, max_depth=19, n_estimators=209, subsample=0.8957956700617997; total time=  20.1s\n",
      "[CV] END learning_rate=0.5001657918580228, max_delta_step=3, max_depth=19, n_estimators=209, subsample=0.8957956700617997; total time=  20.3s\n",
      "[CV] END learning_rate=0.5001657918580228, max_delta_step=3, max_depth=19, n_estimators=209, subsample=0.8957956700617997; total time=  20.5s\n",
      "[CV] END learning_rate=0.16846100257813884, max_delta_step=1, max_depth=13, n_estimators=103, subsample=0.7872208576724811; total time=  12.7s\n",
      "[CV] END learning_rate=0.16846100257813884, max_delta_step=1, max_depth=13, n_estimators=103, subsample=0.7872208576724811; total time=  12.7s\n",
      "[CV] END learning_rate=0.16846100257813884, max_delta_step=1, max_depth=13, n_estimators=103, subsample=0.7872208576724811; total time=  12.3s\n",
      "[CV] END learning_rate=0.16846100257813884, max_delta_step=1, max_depth=13, n_estimators=103, subsample=0.7872208576724811; total time=  12.8s\n",
      "[CV] END learning_rate=0.16846100257813884, max_delta_step=1, max_depth=13, n_estimators=103, subsample=0.7872208576724811; total time=  12.7s\n",
      "[CV] END learning_rate=0.2950305850446825, max_delta_step=7, max_depth=6, n_estimators=81, subsample=0.7698004617768354; total time=   1.0s\n",
      "[CV] END learning_rate=0.2950305850446825, max_delta_step=7, max_depth=6, n_estimators=81, subsample=0.7698004617768354; total time=   1.0s\n",
      "[CV] END learning_rate=0.2950305850446825, max_delta_step=7, max_depth=6, n_estimators=81, subsample=0.7698004617768354; total time=   0.9s\n",
      "[CV] END learning_rate=0.2950305850446825, max_delta_step=7, max_depth=6, n_estimators=81, subsample=0.7698004617768354; total time=   1.1s\n",
      "[CV] END learning_rate=0.2950305850446825, max_delta_step=7, max_depth=6, n_estimators=81, subsample=0.7698004617768354; total time=   0.9s\n",
      "[CV] END learning_rate=0.18932339064808196, max_delta_step=9, max_depth=6, n_estimators=66, subsample=0.8940688564472721; total time=   0.8s\n",
      "[CV] END learning_rate=0.18932339064808196, max_delta_step=9, max_depth=6, n_estimators=66, subsample=0.8940688564472721; total time=   0.8s\n",
      "[CV] END learning_rate=0.18932339064808196, max_delta_step=9, max_depth=6, n_estimators=66, subsample=0.8940688564472721; total time=   0.8s\n",
      "[CV] END learning_rate=0.18932339064808196, max_delta_step=9, max_depth=6, n_estimators=66, subsample=0.8940688564472721; total time=   0.8s\n",
      "[CV] END learning_rate=0.18932339064808196, max_delta_step=9, max_depth=6, n_estimators=66, subsample=0.8940688564472721; total time=   0.7s\n",
      "[CV] END learning_rate=0.0783106657210144, max_delta_step=5, max_depth=11, n_estimators=219, subsample=0.8665528088349594; total time=  21.0s\n",
      "[CV] END learning_rate=0.0783106657210144, max_delta_step=5, max_depth=11, n_estimators=219, subsample=0.8665528088349594; total time=  20.7s\n",
      "[CV] END learning_rate=0.0783106657210144, max_delta_step=5, max_depth=11, n_estimators=219, subsample=0.8665528088349594; total time=  20.7s\n",
      "[CV] END learning_rate=0.0783106657210144, max_delta_step=5, max_depth=11, n_estimators=219, subsample=0.8665528088349594; total time=  21.5s\n",
      "[CV] END learning_rate=0.0783106657210144, max_delta_step=5, max_depth=11, n_estimators=219, subsample=0.8665528088349594; total time=  16.7s\n",
      "[CV] END learning_rate=0.4150566973395904, max_delta_step=8, max_depth=12, n_estimators=62, subsample=0.35711592628016825; total time=   5.0s\n",
      "[CV] END learning_rate=0.4150566973395904, max_delta_step=8, max_depth=12, n_estimators=62, subsample=0.35711592628016825; total time=   5.0s\n",
      "[CV] END learning_rate=0.4150566973395904, max_delta_step=8, max_depth=12, n_estimators=62, subsample=0.35711592628016825; total time=   5.1s\n",
      "[CV] END learning_rate=0.4150566973395904, max_delta_step=8, max_depth=12, n_estimators=62, subsample=0.35711592628016825; total time=   4.4s\n",
      "[CV] END learning_rate=0.4150566973395904, max_delta_step=8, max_depth=12, n_estimators=62, subsample=0.35711592628016825; total time=   4.6s\n",
      "[CV] END learning_rate=0.012592431386993388, max_delta_step=3, max_depth=17, n_estimators=69, subsample=0.7549747515444356; total time=   9.1s\n",
      "[CV] END learning_rate=0.012592431386993388, max_delta_step=3, max_depth=17, n_estimators=69, subsample=0.7549747515444356; total time=   9.1s\n",
      "[CV] END learning_rate=0.012592431386993388, max_delta_step=3, max_depth=17, n_estimators=69, subsample=0.7549747515444356; total time=   9.0s\n",
      "[CV] END learning_rate=0.012592431386993388, max_delta_step=3, max_depth=17, n_estimators=69, subsample=0.7549747515444356; total time=   8.9s\n",
      "[CV] END learning_rate=0.012592431386993388, max_delta_step=3, max_depth=17, n_estimators=69, subsample=0.7549747515444356; total time=   9.4s\n",
      "[CV] END learning_rate=0.3609834386288517, max_delta_step=2, max_depth=11, n_estimators=192, subsample=0.5629080668479608; total time=  12.3s\n",
      "[CV] END learning_rate=0.3609834386288517, max_delta_step=2, max_depth=11, n_estimators=192, subsample=0.5629080668479608; total time=  12.1s\n",
      "[CV] END learning_rate=0.3609834386288517, max_delta_step=2, max_depth=11, n_estimators=192, subsample=0.5629080668479608; total time=  11.2s\n",
      "[CV] END learning_rate=0.3609834386288517, max_delta_step=2, max_depth=11, n_estimators=192, subsample=0.5629080668479608; total time=  11.4s\n",
      "[CV] END learning_rate=0.3609834386288517, max_delta_step=2, max_depth=11, n_estimators=192, subsample=0.5629080668479608; total time=  11.9s\n",
      "[CV] END learning_rate=0.0569909699204345, max_delta_step=6, max_depth=19, n_estimators=135, subsample=0.5297068672323123; total time=  28.7s\n",
      "[CV] END learning_rate=0.0569909699204345, max_delta_step=6, max_depth=19, n_estimators=135, subsample=0.5297068672323123; total time=  29.0s\n",
      "[CV] END learning_rate=0.0569909699204345, max_delta_step=6, max_depth=19, n_estimators=135, subsample=0.5297068672323123; total time=  28.3s\n",
      "[CV] END learning_rate=0.0569909699204345, max_delta_step=6, max_depth=19, n_estimators=135, subsample=0.5297068672323123; total time=  28.8s\n",
      "[CV] END learning_rate=0.0569909699204345, max_delta_step=6, max_depth=19, n_estimators=135, subsample=0.5297068672323123; total time=  26.5s\n",
      "[CV] END learning_rate=0.08752080836387209, max_delta_step=5, max_depth=14, n_estimators=107, subsample=0.3213501749573346; total time=   9.7s\n",
      "[CV] END learning_rate=0.08752080836387209, max_delta_step=5, max_depth=14, n_estimators=107, subsample=0.3213501749573346; total time=   9.9s\n",
      "[CV] END learning_rate=0.08752080836387209, max_delta_step=5, max_depth=14, n_estimators=107, subsample=0.3213501749573346; total time=  11.1s\n",
      "[CV] END learning_rate=0.08752080836387209, max_delta_step=5, max_depth=14, n_estimators=107, subsample=0.3213501749573346; total time=   8.5s\n",
      "[CV] END learning_rate=0.08752080836387209, max_delta_step=5, max_depth=14, n_estimators=107, subsample=0.3213501749573346; total time=   7.9s\n",
      "[CV] END learning_rate=0.02867409437460721, max_delta_step=5, max_depth=19, n_estimators=103, subsample=0.6759576990376588; total time=  25.4s\n",
      "[CV] END learning_rate=0.02867409437460721, max_delta_step=5, max_depth=19, n_estimators=103, subsample=0.6759576990376588; total time=  28.8s\n",
      "[CV] END learning_rate=0.02867409437460721, max_delta_step=5, max_depth=19, n_estimators=103, subsample=0.6759576990376588; total time=  32.8s\n",
      "[CV] END learning_rate=0.02867409437460721, max_delta_step=5, max_depth=19, n_estimators=103, subsample=0.6759576990376588; total time=  36.1s\n",
      "[CV] END learning_rate=0.02867409437460721, max_delta_step=5, max_depth=19, n_estimators=103, subsample=0.6759576990376588; total time=  32.7s\n",
      "[CV] END learning_rate=0.17332562089802045, max_delta_step=7, max_depth=9, n_estimators=109, subsample=0.4510747192477902; total time=   4.7s\n",
      "[CV] END learning_rate=0.17332562089802045, max_delta_step=7, max_depth=9, n_estimators=109, subsample=0.4510747192477902; total time=   4.4s\n",
      "[CV] END learning_rate=0.17332562089802045, max_delta_step=7, max_depth=9, n_estimators=109, subsample=0.4510747192477902; total time=   4.0s\n",
      "[CV] END learning_rate=0.17332562089802045, max_delta_step=7, max_depth=9, n_estimators=109, subsample=0.4510747192477902; total time=   3.8s\n",
      "[CV] END learning_rate=0.17332562089802045, max_delta_step=7, max_depth=9, n_estimators=109, subsample=0.4510747192477902; total time=   3.8s\n",
      "[CV] END learning_rate=0.32144523790950014, max_delta_step=3, max_depth=10, n_estimators=158, subsample=0.43606602379641113; total time=   7.3s\n",
      "[CV] END learning_rate=0.32144523790950014, max_delta_step=3, max_depth=10, n_estimators=158, subsample=0.43606602379641113; total time=   6.8s\n",
      "[CV] END learning_rate=0.32144523790950014, max_delta_step=3, max_depth=10, n_estimators=158, subsample=0.43606602379641113; total time=   7.0s\n",
      "[CV] END learning_rate=0.32144523790950014, max_delta_step=3, max_depth=10, n_estimators=158, subsample=0.43606602379641113; total time=   5.8s\n",
      "[CV] END learning_rate=0.32144523790950014, max_delta_step=3, max_depth=10, n_estimators=158, subsample=0.43606602379641113; total time=   5.9s\n",
      "[CV] END learning_rate=0.2156769525283393, max_delta_step=2, max_depth=11, n_estimators=217, subsample=0.808263933605863; total time=  16.2s\n",
      "[CV] END learning_rate=0.2156769525283393, max_delta_step=2, max_depth=11, n_estimators=217, subsample=0.808263933605863; total time=  12.3s\n",
      "[CV] END learning_rate=0.2156769525283393, max_delta_step=2, max_depth=11, n_estimators=217, subsample=0.808263933605863; total time=  11.2s\n",
      "[CV] END learning_rate=0.2156769525283393, max_delta_step=2, max_depth=11, n_estimators=217, subsample=0.808263933605863; total time=  11.3s\n",
      "[CV] END learning_rate=0.2156769525283393, max_delta_step=2, max_depth=11, n_estimators=217, subsample=0.808263933605863; total time=  12.4s\n",
      "[CV] END learning_rate=0.4979260397312673, max_delta_step=9, max_depth=18, n_estimators=196, subsample=0.8566303363380925; total time=   9.2s\n",
      "[CV] END learning_rate=0.4979260397312673, max_delta_step=9, max_depth=18, n_estimators=196, subsample=0.8566303363380925; total time=   9.0s\n",
      "[CV] END learning_rate=0.4979260397312673, max_delta_step=9, max_depth=18, n_estimators=196, subsample=0.8566303363380925; total time=   8.9s\n",
      "[CV] END learning_rate=0.4979260397312673, max_delta_step=9, max_depth=18, n_estimators=196, subsample=0.8566303363380925; total time=   9.1s\n",
      "[CV] END learning_rate=0.4979260397312673, max_delta_step=9, max_depth=18, n_estimators=196, subsample=0.8566303363380925; total time=   9.1s\n",
      "[CV] END learning_rate=0.14541612563103712, max_delta_step=9, max_depth=11, n_estimators=139, subsample=0.31774552039082027; total time=   5.6s\n",
      "[CV] END learning_rate=0.14541612563103712, max_delta_step=9, max_depth=11, n_estimators=139, subsample=0.31774552039082027; total time=   5.6s\n",
      "[CV] END learning_rate=0.14541612563103712, max_delta_step=9, max_depth=11, n_estimators=139, subsample=0.31774552039082027; total time=   5.4s\n",
      "[CV] END learning_rate=0.14541612563103712, max_delta_step=9, max_depth=11, n_estimators=139, subsample=0.31774552039082027; total time=   6.6s\n",
      "[CV] END learning_rate=0.14541612563103712, max_delta_step=9, max_depth=11, n_estimators=139, subsample=0.31774552039082027; total time=   6.3s\n",
      "[CV] END learning_rate=0.49132420733896254, max_delta_step=6, max_depth=19, n_estimators=186, subsample=0.7819499305357565; total time=  13.5s\n",
      "[CV] END learning_rate=0.49132420733896254, max_delta_step=6, max_depth=19, n_estimators=186, subsample=0.7819499305357565; total time=  12.0s\n",
      "[CV] END learning_rate=0.49132420733896254, max_delta_step=6, max_depth=19, n_estimators=186, subsample=0.7819499305357565; total time=  11.6s\n",
      "[CV] END learning_rate=0.49132420733896254, max_delta_step=6, max_depth=19, n_estimators=186, subsample=0.7819499305357565; total time=  13.0s\n",
      "[CV] END learning_rate=0.49132420733896254, max_delta_step=6, max_depth=19, n_estimators=186, subsample=0.7819499305357565; total time=  12.1s\n",
      "[CV] END learning_rate=0.039096797754221806, max_delta_step=9, max_depth=5, n_estimators=83, subsample=0.46785115141018224; total time=   0.3s\n",
      "[CV] END learning_rate=0.039096797754221806, max_delta_step=9, max_depth=5, n_estimators=83, subsample=0.46785115141018224; total time=   0.3s\n",
      "[CV] END learning_rate=0.039096797754221806, max_delta_step=9, max_depth=5, n_estimators=83, subsample=0.46785115141018224; total time=   0.6s\n",
      "[CV] END learning_rate=0.039096797754221806, max_delta_step=9, max_depth=5, n_estimators=83, subsample=0.46785115141018224; total time=   0.4s\n",
      "[CV] END learning_rate=0.039096797754221806, max_delta_step=9, max_depth=5, n_estimators=83, subsample=0.46785115141018224; total time=   0.4s\n",
      "[CV] END learning_rate=0.05693664504064588, max_delta_step=8, max_depth=12, n_estimators=166, subsample=0.7467894156903452; total time=  15.0s\n",
      "[CV] END learning_rate=0.05693664504064588, max_delta_step=8, max_depth=12, n_estimators=166, subsample=0.7467894156903452; total time=  15.2s\n",
      "[CV] END learning_rate=0.05693664504064588, max_delta_step=8, max_depth=12, n_estimators=166, subsample=0.7467894156903452; total time=  27.9s\n",
      "[CV] END learning_rate=0.05693664504064588, max_delta_step=8, max_depth=12, n_estimators=166, subsample=0.7467894156903452; total time=  15.7s\n",
      "[CV] END learning_rate=0.05693664504064588, max_delta_step=8, max_depth=12, n_estimators=166, subsample=0.7467894156903452; total time=  14.5s\n",
      "[CV] END learning_rate=0.26834812871328334, max_delta_step=4, max_depth=10, n_estimators=142, subsample=0.593720043699453; total time=   6.6s\n",
      "[CV] END learning_rate=0.26834812871328334, max_delta_step=4, max_depth=10, n_estimators=142, subsample=0.593720043699453; total time=   6.3s\n",
      "[CV] END learning_rate=0.26834812871328334, max_delta_step=4, max_depth=10, n_estimators=142, subsample=0.593720043699453; total time=   5.7s\n",
      "[CV] END learning_rate=0.26834812871328334, max_delta_step=4, max_depth=10, n_estimators=142, subsample=0.593720043699453; total time=   7.0s\n",
      "[CV] END learning_rate=0.26834812871328334, max_delta_step=4, max_depth=10, n_estimators=142, subsample=0.593720043699453; total time=   7.3s\n",
      "[CV] END learning_rate=0.13386549475057874, max_delta_step=2, max_depth=9, n_estimators=135, subsample=0.3100754420408291; total time=   3.4s\n",
      "[CV] END learning_rate=0.13386549475057874, max_delta_step=2, max_depth=9, n_estimators=135, subsample=0.3100754420408291; total time=   3.3s\n",
      "[CV] END learning_rate=0.13386549475057874, max_delta_step=2, max_depth=9, n_estimators=135, subsample=0.3100754420408291; total time=   3.1s\n",
      "[CV] END learning_rate=0.13386549475057874, max_delta_step=2, max_depth=9, n_estimators=135, subsample=0.3100754420408291; total time=   2.8s\n",
      "[CV] END learning_rate=0.13386549475057874, max_delta_step=2, max_depth=9, n_estimators=135, subsample=0.3100754420408291; total time=   2.9s\n",
      "[CV] END learning_rate=0.06803632025345811, max_delta_step=4, max_depth=19, n_estimators=143, subsample=0.898822408807705; total time=  40.1s\n",
      "[CV] END learning_rate=0.06803632025345811, max_delta_step=4, max_depth=19, n_estimators=143, subsample=0.898822408807705; total time=  52.7s\n",
      "[CV] END learning_rate=0.06803632025345811, max_delta_step=4, max_depth=19, n_estimators=143, subsample=0.898822408807705; total time=  55.6s\n",
      "[CV] END learning_rate=0.06803632025345811, max_delta_step=4, max_depth=19, n_estimators=143, subsample=0.898822408807705; total time=  41.5s\n",
      "[CV] END learning_rate=0.06803632025345811, max_delta_step=4, max_depth=19, n_estimators=143, subsample=0.898822408807705; total time=  43.0s\n",
      "[CV] END learning_rate=0.36182892969001185, max_delta_step=9, max_depth=14, n_estimators=225, subsample=0.8648390839355455; total time=  11.7s\n",
      "[CV] END learning_rate=0.36182892969001185, max_delta_step=9, max_depth=14, n_estimators=225, subsample=0.8648390839355455; total time=  11.5s\n",
      "[CV] END learning_rate=0.36182892969001185, max_delta_step=9, max_depth=14, n_estimators=225, subsample=0.8648390839355455; total time=  12.0s\n",
      "[CV] END learning_rate=0.36182892969001185, max_delta_step=9, max_depth=14, n_estimators=225, subsample=0.8648390839355455; total time=  11.4s\n",
      "[CV] END learning_rate=0.36182892969001185, max_delta_step=9, max_depth=14, n_estimators=225, subsample=0.8648390839355455; total time=  12.2s\n",
      "[CV] END learning_rate=0.1831521605447004, max_delta_step=4, max_depth=11, n_estimators=59, subsample=0.96440201211397; total time=   5.4s\n",
      "[CV] END learning_rate=0.1831521605447004, max_delta_step=4, max_depth=11, n_estimators=59, subsample=0.96440201211397; total time=   4.7s\n",
      "[CV] END learning_rate=0.1831521605447004, max_delta_step=4, max_depth=11, n_estimators=59, subsample=0.96440201211397; total time=   5.0s\n",
      "[CV] END learning_rate=0.1831521605447004, max_delta_step=4, max_depth=11, n_estimators=59, subsample=0.96440201211397; total time=   4.3s\n",
      "[CV] END learning_rate=0.1831521605447004, max_delta_step=4, max_depth=11, n_estimators=59, subsample=0.96440201211397; total time=   4.1s\n",
      "[CV] END learning_rate=0.4533401936490238, max_delta_step=3, max_depth=19, n_estimators=187, subsample=0.7381019409999654; total time=  15.8s\n",
      "[CV] END learning_rate=0.4533401936490238, max_delta_step=3, max_depth=19, n_estimators=187, subsample=0.7381019409999654; total time=  20.3s\n",
      "[CV] END learning_rate=0.4533401936490238, max_delta_step=3, max_depth=19, n_estimators=187, subsample=0.7381019409999654; total time=  18.8s\n",
      "[CV] END learning_rate=0.4533401936490238, max_delta_step=3, max_depth=19, n_estimators=187, subsample=0.7381019409999654; total time=  17.4s\n",
      "[CV] END learning_rate=0.4533401936490238, max_delta_step=3, max_depth=19, n_estimators=187, subsample=0.7381019409999654; total time=  17.2s\n",
      "[CV] END learning_rate=0.26156812929004386, max_delta_step=0, max_depth=12, n_estimators=118, subsample=0.7787746385786987; total time=  12.2s\n",
      "[CV] END learning_rate=0.26156812929004386, max_delta_step=0, max_depth=12, n_estimators=118, subsample=0.7787746385786987; total time=  13.4s\n",
      "[CV] END learning_rate=0.26156812929004386, max_delta_step=0, max_depth=12, n_estimators=118, subsample=0.7787746385786987; total time=  12.2s\n",
      "[CV] END learning_rate=0.26156812929004386, max_delta_step=0, max_depth=12, n_estimators=118, subsample=0.7787746385786987; total time=  12.5s\n",
      "[CV] END learning_rate=0.26156812929004386, max_delta_step=0, max_depth=12, n_estimators=118, subsample=0.7787746385786987; total time=  11.9s\n",
      "[CV] END learning_rate=0.3179255821949569, max_delta_step=6, max_depth=6, n_estimators=177, subsample=0.7454825182122078; total time=   1.2s\n",
      "[CV] END learning_rate=0.3179255821949569, max_delta_step=6, max_depth=6, n_estimators=177, subsample=0.7454825182122078; total time=   1.2s\n",
      "[CV] END learning_rate=0.3179255821949569, max_delta_step=6, max_depth=6, n_estimators=177, subsample=0.7454825182122078; total time=   1.2s\n",
      "[CV] END learning_rate=0.3179255821949569, max_delta_step=6, max_depth=6, n_estimators=177, subsample=0.7454825182122078; total time=   1.3s\n",
      "[CV] END learning_rate=0.3179255821949569, max_delta_step=6, max_depth=6, n_estimators=177, subsample=0.7454825182122078; total time=   1.2s\n",
      "[CV] END learning_rate=0.41047464734119987, max_delta_step=1, max_depth=7, n_estimators=173, subsample=0.3899502472637371; total time=   2.2s\n",
      "[CV] END learning_rate=0.41047464734119987, max_delta_step=1, max_depth=7, n_estimators=173, subsample=0.3899502472637371; total time=   2.3s\n",
      "[CV] END learning_rate=0.41047464734119987, max_delta_step=1, max_depth=7, n_estimators=173, subsample=0.3899502472637371; total time=   2.5s\n",
      "[CV] END learning_rate=0.41047464734119987, max_delta_step=1, max_depth=7, n_estimators=173, subsample=0.3899502472637371; total time=   2.0s\n",
      "[CV] END learning_rate=0.41047464734119987, max_delta_step=1, max_depth=7, n_estimators=173, subsample=0.3899502472637371; total time=   2.2s\n",
      "[CV] END learning_rate=0.4156020883680015, max_delta_step=4, max_depth=16, n_estimators=116, subsample=0.8742987906398876; total time=  12.5s\n",
      "[CV] END learning_rate=0.4156020883680015, max_delta_step=4, max_depth=16, n_estimators=116, subsample=0.8742987906398876; total time=  12.5s\n",
      "[CV] END learning_rate=0.4156020883680015, max_delta_step=4, max_depth=16, n_estimators=116, subsample=0.8742987906398876; total time=  13.8s\n",
      "[CV] END learning_rate=0.4156020883680015, max_delta_step=4, max_depth=16, n_estimators=116, subsample=0.8742987906398876; total time=  10.9s\n",
      "[CV] END learning_rate=0.4156020883680015, max_delta_step=4, max_depth=16, n_estimators=116, subsample=0.8742987906398876; total time=  13.4s\n",
      "[CV] END learning_rate=0.335742385928894, max_delta_step=1, max_depth=17, n_estimators=84, subsample=0.5355879504221085; total time=  14.3s\n",
      "[CV] END learning_rate=0.335742385928894, max_delta_step=1, max_depth=17, n_estimators=84, subsample=0.5355879504221085; total time=  19.3s\n",
      "[CV] END learning_rate=0.335742385928894, max_delta_step=1, max_depth=17, n_estimators=84, subsample=0.5355879504221085; total time=  17.7s\n",
      "[CV] END learning_rate=0.335742385928894, max_delta_step=1, max_depth=17, n_estimators=84, subsample=0.5355879504221085; total time=  19.7s\n",
      "[CV] END learning_rate=0.335742385928894, max_delta_step=1, max_depth=17, n_estimators=84, subsample=0.5355879504221085; total time=  15.9s\n",
      "[CV] END learning_rate=0.3378613176903711, max_delta_step=9, max_depth=14, n_estimators=139, subsample=0.538437198624968; total time=  27.2s\n",
      "[CV] END learning_rate=0.3378613176903711, max_delta_step=9, max_depth=14, n_estimators=139, subsample=0.538437198624968; total time=  31.1s\n",
      "[CV] END learning_rate=0.3378613176903711, max_delta_step=9, max_depth=14, n_estimators=139, subsample=0.538437198624968; total time=  40.0s\n",
      "[CV] END learning_rate=0.3378613176903711, max_delta_step=9, max_depth=14, n_estimators=139, subsample=0.538437198624968; total time=  39.3s\n",
      "[CV] END learning_rate=0.3378613176903711, max_delta_step=9, max_depth=14, n_estimators=139, subsample=0.538437198624968; total time=  38.6s\n",
      "[CV] END learning_rate=0.14034726411795156, max_delta_step=6, max_depth=8, n_estimators=107, subsample=0.7877160157549055; total time=   8.2s\n",
      "[CV] END learning_rate=0.14034726411795156, max_delta_step=6, max_depth=8, n_estimators=107, subsample=0.7877160157549055; total time=   6.7s\n",
      "[CV] END learning_rate=0.14034726411795156, max_delta_step=6, max_depth=8, n_estimators=107, subsample=0.7877160157549055; total time=   6.8s\n",
      "[CV] END learning_rate=0.14034726411795156, max_delta_step=6, max_depth=8, n_estimators=107, subsample=0.7877160157549055; total time=   5.4s\n",
      "[CV] END learning_rate=0.14034726411795156, max_delta_step=6, max_depth=8, n_estimators=107, subsample=0.7877160157549055; total time=   8.0s\n",
      "[CV] END learning_rate=0.324471423389942, max_delta_step=7, max_depth=8, n_estimators=70, subsample=0.9773063860641731; total time=   5.3s\n",
      "[CV] END learning_rate=0.324471423389942, max_delta_step=7, max_depth=8, n_estimators=70, subsample=0.9773063860641731; total time=   4.9s\n",
      "[CV] END learning_rate=0.324471423389942, max_delta_step=7, max_depth=8, n_estimators=70, subsample=0.9773063860641731; total time=   5.2s\n",
      "[CV] END learning_rate=0.324471423389942, max_delta_step=7, max_depth=8, n_estimators=70, subsample=0.9773063860641731; total time=   5.1s\n",
      "[CV] END learning_rate=0.324471423389942, max_delta_step=7, max_depth=8, n_estimators=70, subsample=0.9773063860641731; total time=   3.1s\n",
      "[CV] END learning_rate=0.28398594162404367, max_delta_step=4, max_depth=13, n_estimators=201, subsample=0.8647843174870848; total time=  38.3s\n",
      "[CV] END learning_rate=0.28398594162404367, max_delta_step=4, max_depth=13, n_estimators=201, subsample=0.8647843174870848; total time=  35.7s\n",
      "[CV] END learning_rate=0.28398594162404367, max_delta_step=4, max_depth=13, n_estimators=201, subsample=0.8647843174870848; total time=  43.5s\n",
      "[CV] END learning_rate=0.28398594162404367, max_delta_step=4, max_depth=13, n_estimators=201, subsample=0.8647843174870848; total time=  37.5s\n",
      "[CV] END learning_rate=0.28398594162404367, max_delta_step=4, max_depth=13, n_estimators=201, subsample=0.8647843174870848; total time=  37.1s\n",
      "[CV] END learning_rate=0.5052525710003366, max_delta_step=3, max_depth=6, n_estimators=145, subsample=0.5385624781771124; total time=   4.8s\n",
      "[CV] END learning_rate=0.5052525710003366, max_delta_step=3, max_depth=6, n_estimators=145, subsample=0.5385624781771124; total time=   5.3s\n",
      "[CV] END learning_rate=0.5052525710003366, max_delta_step=3, max_depth=6, n_estimators=145, subsample=0.5385624781771124; total time=   5.0s\n",
      "[CV] END learning_rate=0.5052525710003366, max_delta_step=3, max_depth=6, n_estimators=145, subsample=0.5385624781771124; total time=   4.6s\n",
      "[CV] END learning_rate=0.5052525710003366, max_delta_step=3, max_depth=6, n_estimators=145, subsample=0.5385624781771124; total time=   5.4s\n",
      "[CV] END learning_rate=0.47537866280178237, max_delta_step=4, max_depth=16, n_estimators=162, subsample=0.7758913459301721; total time=  33.3s\n",
      "[CV] END learning_rate=0.47537866280178237, max_delta_step=4, max_depth=16, n_estimators=162, subsample=0.7758913459301721; total time=  37.5s\n",
      "[CV] END learning_rate=0.47537866280178237, max_delta_step=4, max_depth=16, n_estimators=162, subsample=0.7758913459301721; total time=  31.6s\n",
      "[CV] END learning_rate=0.47537866280178237, max_delta_step=4, max_depth=16, n_estimators=162, subsample=0.7758913459301721; total time=  33.8s\n",
      "[CV] END learning_rate=0.47537866280178237, max_delta_step=4, max_depth=16, n_estimators=162, subsample=0.7758913459301721; total time=  34.8s\n",
      "[CV] END learning_rate=0.37995438022368727, max_delta_step=2, max_depth=13, n_estimators=79, subsample=0.9317870346756967; total time=  30.6s\n",
      "[CV] END learning_rate=0.37995438022368727, max_delta_step=2, max_depth=13, n_estimators=79, subsample=0.9317870346756967; total time=  22.4s\n",
      "[CV] END learning_rate=0.37995438022368727, max_delta_step=2, max_depth=13, n_estimators=79, subsample=0.9317870346756967; total time=  11.0s\n",
      "[CV] END learning_rate=0.37995438022368727, max_delta_step=2, max_depth=13, n_estimators=79, subsample=0.9317870346756967; total time=   9.8s\n",
      "[CV] END learning_rate=0.37995438022368727, max_delta_step=2, max_depth=13, n_estimators=79, subsample=0.9317870346756967; total time=  10.1s\n",
      "[CV] END learning_rate=0.2626261862239286, max_delta_step=8, max_depth=10, n_estimators=190, subsample=0.9268662599473403; total time=  10.5s\n",
      "[CV] END learning_rate=0.2626261862239286, max_delta_step=8, max_depth=10, n_estimators=190, subsample=0.9268662599473403; total time=  10.6s\n",
      "[CV] END learning_rate=0.2626261862239286, max_delta_step=8, max_depth=10, n_estimators=190, subsample=0.9268662599473403; total time=  10.6s\n",
      "[CV] END learning_rate=0.2626261862239286, max_delta_step=8, max_depth=10, n_estimators=190, subsample=0.9268662599473403; total time=  10.6s\n",
      "[CV] END learning_rate=0.2626261862239286, max_delta_step=8, max_depth=10, n_estimators=190, subsample=0.9268662599473403; total time=  10.7s\n",
      "[CV] END learning_rate=0.20460083936708157, max_delta_step=8, max_depth=7, n_estimators=125, subsample=0.5484336333239044; total time=   1.8s\n",
      "[CV] END learning_rate=0.20460083936708157, max_delta_step=8, max_depth=7, n_estimators=125, subsample=0.5484336333239044; total time=   2.2s\n",
      "[CV] END learning_rate=0.20460083936708157, max_delta_step=8, max_depth=7, n_estimators=125, subsample=0.5484336333239044; total time=   2.0s\n",
      "[CV] END learning_rate=0.20460083936708157, max_delta_step=8, max_depth=7, n_estimators=125, subsample=0.5484336333239044; total time=   1.9s\n",
      "[CV] END learning_rate=0.20460083936708157, max_delta_step=8, max_depth=7, n_estimators=125, subsample=0.5484336333239044; total time=   2.0s\n",
      "{'learning_rate': 0.039096797754221806, 'max_delta_step': 9, 'max_depth': 5, 'n_estimators': 83, 'subsample': 0.46785115141018224}\n",
      "-183.0145721147627\n",
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.039096797754221806,\n",
      "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=9, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=83, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n"
     ]
    }
   ],
   "source": [
    "# perform random grid search on xgboost\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': randint(5, 20),\n",
    "    'n_estimators': randint(50, 250),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'max_delta_step': randint(0, 10),\n",
    "    'subsample': uniform(0.3, 0.7),\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(xgb, param_distributions=param_grid,\n",
    "                                n_iter=100, cv=5, scoring='neg_mean_squared_error', random_state=42,verbose=2)\n",
    "rnd_search.fit(X_train_pca, y_train)\n",
    "\n",
    "print(rnd_search.best_params_)\n",
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
